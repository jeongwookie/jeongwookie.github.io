<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>JW&#39;s Blog</title>
  
  <subtitle>Make stuff people want</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://jeongwookie.github.io/"/>
  <updated>2021-12-08T08:57:21.685Z</updated>
  <id>https://jeongwookie.github.io/</id>
  
  <author>
    <name>Jeongwook, Kim</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>백준 2178번 - 미로 탐색</title>
    <link href="https://jeongwookie.github.io/2021/12/08/programming/codingtest/dfs&amp;bfs/3-baekjoon-2178/"/>
    <id>https://jeongwookie.github.io/2021/12/08/programming/codingtest/dfs&amp;bfs/3-baekjoon-2178/</id>
    <published>2021-12-08T09:01:24.000Z</published>
    <updated>2021-12-08T08:57:21.685Z</updated>
    
    <content type="html"><![CDATA[<p>코테 풀이들은 대부분 길어서 더보기 클릭을 하지 않으면 보이지 않도록 해당 문구를 추가합니다.</p><a id="more"></a><h2 id="백준-2178-미로-탐색"><a href="#백준-2178-미로-탐색" class="headerlink" title="백준 2178: 미로 탐색"></a>백준 2178: 미로 탐색</h2><p>문제 출처 : <a href="https://www.acmicpc.net/problem/2178" rel="external nofollow noopener noreferrer" target="_blank">https://www.acmicpc.net/problem/2178</a></p><p><img src="https://user-images.githubusercontent.com/25416425/145166687-2a0da963-a253-49b5-8b7c-de7d4b302ddb.png" alt="image"></p><h2 id="문제-설명"><a href="#문제-설명" class="headerlink" title="문제 설명"></a>문제 설명</h2><p>출발 지점과 도착 지점이 주어진 <strong>최단 거리 구하기</strong> 문제 이다.<br>한 지점을 기준으로 BFS를 차근차근 수행해가며 값을 누적시키면 문제를 해결할 수 있다.<br>최단 거리 문제가 나오면 일단 BFS를 떠올려 보자!</p><h2 id="문제-풀이"><a href="#문제-풀이" class="headerlink" title="문제 풀이"></a>문제 풀이</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">[풀이 논리]</span><br><span class="line"><span class="number">1.</span> 시작점이 (<span class="number">1</span>,<span class="number">1</span>)이고 도착점이 (N,M)이므로, 한칸씩 당겨서 시작점을 (<span class="number">0</span>,<span class="number">0</span>) 도착점을 (N<span class="number">-1</span>,M<span class="number">-1</span>)로 설정한다.</span><br><span class="line"><span class="number">2.</span> visited라는 리스트를 만들고 주어진 graph와 dim을 맞춰서 <span class="number">0</span>을 넣어놓는다.</span><br><span class="line"><span class="number">3.</span> 시작점에서 시작해서 bfs를 수행하고, 해당 지점이 도착점과 같아질 때 함수를 종료한다.</span><br><span class="line"><span class="number">4.</span> 지점을 방문할때마다 visited의 값을 누적시킨다.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bfs</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 상하좌우</span></span><br><span class="line">    dx = [<span class="number">-1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    dy = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    queue = deque([start]) <span class="comment"># (0,0)을 q에 넣고</span></span><br><span class="line">    visited[start[<span class="number">0</span>]][start[<span class="number">1</span>]] = <span class="number">1</span> <span class="comment"># 방문 처리</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> queue:</span><br><span class="line">        x, y = queue.popleft()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> x == end[<span class="number">0</span>] <span class="keyword">and</span> y == end[<span class="number">1</span>]: <span class="comment"># 종료 조건</span></span><br><span class="line">            <span class="keyword">return</span> visited[x][y]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>): <span class="comment"># 상하좌우로 인접 탐색</span></span><br><span class="line">            next_x, next_y = x + dx[i], y + dy[i]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> valid(next_x, next_y): <span class="comment"># 좌표가 유효한 경우,</span></span><br><span class="line">                queue.append([next_x, next_y]) <span class="comment"># 해당 좌표를 큐에 넣고</span></span><br><span class="line">                visited[next_x][next_y] = visited[x][y] + <span class="number">1</span> <span class="comment"># 방문처리하여 값 누적</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">valid</span><span class="params">(x,y)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="number">0</span> &lt;= x &lt; N <span class="keyword">and</span> <span class="number">0</span> &lt;= y &lt; M: <span class="comment"># 범위에서 벗어나지 않고,</span></span><br><span class="line">        <span class="keyword">if</span> graph[x][y] == <span class="number">1</span> <span class="keyword">and</span> visited[x][y] == <span class="number">0</span>: <span class="comment"># 길이 있고, 방문한 적이 없다면</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">import</span> sys; readline = sys.stdin.readline</span><br><span class="line">    <span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line">    N, M = map(int, readline().split())</span><br><span class="line">    graph = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(N):</span><br><span class="line">        _list = [int(i) <span class="keyword">for</span> i <span class="keyword">in</span> readline().strip()]</span><br><span class="line">        graph.append(_list)</span><br><span class="line"></span><br><span class="line">    start = [<span class="number">0</span>, <span class="number">0</span>] <span class="comment"># (1,1)이 처음이므로 1칸씩 뒤로 당김</span></span><br><span class="line">    end = [N<span class="number">-1</span>, M<span class="number">-1</span>]</span><br><span class="line">    visited = [[<span class="number">0</span>] * M <span class="keyword">for</span> _ <span class="keyword">in</span> range(N)] <span class="comment"># 0으로 초기화</span></span><br><span class="line">    print(bfs())</span><br></pre></td></tr></table></figure><blockquote><p><strong>풀이 포인트</strong><br>최단 거리 구하기 문제는 BFS 떠올리기<br>값 누적시킬 visited 리스트를 새로 만들기<br>내가 실수했던 부분 : visited 리스트 만들 때 리스트 구조를 이상하게 만들었었음 ㅠ<br>얌전하게 [[0] * M for _ in range(N)] 이런식으로 합시다..<br>아니면 걍 [[0 for _ in range(M)] for _ in range(N)] 이렇게 적던가</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;코테 풀이들은 대부분 길어서 더보기 클릭을 하지 않으면 보이지 않도록 해당 문구를 추가합니다.&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅱ. Programming" scheme="https://jeongwookie.github.io/categories/%E2%85%A1-Programming/"/>
    
      <category term="코딩 테스트 문제 풀이" scheme="https://jeongwookie.github.io/categories/%E2%85%A1-Programming/%EC%BD%94%EB%94%A9-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%AC%B8%EC%A0%9C-%ED%92%80%EC%9D%B4/"/>
    
      <category term="DFS와 BFS" scheme="https://jeongwookie.github.io/categories/%E2%85%A1-Programming/%EC%BD%94%EB%94%A9-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%AC%B8%EC%A0%9C-%ED%92%80%EC%9D%B4/DFS%EC%99%80-BFS/"/>
    
    
      <category term="Python" scheme="https://jeongwookie.github.io/tags/Python/"/>
    
      <category term="Codingtest" scheme="https://jeongwookie.github.io/tags/Codingtest/"/>
    
      <category term="Baekjoon" scheme="https://jeongwookie.github.io/tags/Baekjoon/"/>
    
      <category term="DFS&amp;BFS" scheme="https://jeongwookie.github.io/tags/DFS-BFS/"/>
    
  </entry>
  
  <entry>
    <title>OS공부 - 프로세스</title>
    <link href="https://jeongwookie.github.io/2021/12/06/computerscience/operatingsystem/3-what-is-process/"/>
    <id>https://jeongwookie.github.io/2021/12/06/computerscience/operatingsystem/3-what-is-process/</id>
    <published>2021-12-06T09:03:20.000Z</published>
    <updated>2021-12-09T05:12:32.603Z</updated>
    
    <content type="html"><![CDATA[<h2 id="프로세스의-정의"><a href="#프로세스의-정의" class="headerlink" title="프로세스의 정의"></a>프로세스의 정의</h2><p><strong>프로세스 (process)</strong> 란, 실행 중인 프로그램을 뜻한다.</p><p>HDD, SSD와 같은 스토리지에 우리가 작성한 코드 파일이 있을 것이다. 이런 명령어들의 집합으로 구성된 프로그램을 실행시키게 되면 해당 정보들이 메모리에 로드 된다. 해당 프로그램은 이제 cpu가 fetch해서 연산할 수 있는 상태가 되는데, 해당 상태에 있는 프로그램을 프로세스 라고 할 수 있겠다. 이제 이 프로세스는 cpu를 점유하거나, 파일을 열거나, I/O 장치들과 신호를 주고 받게 될 것이다. 운영체제가 해야 하는 가장 기본적인 활동은 <u>바로 프로세스를 관리하는 것이다</u>.</p><a id="more"></a><p><img src="https://user-images.githubusercontent.com/25416425/144813252-f2160a8b-923b-4978-ac3f-8b20efcf79bf.png" alt="image"></p><p>프로세스는 위 그림과 같은 주소 공간을 필요로 하게 된다. text 영역에는 우리가 작성한 프로그램 코드가 들어 있고, data에는 전역 변수가, heap 영역에는 동적으로 할당된 메모리가 들어 있다. C에서는 <code>malloc</code>, Java에서는 <code>new</code>와 같은 코드가 메모리 동적 할당을 수행한다. stack 영역은 임시 데이터 저장 공간이라고 할 수 있는데 여기는 지역 번수, 함수의 매개 변수, 리턴값의 주소 등이 들어 있다. stack 영역은 위에서부터 아래로 커지고, heap 영역은 아래에서 위로 커지는 방식이다. 이렇게 쭉 쌓아오다가 만약 부족해지면 다른 메모리 영역을 참조하기도 한다.</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> x; <span class="comment">// uninitialized data section</span></span><br><span class="line"><span class="keyword">int</span> y = <span class="number">15</span>; <span class="comment">// initialized data section</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> <span class="comment">// stack section</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> *values; <span class="comment">// stack section </span></span><br><span class="line">    <span class="keyword">int</span> i; <span class="comment">// stack section</span></span><br><span class="line"></span><br><span class="line">    values = (<span class="keyword">int</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">int</span>)*<span class="number">5</span>) <span class="comment">// heap section</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">0</span>; i &lt; <span class="number">5</span>; i++) <span class="comment">// text section에서 수행</span></span><br><span class="line">        values[i] = i;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>; <span class="comment">// 프로그램이 종료되고, 다시 제어권을 os에게 넘겨줌</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>위 소스 코드가 우리가 일반적으로 작성하는 형태이고, 이를 컴파일 하여 <code>a.out</code> 이라는 프로그램을 만들 수 있다. 해당 프로그램이 메모리에 로드되면서 각각의 section을 차지하게 되는 이런 일련의 동작을 프로세스 라고 할 수 있겠다. (즉, 실행중인 프로그램!)</p><h2 id="프로세스의-상태"><a href="#프로세스의-상태" class="headerlink" title="프로세스의 상태"></a>프로세스의 상태</h2><p>프로세스는 총 다섯 가지 상태를 가질 수 있다.</p><ul><li>new :  프로세스가 생성 되었을 때</li><li>ready : 프로세스가 cpu를 할당 받기를 기다리고 있을 때 (준비 완료!)</li><li>running : 명령어들이 실행되고 있을 때</li><li>waiting : 프로세스가 어떤 이벤트가 발생하기를 기다리고 있을 때</li><li>terminated : 프로세스가 종료 되었을 때</li></ul><p><img src="https://user-images.githubusercontent.com/25416425/144817003-230dce48-06b1-488e-898b-d4e028870858.png" alt="image"></p><p>위 그림을 순서대로 해석 해 보자.</p><ol><li><code>fork()</code>라는 시스템 콜을 통해서 사용자는 프로세스 생성을 os에게 요청할 수 있다. (new 상태)</li><li>프로그램을 프로세스로 만드는 여러 작업들을 거친 후, cpu에게 점유할 준비가 다 되었다고 알려주기 위해 ready queue에 들어간다. (ready 상태)</li><li>cpu 스케쥴러는 이를 확인하고, 정책에 따라 ready 상태의 프로세스를 cpu에 dispatch한다. (running 상태) </li><li>프로세스는 cpu 스케쥴러의 판단에 따라서 다시 ready 상태로 옮겨지기도 한다. (interrupt 발생) </li><li>만약 I/O 요청 또는 다른 event가 발생하여 잠시 프로세스의 실행을 멈춰야 할 때도 있다. (waiting 상태)</li><li>I/O 요청이 종료되면, 해당 프로세스는 다시 cpu를 점유할 수 있는 상태가 되므로 ready queue에 들어가서 대기한다.</li><li>마지막으로 <code>exit()</code>과 같은 명시적인 종료 시스템 콜이 들어오면, 프로세스는 종료된다. (terminated 상태)</li></ol><h2 id="프로세스-컨트롤-블록"><a href="#프로세스-컨트롤-블록" class="headerlink" title="프로세스 컨트롤 블록"></a>프로세스 컨트롤 블록</h2><p><strong>프로세스 컨트롤 블록 (Process Control Block, PCB)</strong>은 운영체제가 가지고 있는 프로세스에 대한 정보의 총집합이다.<br>다시 말하면, 운영체제가 프로세스 스케쥴링을 위해 프로세스에 관한 모든 정보를 가지고 있는 데이터베이스를 의미한다.</p><p>각 프로세스가 생성될 때 마다 고유의 PCB가 생성되고, 프로세스가 완료되면 제거된다. 이런 정보 구조체가 실제로 어떻게 쓰일까? 프로세스는 기본적으로 cpu를 점유하여 작업을 처리한다. 그런데, 우리가 앞서 살펴본 process state에 따르면 프로세스가 running 상태에 있더라도 특정 이벤트 혹은 interrupt에 의해 ready나 wait 상태로 바뀐다. 이때 PCB를 활용하여, 방금 전까지 작업한 내용들을 전부 저장해 둔다. 이후 다시 해당 프로세스가 cpu를 점유하게 되면 (running 상태) PCB로부터 해당 정보들을 불러와서 작업을 이어서 진행할 수 있게 된다. </p><p><img src="https://user-images.githubusercontent.com/25416425/145335493-9b5e84a0-0892-4c0f-8a0a-3434f17bd1df.png" alt="image"></p><p>PCB는 위 그림과 같은 구조로 이루어져 있다. 중요한 몇 가지만 짚고 넘어가자.</p><ul><li>프로세스 식별자 (process ID)</li><li>프로세스 상태 (process state) : ready? wait? 이런 상태들을 저장해두어야 한다.</li><li><strong>프로그램 카운터 (program counter, pc)</strong> : 해당 프로세스가 다음에 실행할 명령어의 주소를 가리킨다.</li><li>cpu 및 일반 레지스터</li><li>cpu 스케쥴링 정보 : 최종 실행 시각, 우선 순위, 점유 시간 등등</li><li>메모리 관리 정보 : 해당 프로세스의 주소 공간</li><li>프로세스 계정 정보</li><li>입출력 상태 정보 : 프로세스에 할당돤 입출력장치 목록, 열린 파일 목록 등</li></ul><h2 id="요약"><a href="#요약" class="headerlink" title="요약"></a>요약</h2><ul><li>프로세스란, 실행 중인 프로그램을 뜻함</li><li>프로세스가 필요한 메모리 주소 공간은 text, data, heap, stack이 있음</li><li>ready 상태의 프로세스는 cpu 스케쥴러에 의해 running 상태로 바뀜</li><li>running 상태의 프로세스는 I/O interrupt에 의해 wait 상태로 바뀔 수 있음</li><li>running 상태의 프로세스는 cpu 스케쥴러에 의해 interrupt 되어 다시 ready 상태로 바뀔 수 있음</li><li>PCB는 프로세스의 정보를 담고 있는 데이터베이스임. 프로세스가 스케쥴링되어 바뀔 때 유용하게 사용됨</li><li>특히, 프로그램 카운터 (pc)는 해당 프로세스가 다음에 실행할 명령어의 주소를 저장하고 있음</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;프로세스의-정의&quot;&gt;&lt;a href=&quot;#프로세스의-정의&quot; class=&quot;headerlink&quot; title=&quot;프로세스의 정의&quot;&gt;&lt;/a&gt;프로세스의 정의&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;프로세스 (process)&lt;/strong&gt; 란, 실행 중인 프로그램을 뜻한다.&lt;/p&gt;
&lt;p&gt;HDD, SSD와 같은 스토리지에 우리가 작성한 코드 파일이 있을 것이다. 이런 명령어들의 집합으로 구성된 프로그램을 실행시키게 되면 해당 정보들이 메모리에 로드 된다. 해당 프로그램은 이제 cpu가 fetch해서 연산할 수 있는 상태가 되는데, 해당 상태에 있는 프로그램을 프로세스 라고 할 수 있겠다. 이제 이 프로세스는 cpu를 점유하거나, 파일을 열거나, I/O 장치들과 신호를 주고 받게 될 것이다. 운영체제가 해야 하는 가장 기본적인 활동은 &lt;u&gt;바로 프로세스를 관리하는 것이다&lt;/u&gt;.&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅲ. CS Study" scheme="https://jeongwookie.github.io/categories/%E2%85%A2-CS-Study/"/>
    
      <category term="Operating System" scheme="https://jeongwookie.github.io/categories/%E2%85%A2-CS-Study/Operating-System/"/>
    
    
      <category term="cs" scheme="https://jeongwookie.github.io/tags/cs/"/>
    
      <category term="os" scheme="https://jeongwookie.github.io/tags/os/"/>
    
  </entry>
  
  <entry>
    <title>OS공부 - 운영체제의 개념과 구조</title>
    <link href="https://jeongwookie.github.io/2021/12/04/computerscience/operatingsystem/2-os-structures-intro/"/>
    <id>https://jeongwookie.github.io/2021/12/04/computerscience/operatingsystem/2-os-structures-intro/</id>
    <published>2021-12-04T13:11:20.000Z</published>
    <updated>2021-12-06T09:33:31.966Z</updated>
    
    <content type="html"><![CDATA[<h2 id="운영-체제의-정의"><a href="#운영-체제의-정의" class="headerlink" title="운영 체제의 정의"></a>운영 체제의 정의</h2><p>운영 체제 (Operating System)에 대해서 다시 정의를 짚어보고 넘어가자.</p><ul><li>OS는 컴퓨터의 하드웨어를 manage하는 소프트웨어이다.</li><li>OS는 컴퓨터 유저와 컴퓨터 하드웨어간의 매개 역할을 수행한다.</li></ul><p>이해를 돕기 위해 우리는 컴퓨터 시스템이 어떻게 구성되어 있는지 알아야 한다. 크게 4가지 component로 구성되어 있는데, 하드웨어, 운영체제, 응용 프로그램, 그리고 유저 이다. 유저가 행하는 다양한 프로그래밍이 접근하는 프로그램은 컴파일러, 어셈블러, 텍스트 에디터, 데이터베이스 시스템 등 다양하다. 이러한 시스템 프로그래밍 혹은 어플리케이션 프로그래밍을 할때 운영체제와 통신하면, 운영체제가 대신 하드웨어에 접근하는 방식으로 구성되어 있다. 아래의 그림을 참고하자.</p><a id="more"></a><p><img src="https://user-images.githubusercontent.com/25416425/144545482-4253256d-cab3-4325-a2db-f55ddf99181e.png" alt="image"></p><p>공룡책의 저자는 운영체제를 정의함에 있어서 어떤 universally하게 받아들여지는 정의는 없다고 한다. 대신, 더 common한 정의를 가져왔는데, 이는 아래와 같다.</p><blockquote><p>The one program running at all times on the computer. Usually called the kernel.</p></blockquote><p>앞으로 우리는 운영체제에서 특히 <strong>kernel</strong>이라고 불리는 부분에서 어떠한 동작이 발생하는지에 대해서 주로 관심있게 공부할 것이다.</p><h2 id="컴퓨터-시스템-구조"><a href="#컴퓨터-시스템-구조" class="headerlink" title="컴퓨터 시스템 구조"></a>컴퓨터 시스템 구조</h2><p>현대 컴퓨터 시스템은 하나 이상의 CPU를 가지고 있으며, 다양한 장치 컨트롤러들이 common bus를 통해 연결되어 있다. 아래의 그림을 참고하자. disk에는 HDD와 SSD가 사용되며, 마우스 키보드와 같은 Input 장치들과 프린터 모니터와 같은 Output 장치들 또한 메모리와 연결되어 있다.</p><p><img src="https://user-images.githubusercontent.com/25416425/144707234-af49bba4-5ba2-47e8-a239-393f2e8e02c1.png" alt="image"></p><h3 id="Bootstrap"><a href="#Bootstrap" class="headerlink" title="Bootstrap"></a>Bootstrap</h3><p>컴퓨터의 전원을 켜는 것을 우리는 부팅 한다고 표현한다. 이 때 컴퓨터를 동작시키는 프로그램이 바로 bootstrap 이라는 프로그램인데, 해당 프로그램이 해야할 역할은 당연하게도 OS를 불러와서 메모리에 로드하는 것이다. 그렇다면 bootstrap program은 어디에 저장되어 있을까? 휘발성 메모리에 부팅 시스템과 관련한 명령어들을 넣어 놓는다면, 부팅시마다 초기화 되기 때문에 큰일이 날 것이다. 그래서 이 중요한 프로그램은 <u>EEPROM과 같은 불휘발성 메모리에 저장된다.</u> 블휘발성 메모리는 전원이 끊어져도 기록된 데이터들이 소멸되지 않는 특성이 있다.</p><h3 id="Interrupts"><a href="#Interrupts" class="headerlink" title="Interrupts"></a>Interrupts</h3><p>CPU와 I/O devices 사이에 통신하는 방법 중의 하나가 바로 interrupts이다. 예를 들어서 우리가 키보드로 A라는 문자를 눌렀다고 하자. 이를 CPU에게 알려 주기 위해 transfer을 진행하고, CPU는 하던 일 (user process) 을 멈추고 이를 받아들인다. 이러한 매커니즘이 마치 CPU의 현재 동작을 방해하는 것처럼 이루어지므로 Interrupt라는 이름에 참 알맞다. 아래의 그림은 Interrupt가 발생하는 타임라인을 개략적으로 표현한 것이다. </p><p><img src="https://user-images.githubusercontent.com/25416425/144707547-e8235d42-3988-4240-8818-d65a6afd3164.png" alt="image"></p><p>이처럼 Interrupts는 하드웨어에 의해 언제든 유발될 수 있으며 동작 방식은 간단하다. CPU에 특정 시그널을 보내는 것이다.</p><h3 id="Storage-Device-Hierarchy"><a href="#Storage-Device-Hierarchy" class="headerlink" title="Storage Device Hierarchy"></a>Storage Device Hierarchy</h3><p>우리의 컴퓨터는 여러 종류의 저장 장치로 구성되어 있다. 프로그램의 목적에 따라 저장 장치를 활용하게 되는데, 예를 들어서 이전에 살펴본 Bootstrap은 RAM과 같은 휘발성 메모리에 저장되면 안될 것이다. 저장 장치들은 저장 용량과 엑세스 타임에 따라서 여러 개의 계층 구조를 가지고 있다. 아래의 그림을 참고하자.</p><p><img src="https://user-images.githubusercontent.com/25416425/144708062-e2074a9d-4944-4692-9298-19b5f1cb52d1.png" alt="image"></p><p>메인 메모리는 우리가 흔히 이야기하는 RAM이다. 여기까지가 휘발성 메모리. 그 바로 아래부터 비휘발성 메모리로, ssd와 hdd같은 저장 디스크들, 그리고 더 아래로 내려가면 광학 디스크와 마그네틱 테잎과 같은 저장 장치들이 있다. 상위 계층으로 갈수록 작은 저장 용량을 가지지만 속도가 매우 빨라진다. 가격도 비싸다..</p><h4 id="레지스터-Register"><a href="#레지스터-Register" class="headerlink" title="레지스터 (Register)"></a>레지스터 (Register)</h4><p>CPU 내에 위치한, 극히 소량의 데이터나 처리중인 중간 결과를 일시적으로 기억해 두는 고속의 전용 영역이며, 현재 수행하는 값을 기억한다. 그림 상 레지스터 위에 CPU가 있다고 이해하면 된다. </p><h4 id="캐시-Cache"><a href="#캐시-Cache" class="headerlink" title="캐시 (Cache)"></a>캐시 (Cache)</h4><p>CPU와 메모리 사이에 자주 쓰는 것을 가까운 곳에 저장하기 위해 사용하는 메모리.<br>메인 메모리에 있는 데이터를 캐시 메모리에 불러와 두고, CPU가 필요한 데이터를 캐시에서 먼저 찾도록 하면, 시스템 성능을 크게 향상시킬 수 있다.</p><blockquote><p><strong>레지스터와 캐시의 차이는?</strong><br>: <strong>캐시</strong>는 <u>CPU와 별도로 있는 저장 공간이며,</u> 메인 메모리와 CPU 간의 속도 차이를 극복하기 위한 것이다. 반면 <strong>레지스터</strong>는 <u>CPU 안에서 연산을 처리하기 위해</u>  데이터를 저장하는 공간이다.</p></blockquote><h3 id="I-O-Structures"><a href="#I-O-Structures" class="headerlink" title="I/O Structures"></a>I/O Structures</h3><p>아래 그림은 I/O 장치가 정보를 전달할때, CPU와 메모리에서 어떻게 동작하는지를 개략적으로 보여준다.</p><p><img src="https://user-images.githubusercontent.com/25416425/144708678-695e94d7-1aed-4049-b37a-5b4ba9d937a2.png" alt="image"></p><p>CPU에서 어떤 프로그램이 실행되면, 이는 캐시 메모리를 거쳐 메모리 영역의 명령어들과 데이터를 읽어온다. CPU가 I/O request를 device에 전달하면, device는 앞서 설명하였던 interrupt를 발생시키고, 이는 실행하고 있는 프로그램을 wait하게 하기도 한다. CPU의 연산이 불필요할 경우, device에서 직접 메모리로 정보를 주고받는 일종의 interrupt도 발생할 수 있는데 이를 <strong>Direct Memory Access (DMA)</strong> 라고 한다. 유튜브 동영상을 보는 것에 CPU가 열심히 계산할 필요는 없지 않을까? Network에서 데이터를 읽어서 그대로 모니터로 영상을 쏴주고, CPU는 가만히 있다가 사용자가 동영상을 멈춘다던지 뭔가 액션을 취할때만 연산을 해주면 더 효율적일 것이다.</p><h2 id="컴퓨터-시스템-아키텍쳐"><a href="#컴퓨터-시스템-아키텍쳐" class="headerlink" title="컴퓨터 시스템 아키텍쳐"></a>컴퓨터 시스템 아키텍쳐</h2><p>프로세서는 1개인데 코어가 여러 개 라는 것이 무엇을 의미할까? 쿼드코어를 넘어서서 8-코어 등의 용어를 우리는 많이 접해보았을 것이다. 아래의 개념을 먼저 짚고 넘어가자.</p><ul><li>CPU (Central Processing Unit): 명령어를 실행하는 하드웨어 장치. 중앙 처리 장치.</li><li>Processor : 기본적인 명령어들을 처리하는 논리회로. 일반적인 PC환경에서 프로세서와 CPU는 같은 개념으로 보아도 무방하다고 한다.</li><li>Core : 각종 연산을 하는 CPU의 핵심 요소. 하나의 프로세서 안에 4개의 코어가 있다는 것은 4명이 분담해서 일을 처리한다고 이해하면 된다. Core의 종류는 ARM, MIPS, x86 등의 ISA (Instruction Set Architecture) 로 구별된다.</li></ul><p><img src="https://user-images.githubusercontent.com/25416425/144709730-5fdb828d-9560-4247-8bd0-6c144ef5ac38.png" alt="image"></p><p>동일한 프로세서 칩에 여러 개의 코어가 있으면 멀티코어, 프로세서가 여려개 있으면 그게 바로 멀티프로세서 이다.</p><blockquote><p><strong>잠깐, ISA가 뭐지?</strong><br>: CPU가 인식해서 기능을 이해하고 실행할 수 있는 기계어 명령어들의 set을 의미한다. 사용자가 실행한 응용 어플리케이션은 하단에 존재하는 알고리즘, 프로그래밍 언어, 어셈블리어, 기계어 등 소프트웨어 파트를 거쳐서 하드웨어 파트로 넘어가게 되는데 이때 소프트웨어와 하드웨어의 중재 역할을 하는 부분이 바로 ISA이다. 다시 말하면 최하위 레벨의 프로그래밍 인터페이스로, 프로세서 (cpu)가 실행할 수 있는 모든 명령어들을 포함한다.</p></blockquote><h2 id="운영-체제의-실제-운영-방식"><a href="#운영-체제의-실제-운영-방식" class="headerlink" title="운영 체제의 실제 운영 방식"></a>운영 체제의 실제 운영 방식</h2><p>운영 체제는 두 가지 모드로 나누어 운영을 하게 되는데, 이를 <strong>user mode</strong>와 <strong>kernel mode</strong> 라고 한다.<br>user mode에서는 우리가 일반적으로 실행하는 프로그램들이 동작한다. 반면 kernel mode에서는 OS 코드를 실행한다. 이렇게 모드를 나누는 이유는, 유저가 혹시 잘못된 프로그램을 동작 시켰을 때 컴퓨터 전체의 동작이 망가지는 것을 대비하기 위함이다.</p><p><img src="https://user-images.githubusercontent.com/25416425/144710603-4510ced8-d344-485b-878b-fcbc6be50dca.png" alt="image"></p><p>위의 그림을 보면 kernel mode가 언제 등장하는지 이해할 수 있다. 유저 프로세스는 user mode에서 실행되고 있다. 이때 유저 프로세스가 system call이라는 방식으로 OS를 부르면, 이때 trap이 발생하면서 kernel mode로 진입된다. 그리고 system call이 수행된 후 다시 user mode로 리턴된다. 이러한 seperate mode 동작 방식으로 OS는 의도치 않은 동작을 하는 프로그램이 자칫 다른 프로그램이나 디바이스에 영향을 주는 것을 원천적으로 차단할 수 있는 것이다.</p><p>마지막으로, 운영 체제가 어떤 서비스를 제공하는지 그림으로 살펴본다. 뭐 그냥 중요한걸 다 한다고 볼 수 있다.<br>OS 없으면 못살어<del>~</del>~</p><p><img src="https://user-images.githubusercontent.com/25416425/144710798-4d768917-895f-4371-9a94-335cdede9a86.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;운영-체제의-정의&quot;&gt;&lt;a href=&quot;#운영-체제의-정의&quot; class=&quot;headerlink&quot; title=&quot;운영 체제의 정의&quot;&gt;&lt;/a&gt;운영 체제의 정의&lt;/h2&gt;&lt;p&gt;운영 체제 (Operating System)에 대해서 다시 정의를 짚어보고 넘어가자.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OS는 컴퓨터의 하드웨어를 manage하는 소프트웨어이다.&lt;/li&gt;
&lt;li&gt;OS는 컴퓨터 유저와 컴퓨터 하드웨어간의 매개 역할을 수행한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이해를 돕기 위해 우리는 컴퓨터 시스템이 어떻게 구성되어 있는지 알아야 한다. 크게 4가지 component로 구성되어 있는데, 하드웨어, 운영체제, 응용 프로그램, 그리고 유저 이다. 유저가 행하는 다양한 프로그래밍이 접근하는 프로그램은 컴파일러, 어셈블러, 텍스트 에디터, 데이터베이스 시스템 등 다양하다. 이러한 시스템 프로그래밍 혹은 어플리케이션 프로그래밍을 할때 운영체제와 통신하면, 운영체제가 대신 하드웨어에 접근하는 방식으로 구성되어 있다. 아래의 그림을 참고하자.&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅲ. CS Study" scheme="https://jeongwookie.github.io/categories/%E2%85%A2-CS-Study/"/>
    
      <category term="Operating System" scheme="https://jeongwookie.github.io/categories/%E2%85%A2-CS-Study/Operating-System/"/>
    
    
      <category term="cs" scheme="https://jeongwookie.github.io/tags/cs/"/>
    
      <category term="os" scheme="https://jeongwookie.github.io/tags/os/"/>
    
  </entry>
  
  <entry>
    <title>백준 2667번 - 단지번호붙이기</title>
    <link href="https://jeongwookie.github.io/2021/12/02/programming/codingtest/dfs&amp;bfs/2-baekjoon-2667/"/>
    <id>https://jeongwookie.github.io/2021/12/02/programming/codingtest/dfs&amp;bfs/2-baekjoon-2667/</id>
    <published>2021-12-02T08:33:28.000Z</published>
    <updated>2021-12-08T08:56:33.496Z</updated>
    
    <content type="html"><![CDATA[<p>코테 풀이들은 대부분 길어서 더보기 클릭을 하지 않으면 보이지 않도록 해당 문구를 추가합니다.</p><a id="more"></a><h2 id="백준-2667-단지번호붙이기"><a href="#백준-2667-단지번호붙이기" class="headerlink" title="백준 2667: 단지번호붙이기"></a>백준 2667: 단지번호붙이기</h2><p>문제 출처 : <a href="https://www.acmicpc.net/problem/2667" rel="external nofollow noopener noreferrer" target="_blank">https://www.acmicpc.net/problem/2667</a><br><img src="https://user-images.githubusercontent.com/25416425/144386584-c78c68dc-799e-495f-a92d-406ae9cb9cbd.png" alt="image"></p><h2 id="문제-설명"><a href="#문제-설명" class="headerlink" title="문제 설명"></a>문제 설명</h2><p>시작점을 잡고, 해당 점에서 인접한 동서남북을 dfs 또는 bfs로 방문하면서 count하는 문제<br>시작 가능한 점은 지도에서 1로 표시된 구역이고, 여기서 시작하여 인접한 곳을 탐색하면 자연스럽게 단지가 정의된다.<br>탐색 도중 지도 밖으로 나가는 경우를 제외시켜 주어야 한다. </p><h2 id="문제-풀이"><a href="#문제-풀이" class="headerlink" title="문제 풀이"></a>문제 풀이</h2><p>[1] DFS<br>: 해당 좌표의 값이 1인 지점에서 시작하여 깊이 우선 탐색으로 단지를 정의할 수 있다. 재귀적으로 모든 인접한 구간을 방문한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">[풀이 논리]</span><br><span class="line"><span class="number">1.</span> 해당 좌표가 지도 밖이면 <span class="literal">False</span></span><br><span class="line"><span class="number">2.</span> 해당 좌표에 집이 없으면 <span class="literal">False</span></span><br><span class="line"><span class="number">3.</span> 해당 좌표에 집이 있는 경우, 글로벌 변수인 house_count를 <span class="number">1</span> 올려주고,</span><br><span class="line"><span class="number">4.</span> 해당 좌표값을 <span class="number">0</span>으로 만들어줌 (다시 방문하지 않기 위해)</span><br><span class="line"><span class="number">5.</span> 그리고 상하좌우로 dfs를 수행하여 방문함</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(i,j)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> i&lt;<span class="number">0</span> <span class="keyword">or</span> i&gt;N<span class="number">-1</span> <span class="keyword">or</span> j&lt;<span class="number">0</span> <span class="keyword">or</span> j&gt;N<span class="number">-1</span>: <span class="comment"># 지도 밖으로 나가면 False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> array[i][j] == <span class="number">0</span>: <span class="comment"># 집이 없으면 False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>: <span class="comment"># 집이 있는 경우 True</span></span><br><span class="line">        array[i][j] = <span class="number">0</span> <span class="comment"># 방문 후 0으로 만듬</span></span><br><span class="line">        <span class="keyword">global</span> house_count</span><br><span class="line">        house_count += <span class="number">1</span> <span class="comment"># 글로별 변수에 해당 count를 누적시킴</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> range(<span class="number">4</span>): <span class="comment"># 인접한 곳을 재귀적으로 방문</span></span><br><span class="line">            nx, ny = i + dx[idx], j + dy[idx]</span><br><span class="line">            dfs(nx, ny)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">import</span> sys; readline = sys.stdin.readline</span><br><span class="line">    N = int(readline().strip())</span><br><span class="line">    array = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(N):</span><br><span class="line">        array.append([int(i) <span class="keyword">for</span> i <span class="keyword">in</span> readline().strip()])</span><br><span class="line"></span><br><span class="line">    dx = [<span class="number">-1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    dy = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">1</span>]</span><br><span class="line">    house_count, total_count = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    ans = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(N):</span><br><span class="line">            <span class="keyword">if</span> dfs(i,j): <span class="comment"># dfs의 결과가 True인 경우 : (i,j)가 시작점 일때</span></span><br><span class="line">                ans.append(house_count)</span><br><span class="line">                house_count = <span class="number">0</span>  <span class="comment"># 단지가 종료되었으므로 초기화</span></span><br><span class="line">                total_count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 결과 프린트</span></span><br><span class="line">    print(total_count)</span><br><span class="line">    [print(i) <span class="keyword">for</span> i <span class="keyword">in</span> sorted(ans)]</span><br></pre></td></tr></table></figure></p><p>[2] BFS<br>: 해당 좌표의 값이 1인 지점에서 시작하여 넓이 우선 탐색으로 단지를 정의할 수 있다. 큐를 사용하여 인접한 좌표를 한번에 탐색한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> 집이 없는 곳은 방문하지 않음</span><br><span class="line"><span class="number">2.</span> 집이 있는 경우, queue를 만들고 방문 처리 후 반복문을 셋팅함</span><br><span class="line"><span class="number">3.</span> 반복문을 돌면서, 해당 좌표와 인접한 곳을 다 돌면서 확인함</span><br><span class="line"><span class="number">4.</span> 지도 밖을 넘어가지 않고, 해당 인접 좌표에 집이 있는 경우 houst_count를 올려줌.</span><br><span class="line"><span class="number">5.</span> 총 house_count를 리턴함. <span class="number">0</span>인 경우는 하나도 방문 못한 것이기 때문에 단지가 아님.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bfs</span><span class="params">(i,j)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> array[i][j] == <span class="number">0</span>: <span class="comment"># 집이 없으면 False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    queue = deque([[i,j]]) <span class="comment"># 큐에 방문 좌표 넣기</span></span><br><span class="line">    array[i][j] = <span class="number">0</span> <span class="comment"># 방문 처리</span></span><br><span class="line">    house_count = <span class="number">1</span> <span class="comment"># 현재 방문한 곳부터 세어야 함.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> queue:</span><br><span class="line">        x, y = queue.popleft()</span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">            nx, ny = x + dx[idx], y + dy[idx]</span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span>&lt;=nx&lt;N <span class="keyword">and</span> <span class="number">0</span>&lt;=ny&lt;N: <span class="comment"># 지도 밖을 넘어가지 않고,</span></span><br><span class="line">                <span class="keyword">if</span> array[nx][ny] == <span class="number">1</span>: <span class="comment"># 해당 좌표에 집이 있는 경우</span></span><br><span class="line">                    queue.append([nx,ny]) <span class="comment"># 큐에 넣기</span></span><br><span class="line">                    array[nx][ny] = <span class="number">0</span> <span class="comment"># 방문 처리</span></span><br><span class="line">                    house_count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> house_count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">import</span> sys; readline = sys.stdin.readline</span><br><span class="line">    <span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line">    N = int(readline().strip())</span><br><span class="line">    array = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(N):</span><br><span class="line">        array.append([int(i) <span class="keyword">for</span> i <span class="keyword">in</span> readline().strip()])</span><br><span class="line"></span><br><span class="line">    dx = [<span class="number">-1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    dy = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">1</span>]</span><br><span class="line">    total_count = <span class="number">0</span></span><br><span class="line">    ans = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(N):</span><br><span class="line">            result = bfs(i,j)</span><br><span class="line">            <span class="keyword">if</span> result:</span><br><span class="line">                ans.append(result)</span><br><span class="line">                total_count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 결과 프린트</span></span><br><span class="line">    print(total_count)</span><br><span class="line">    [print(i) <span class="keyword">for</span> i <span class="keyword">in</span> sorted(ans)]</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;코테 풀이들은 대부분 길어서 더보기 클릭을 하지 않으면 보이지 않도록 해당 문구를 추가합니다.&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅱ. Programming" scheme="https://jeongwookie.github.io/categories/%E2%85%A1-Programming/"/>
    
      <category term="코딩 테스트 문제 풀이" scheme="https://jeongwookie.github.io/categories/%E2%85%A1-Programming/%EC%BD%94%EB%94%A9-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%AC%B8%EC%A0%9C-%ED%92%80%EC%9D%B4/"/>
    
      <category term="DFS와 BFS" scheme="https://jeongwookie.github.io/categories/%E2%85%A1-Programming/%EC%BD%94%EB%94%A9-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%AC%B8%EC%A0%9C-%ED%92%80%EC%9D%B4/DFS%EC%99%80-BFS/"/>
    
    
      <category term="Python" scheme="https://jeongwookie.github.io/tags/Python/"/>
    
      <category term="Codingtest" scheme="https://jeongwookie.github.io/tags/Codingtest/"/>
    
      <category term="Baekjoon" scheme="https://jeongwookie.github.io/tags/Baekjoon/"/>
    
      <category term="DFS&amp;BFS" scheme="https://jeongwookie.github.io/tags/DFS-BFS/"/>
    
  </entry>
  
  <entry>
    <title>OS공부 - 인트로</title>
    <link href="https://jeongwookie.github.io/2021/11/30/computerscience/operatingsystem/1-intro/"/>
    <id>https://jeongwookie.github.io/2021/11/30/computerscience/operatingsystem/1-intro/</id>
    <published>2021-11-30T07:18:33.000Z</published>
    <updated>2021-11-30T07:29:20.857Z</updated>
    
    <content type="html"><![CDATA[<p>운영 체제 과목을 본격적으로 들어가기 전, 인트로적인 내용을 정리했다.</p><p>운영 체제 (Operating System)는 컴퓨터 시스템을 운영하는 소프트웨어를 의미한다. 그러면 컴퓨터는 무엇인가? 무엇을 보고 컴퓨터라고 하나?<br>컴퓨터의 정의는 다음과 같이 되어 있다.</p><blockquote><p>A machine that processes the information</p></blockquote><a id="more"></a><p>즉, 정보를 처리하는 기계가 컴퓨터라는 것이다. 그러면 또 꼬리에 꼬리를 무는 질문이 있다. 정보란 무엇인가? 정보의 단위도 있는가?<br>다행히, 섀넌 선생님이 이에 대한 답을 마련해두었는데 이는 다음과 같다.<br>어떤 사건 x에 대해서 해당 사건의 정보량 I는, 해당 사건이 발생한 확률에 밑이 2인 로그를 취한 값의 negative로 하자!</p><p>이게 뭔소리냐, 일반적인 주사위를 상상해보자. 주사위는 1부터 6까지 나올 수 있다.<br>주사위를 하늘 위로 던졌다! 아직 뭐가 나올지 모르는 상황이고 사건은 발생하지 않았다. 이때 정보량은 없다.<br>주사위가 땅에 도달했다. 보니까 3이 나왔네? 이런 사건이 발생했고 이걸 나만 안다고 생각해보자.<br>이제 이 정보를 타인에게 전달해 주고 싶다. 이때, 전달되는 정보량이 얼마인가?<br>주사위를 던져서 3이 나올 확률은 알다시피 1/6이다. 섀넌의 정의에 따라서, 해당 값에 로그를 취하고 음수를 붙여주면 밑이 2인 log6이 바로 정보량이 된다. 이렇게 어떤 정보에 대해서 전달을 하고 싶을때는 반드시 해당 정보에 대한 quantitative한 정의가 동반되어야 한다. 컴퓨터는 정보를 처리하는 기계니깐..</p><p>이번에는 주사위가 아니라 동전을 던진다고 생각해보자. 동전은 앞과 뒤 이렇게 두가지 사건만 발생할 수 있고, 만약 사건 X가 동전의 앞이 나왔다고 정의되었을 때, 우리는 해당 정보의 전달량을 앞선 주사위의 예와 마찬가지로 계산할 수 있다. 밑이 2인 로그와 음수를 1/2에 취해주면…!! 1이 나왔다!</p><p>도량형을 정의할 때 해당 단위의 1을 어떤 기준으로 정의할 것인지는 대단히 중요한 문제이다. 우리는 이미 앞선 예로 정보량이 1이라는 것에 대해서 어떤 느낌인지 알았다. 바로 이것이 정보의 최소 단위인 <code>1 bit</code>을 정의하는 방식이다. bit은 binary digit의 약자이다.</p><p>그러면 이를 확장하면, 2비트는 동전 두개로 8비트는 동전 8개로 나타낼 수 있는 정보라고 이해할 수 있다. 8비트의 해당 가짓수는 2의 8승으로 이를 <code>1 byte</code>로 정의한다. 이런식으로 우리가 아는 1 메가바이트, 1 기가바이트, 1 테레바이트 등을 모두 이해할 수 있다.<br><img src="https://user-images.githubusercontent.com/25416425/144003917-54e6c816-19e3-4918-a04d-9f67172d1c59.png" alt="image"></p><p>자 정보의 단위는 알았다. 그러면 구체적으로 컴퓨터가 정보를 어떻게 처리하는지 궁금해진다. <strong>“정보의 처리”</strong> 라는 것은 정보의 상태를 0에서 1로 또는 1에서 0으로 바꾸는 것을 의미한다. 이는 NOT, AND, OR, XOR, NAND, NOR 이 여섯가지 논리 게이트를 통해서 이루어지는데 얘들을 집적 시켜서 바로 그 논리 회로를 만든다. 논리 게이트를 계속 집적시켜서 논리 회로가 점점 더 빽빽해지고 컴퓨터의 정보 처리 능력이 비약적으로 향상되는 것이다. 여기서 꼭 나오는 법칙이 있는데 그 유명한 무어의 법칙과 황의 법칙이다. </p><ul><li>무어의 법칙 : 집적도가 1년 6개월마다 두배씩 늘어남</li><li>황의 법칙 : 메모리가 1년에 두배씩 늘어남<br>해당 법칙들 까지만 이해하고, 실제로 정보를 산술연산 하는 방법이라던가 하는것은 컴퓨터 시스템 과목에서 상세하게 다루고 있기 때문에 넘어간다.</li></ul><p>그러면 이제 다시 컴퓨터로 돌아가자. 폰 노이만이 현대적 컴퓨터의 아버지라고 불리우는데, 그 이유는 그가 stored-program 방식의 컴퓨터를 설계했기 때문이다. 이게 뭐냐하면, 메모리에 프로그램을 저장해 놓고 쓰는 컴퓨터를 의미한다. 우리가 현재 사용하는 컴퓨터의 형태 아닌가! 이제 드디어 프로그램을 정의하는 단계까지 왔다.</p><p>프로그램이란, a set of instructions이다. 컴퓨터에게 어떤 task를 실행시키는 명령어들의 집합이 바로 프로그램인 것이다. 우리가 어떤 의도를 가지고 작성한 소스코드가 바로 프로그램이다. 이를 컴파일러가 컴파일하여 어셈블리어 단계를 지나 기계어로 번환되면 이는 곧 0과 1로 표현된 정보 이다. 우리는 중간 단계인 어셈블리어의 명령어를 보고 하드웨어가 어떻게 정보를 처리하고 있는지 파악할 수 있다.</p><p>프로그램이 무엇인지에 대해서 정의하였으니, 마지막으로 운영체제의 정의로 돌아가자.<br>운영체제는 컴퓨터에서 올타임으로 돌아가고 있는 프로그램이다. 구체적으로, 운영체제는 시스템 서비스들을 어플리케이션 프로그램에 제공해주는 역할을 수행하는데 이는 마치 API와 비슷하다. 사용자가 하드웨어를 직접 제어하지 않고 OS에 제어를 특정한 방법으로 요청하면, 이를 OS가 대신 처리해 주는 셈이다. 프로세스, 리소스, 유저 인터페이스 등을 관리하는 주체가 바로 운영체제! </p><h2 id="요약"><a href="#요약" class="headerlink" title="요약"></a>요약</h2><ul><li>1 bit는 0과 1 두가지 값만 가질 수 있는 측정 단위이다.</li><li>1 byte는 8개의 bit로 구성된 데이터의 양을 나타내는 단위이다.</li><li>무어의 법칙 : 회로의 집적도가 1년 6개월에 2배씩 늘어남</li><li>프로그램이란, 명령어들의 집합이다.</li><li>운영체제란, 시스템 콜과 같은 방법으로 사용자가 요청하면 이를 처리하여 하드웨어를 제어하는 기저 프로그램이라 할 수 있다.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;운영 체제 과목을 본격적으로 들어가기 전, 인트로적인 내용을 정리했다.&lt;/p&gt;
&lt;p&gt;운영 체제 (Operating System)는 컴퓨터 시스템을 운영하는 소프트웨어를 의미한다. 그러면 컴퓨터는 무엇인가? 무엇을 보고 컴퓨터라고 하나?&lt;br&gt;컴퓨터의 정의는 다음과 같이 되어 있다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A machine that processes the information&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Ⅲ. CS Study" scheme="https://jeongwookie.github.io/categories/%E2%85%A2-CS-Study/"/>
    
      <category term="Operating System" scheme="https://jeongwookie.github.io/categories/%E2%85%A2-CS-Study/Operating-System/"/>
    
    
      <category term="cs" scheme="https://jeongwookie.github.io/tags/cs/"/>
    
      <category term="os" scheme="https://jeongwookie.github.io/tags/os/"/>
    
  </entry>
  
  <entry>
    <title>백준 1260번 - DFS와 BFS</title>
    <link href="https://jeongwookie.github.io/2021/11/29/programming/codingtest/dfs&amp;bfs/1-baekjoon-1260/"/>
    <id>https://jeongwookie.github.io/2021/11/29/programming/codingtest/dfs&amp;bfs/1-baekjoon-1260/</id>
    <published>2021-11-29T08:13:38.000Z</published>
    <updated>2021-11-30T05:55:40.525Z</updated>
    
    <content type="html"><![CDATA[<p>코테 풀이들은 대부분 길어서 더보기 클릭을 하지 않으면 보이지 않도록 해당 문구를 추가합니다.</p><a id="more"></a><h2 id="백준-1260-DFS와-BFS"><a href="#백준-1260-DFS와-BFS" class="headerlink" title="백준 1260: DFS와 BFS"></a>백준 1260: DFS와 BFS</h2><p>문제 출처 : <a href="https://www.acmicpc.net/problem/1260" rel="external nofollow noopener noreferrer" target="_blank">https://www.acmicpc.net/problem/1260</a><br><img src="https://user-images.githubusercontent.com/25416425/143832293-337679f4-5b35-48b9-9a88-0cd132ccf1bf.png" alt="image"></p><h2 id="문제-설명"><a href="#문제-설명" class="headerlink" title="문제 설명"></a>문제 설명</h2><p>DFS와 BFS를 구현할 수 있는지 물어보는 직관적인 문제.<br>인풋을 받아서 적절한 graph 형태로 저장한 후, 이를 각각의 방식으로 순회하면서 출력하면 끝.<br><strong>어떤 두 정점 사이에 여러 개의 간선이 있을 수 있음</strong>에 주의하자.<br>큐나 스택을 활용할 때는 <code>from collections import deque</code>를 사용한다.</p><h2 id="문제-풀이"><a href="#문제-풀이" class="headerlink" title="문제 풀이"></a>문제 풀이</h2><p>[1] DFS<br>: 스택이나 재귀함수로 구현할 수 있다. 아래와 같은 플로우로 구현한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[Recursive하게 구현하기]</span><br><span class="line"><span class="number">1.</span> 시작점을 먼저 방문 처리 후 해당 노드 출력</span><br><span class="line"><span class="number">2.</span> 인접 노드를 탐색하는데,</span><br><span class="line"><span class="number">3.</span> 해당 노드를 방문한 적이 없다면,</span><br><span class="line"><span class="number">4.</span> 재귀적으로 해당 노드를 방문함.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(graph, v, visited)</span>:</span></span><br><span class="line">    visited[v] = <span class="literal">True</span></span><br><span class="line">    print(v, end=<span class="string">' '</span>) <span class="comment"># 방문 처리한 노드를 출력</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> near_v <span class="keyword">in</span> graph[v]: <span class="comment"># 인접 노드에 대해서</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> visited[near_v]: <span class="comment"># 해당 노드를 방문한 적이 없다면,</span></span><br><span class="line">            dfs(graph, near_v, visited) <span class="comment"># 재귀적으로 방문함</span></span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[stack으로 구현하기]</span><br><span class="line"><span class="number">1.</span> stack을 만들고 시작점을 삽입</span><br><span class="line"><span class="number">2.</span> <span class="keyword">while</span>문을 써서 stack이 빌때까지 반복</span><br><span class="line"><span class="number">3.</span> 방문할 노드를 pop()을 통해 뽑음</span><br><span class="line"><span class="number">4.</span> 해당 노드를 방문한 적이 없다면, 방문 처리하고</span><br><span class="line"><span class="number">5.</span> 인접 노드를 stack에 extend()한다.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span><span class="params">(graph, v, visited)</span>:</span></span><br><span class="line">    stack = deque([v]) <span class="comment"># stack에 시작점을 삽입</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> stack: <span class="comment"># stack이 빌 때까지 반복</span></span><br><span class="line">        visiting_node = stack.pop() <span class="comment"># stack에서 방문할 노드 선택</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> visited[visiting_node]: <span class="comment"># 해당 노드를 방문한 적이 없다면,</span></span><br><span class="line">            visited[visiting_node] = <span class="literal">True</span> <span class="comment"># 방문 처리</span></span><br><span class="line">            print(visiting_node, end=<span class="string">' '</span>) <span class="comment"># 방문 완료한 노드 출력</span></span><br><span class="line">            stack.extend(sorted(graph[visiting_node], reverse=<span class="literal">True</span>)) <span class="comment"># 인접 노드를 stack에 넣는데 문제의 조건때문에 sort</span></span><br></pre></td></tr></table></figure><p>[2] BFS<br>: 큐를 통해 구현할 수 있다. 아래와 같은 플로우로 구현한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[Queue를 통해 구현하기]</span><br><span class="line"><span class="number">1.</span> Queue를 만들고 시작점을 삽입 후</span><br><span class="line"><span class="number">2.</span> 해당 노드를 방문 처리함.</span><br><span class="line"><span class="number">3.</span> <span class="keyword">while</span>문을 사용하여 큐가 빌때까지 반복하는데,</span><br><span class="line"><span class="number">4.</span> 큐에서 이미 방문한 노드를 뽑고, 해당 노드에 대해서 인접한 노드를 전부 방문하는데</span><br><span class="line"><span class="number">5.</span> 인접 노드를 방문한 적이 없다면,</span><br><span class="line"><span class="number">6.</span> 해당 인접 노드를 큐에 넣고 방문 처리한다. (핵심)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bfs</span><span class="params">(graph, v, visited)</span>:</span></span><br><span class="line">    queue = deque([v]) <span class="comment"># queue에 시작점을 삽입후</span></span><br><span class="line">    visited[v] = <span class="literal">True</span> <span class="comment"># 해당 노드를 방문 처리</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> queue: <span class="comment"># queue가 빌 때까지 반복</span></span><br><span class="line">        visited_node = queue.popleft()</span><br><span class="line">        print(visited_node, end=<span class="string">' '</span>) <span class="comment"># 방문 완료한 노드를 출력</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> near_v <span class="keyword">in</span> graph[visited_node]: <span class="comment"># 인접 노드에 대해서</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> visited[near_v]: <span class="comment"># 해당 노드를 방문한 적이 없다면</span></span><br><span class="line">                queue.append(near_v) <span class="comment"># 인접 노드를 queue에 넣고</span></span><br><span class="line">                visited[near_v] = <span class="literal">True</span> <span class="comment"># 해당 노드를 방문 처리</span></span><br></pre></td></tr></table></figure></p><h2 id="제출"><a href="#제출" class="headerlink" title="제출"></a>제출</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># main.py</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">import</span> sys; readline = sys.stdin.readline</span><br><span class="line">    <span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line">    N, M, V = map(int, readline().split()) <span class="comment"># 정점 갯수, 간선 갯수, 탐색 시작 정점 번호</span></span><br><span class="line">    graph = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> range(N+<span class="number">1</span>)] <span class="comment"># 0번 인덱스를 버리기 위해 1 추가</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(M):</span><br><span class="line">        v1, v2 = map(int, readline().split())</span><br><span class="line">        graph[v1].append(v2)</span><br><span class="line">        graph[v2].append(v1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 정점 번호가 작은 것을 먼저 방문하기 위해 sort</span></span><br><span class="line">    graph = [sorted(_list) <span class="keyword">for</span> _list <span class="keyword">in</span> graph]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># DFS</span></span><br><span class="line">    visited = [<span class="literal">False</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(N + <span class="number">1</span>)]</span><br><span class="line">    dfs(graph, V, visited)</span><br><span class="line">    print()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># BFS</span></span><br><span class="line">    visited = [<span class="literal">False</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(N + <span class="number">1</span>)]</span><br><span class="line">    bfs(graph, V, visited)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;코테 풀이들은 대부분 길어서 더보기 클릭을 하지 않으면 보이지 않도록 해당 문구를 추가합니다.&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅱ. Programming" scheme="https://jeongwookie.github.io/categories/%E2%85%A1-Programming/"/>
    
      <category term="코딩 테스트 문제 풀이" scheme="https://jeongwookie.github.io/categories/%E2%85%A1-Programming/%EC%BD%94%EB%94%A9-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%AC%B8%EC%A0%9C-%ED%92%80%EC%9D%B4/"/>
    
      <category term="DFS와 BFS" scheme="https://jeongwookie.github.io/categories/%E2%85%A1-Programming/%EC%BD%94%EB%94%A9-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%AC%B8%EC%A0%9C-%ED%92%80%EC%9D%B4/DFS%EC%99%80-BFS/"/>
    
    
      <category term="Python" scheme="https://jeongwookie.github.io/tags/Python/"/>
    
      <category term="Codingtest" scheme="https://jeongwookie.github.io/tags/Codingtest/"/>
    
      <category term="Baekjoon" scheme="https://jeongwookie.github.io/tags/Baekjoon/"/>
    
      <category term="DFS&amp;BFS" scheme="https://jeongwookie.github.io/tags/DFS-BFS/"/>
    
  </entry>
  
  <entry>
    <title>2021년의 근황</title>
    <link href="https://jeongwookie.github.io/2021/11/14/others/diary/8-my-recent-days-in-2021/"/>
    <id>https://jeongwookie.github.io/2021/11/14/others/diary/8-my-recent-days-in-2021/</id>
    <published>2021-11-14T12:14:29.000Z</published>
    <updated>2021-12-06T09:25:11.406Z</updated>
    
    <content type="html"><![CDATA[<p>블로그를 오랜만에 접속했습니다.<br>18년도에 블로그를 만들었을 때, 꾸준히 한달에 한번이라도 글을 쓰자 생각했었는데 지켜지지 않았네요 ㅠ.ㅠ<br>2020년의 나와 현재의 나를 비교하면서 되돌아보니 생각보다 이것저것 바뀐 것이 있습니다. 물론 시간이 너무 빨리 지나가는 것 같은 생각은 항상 하지만요.</p><a id="more"></a><p>현재 저는 분당에 있는 티맥스소프트에서 전문연구요원을 하고 있습니다. 시작한지 벌써 1년이 지났네요…<br>그 사이에 훈련소도 다녀오고, 훈련소 다녀온 시점부터 현재까지 약 7개월 이상 꾸준하게 헬스를 하고 있습니다.<br>과거에 저는 헬스를 정말 싫어하던 사람이더라구요 옛날 글들을 보니까 ㅋㅋㅋ 지금은 사람이 뭘 잘못먹었나 싶을 정도로 헬스에 집착(?)하고 있습니다. 운동 한번 제대로 시작해보자 생각하고 꾸준하게 생활로 가져가니까 되긴 되더라구요. 식단도 관리 하면서 주에 5~6회 헬스장에 퇴근하고 반드시 갑니다.</p><p>블로그를 다시 시작할려고 생각한 이유는, 회사에 익숙해지고 분당이란 곳에 충분히 익숙해졌다고 생각했기 때문입니다. 이제 또 다른 도약을 진지하게 준비해야 하는 시점이라고 생각이 들었어요. (사실 위기감입니다 이렇게 살아도 되나 현자타임이 강하게 왔습니다;;;)</p><p>저의 다음 스텝에 대한 진지한 고민을 병행하면서, 일단은 방향을 Data Scientist / ML Engineer 로 잡았습니다. 그리고 더 늦기 전에 Computer Science 교과목들을 제대로 짚고 넘어가야겠다고 생각했습니다. 이쪽 분야로 계속 들어가려면 CS공부는 필수적이고, 앒게 공부한 분들이나 학부때부터 전공했음에도 불구하고 당시 수업때 많이 놀아서(?) 까먹음을 후회하는 개발자들을 많이 보았습니다. 회사 다니면서 시간 쪼개서 공부하는 것이 쉽지는 않겠지만, 이직을 하고 더 deep dive하게 되면 점점 더 시간이 없어서 결국은 못하게 되지 않을까 하는 생각입니다.</p><p>다른 학부때부터 전공자들에 비해서 확실히 부족한 부분들이 있다는 점이 제 마음에 계속 응어리처럼 남아있었습니다. 회사에서 갑자기 java로 백엔드 서비스 개발을 맡았을 때도, DB에 대한 이해가 부족하여서 계속 구글링하거나 물어보는 수 밖에 없었죠 ㅠㅠ 이걸 해결하지 못하면, 운좋게 어디 다른 좋은 회사에 이직하게 된다 하더라도 결국은 끝에 가서 발목을 잡을 것 같습니다.</p><p>잡설이 길었는데, 이런 여러가지 생각으로 공부를 시작했고 공부한 내용들을 복습하기 위해 블로그에 기록을 하자는게 취지입니다. 덤으로 코테 문제들을 안풀어본지 대단히 오래되어서;;;; 이직을 하는데 문제가 있을 것이라 판단하여서 기본부터 다시 매일 조금씩 풀기로 결정했습니다. 요것도 복습이 필요한 문제의 경우에는 포스팅을 약간씩 해보려구요 :)</p><p>거품 다 빼고, 프로그래밍적 마인드 부터 알고리즘, 자료구조, 컴퓨터시스템, 운영체제, 네트워크, 데이터베이스 등 CS과목들을 쭉 다 읽을 계획을 가지고 있습니다. 주로 관련 전공서 읽기 + 해외 유명 대학 수업듣고 lab session 수행하는 방법으로 마치 다시 대학교 가서 수업 듣는 것처럼 생각하고 진행할 것 같아요.</p><p>구체적인 CS 공부 커리큘럼, 이직을 위한 준비 등 이런 정보들도 제가 마음을 다잡는 겸 포스팅 할수도 있습니다 ㅎㅎ 이직이 끝나면 할수도 있구요. 일단은 공부부터, 코드부터 짜고 해보겠습니다. 안녕.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;블로그를 오랜만에 접속했습니다.&lt;br&gt;18년도에 블로그를 만들었을 때, 꾸준히 한달에 한번이라도 글을 쓰자 생각했었는데 지켜지지 않았네요 ㅠ.ㅠ&lt;br&gt;2020년의 나와 현재의 나를 비교하면서 되돌아보니 생각보다 이것저것 바뀐 것이 있습니다. 물론 시간이 너무 빨리 지나가는 것 같은 생각은 항상 하지만요.&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅹ. Others" scheme="https://jeongwookie.github.io/categories/%E2%85%A9-Others/"/>
    
      <category term="일기" scheme="https://jeongwookie.github.io/categories/%E2%85%A9-Others/%EC%9D%BC%EA%B8%B0/"/>
    
    
      <category term="Daily life" scheme="https://jeongwookie.github.io/tags/Daily-life/"/>
    
  </entry>
  
  <entry>
    <title>트위터 파헤치기 시리즈 두번째 - 한국어 전처리</title>
    <link href="https://jeongwookie.github.io/2020/04/29/datascience/twitter/3-analyze-tweet-series-2-preprocessing/"/>
    <id>https://jeongwookie.github.io/2020/04/29/datascience/twitter/3-analyze-tweet-series-2-preprocessing/</id>
    <published>2020-04-29T07:51:49.000Z</published>
    <updated>2021-11-21T11:21:46.905Z</updated>
    
    <content type="html"><![CDATA[<p>트위터 파헤치기 두번째 시리즈의 주제는 <strong>한국어 전처리</strong> 이다.<br>단순히 LDA 토픽 모델링을 하는 것에서부터 딥러닝 모델을 훈련시키는 것 까지 NLP와 관련된 전 과정에서 전처리는 필수적이다.<br>텍스트 데이터의 특성상 기본적으로 노이즈 (noise)가 많은 데이터에 속하기 때문이다. 다음과 같은 과정을 보통 진행한다.</p><ul><li>Tokenization : 문장을 하나의 기준을 가지고 자르는 것 (안녕하세요 -&gt; 안녕 / 하세요)</li><li>Stemming : 동사 및 형용사 등의 활용 형태를 원문으로 바꾸는 것 (잼따 -&gt; 재미 이다)</li><li>Noramlization : 표기가 다른 단어들을 통합하는 것 (입니닼ㅋㅋ -&gt; 입니다 ㅋㅋ)</li><li>Noise removal : 문장의 의미를 이해하는 데에 불필요한 부분을 제거하는 것 (특수문자, url 등)</li></ul><p>영어의 경우 <code>nltk</code> 라는 강력한 파이썬 패키지가 존재하여, 대부분의 우리가 원하는 전처리 함수들이 구현되어 있다.<br>그러나 한국어의 경우 Tokenization의 단위가 단어인지, 형태소인지, 자모인지, 아니면 그 외인지조차 아직까지 불명확한 부분이 있다. (현재도 연구중)<br>또한, Normalization이나 Stemming의 경우에도 <code>Konlpy</code>에 최근 포함된 <code>Okt</code> 클래스가 지원하지만 써본 결과 영어만큼 완벽하지는 않다.</p><p>그래서 본 포스트에서는 제일 general 한 토크나이저인 <code>Mecab</code>을 사용해서 그나마 reasonable한 방향으로 한국어 전처리를 진행해 보고자 한다. 현재도 계속 연구중이므로 완벽한 방법은 아니라는 것에 유의하자.</p><p><img src="https://user-images.githubusercontent.com/25416425/80573175-742c0680-8a3a-11ea-9a8d-940a8215b879.png" width="500"></p><a id="more"></a><h2 id="토크나이저-설치하기"><a href="#토크나이저-설치하기" class="headerlink" title="토크나이저 설치하기"></a>토크나이저 설치하기</h2><p>전처리를 시작하기 전, base 도구가 될 토크나이저 선정 및 설치는 필수적이다.<br>다양한 토크나이저가 있지만, 속도가 빠르고 비문에서도 적당히 잘 동작하는 <code>Mecab</code> 패키지를 본 포스트에서는 사용할 것이다.<br><code>Khaiii</code> 또는 <code>Soynlp</code>와 같은 최신 한국어 대응 패키지들을 사용하여도 무방하다.<br>심지어 한국어가 아닌 다른 나라 언어 (예: 이란어)를 전처리 하고 싶을 때에도 아래의 로직은 그대로 활용할 수 있다. 적절한 토크나이저만 선택해서 설치하자.</p><p>우리가 사용할 <code>Mecab</code>은 <a href="https://bitbucket.org/eunjeon/mecab-ko-dic/src/master/" rel="external nofollow noopener noreferrer" target="_blank">공식 홈페이지</a>에서 설치 방법을 확인할 수 있다. 상세한 설치 방법은 여기서는 다루지 않겠다. 총 3가지의 설치 과정을 모두 진행해야 한다는 것만 유의하자. </p><ul><li>Mecab-ko 설치하기 (source)</li><li>Mecab-ko-dic 설치하기 (사전)</li><li>Mecab-python3 설치하기 (파이썬 연동)</li></ul><p>포스트를 적는 도중 나 대신 <code>Mecab</code> 설치 방법에 대해 자세히 적어놓은 블로그를 발견했다. <a href="https://lsjsj92.tistory.com/491" rel="external nofollow noopener noreferrer" target="_blank">이수진 님의 블로그 - Mecab 설치</a> 을 참고해도 괜찮을 것 같다.</p><p>설치 완료 후 주피터 노트북에서 동작을 확인하자. 혹시나 <code>Konlpy</code>를 설치하지 않은 사용자라면 이 패키지는 한국어 처리의 기본이니 설치해 놓자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> konlpy.tag <span class="keyword">import</span> Mecab </span><br><span class="line"></span><br><span class="line">m = Mecab()</span><br><span class="line">m.pos(<span class="string">"일등이 아니여도 괜찮아"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print out</span></span><br><span class="line">&gt;&gt; [(<span class="string">'일등'</span>, <span class="string">'NNG'</span>),</span><br><span class="line"> (<span class="string">'이'</span>, <span class="string">'JKC'</span>),</span><br><span class="line"> (<span class="string">'아니'</span>, <span class="string">'VCN'</span>),</span><br><span class="line"> (<span class="string">'여도'</span>, <span class="string">'EC'</span>),</span><br><span class="line"> (<span class="string">'괜찮'</span>, <span class="string">'VA'</span>),</span><br><span class="line"> (<span class="string">'아'</span>, <span class="string">'EC'</span>)]</span><br></pre></td></tr></table></figure><h2 id="텍스트-클리닝"><a href="#텍스트-클리닝" class="headerlink" title="텍스트 클리닝"></a>텍스트 클리닝</h2><p>본격적으로 한국어 토크나이징을 진행하기 전, noise removal 파트부터 코드를 작성해 보자.</p><p><a href="https://jeongwookie.github.io/2020/04/23/200423-analyze-tweet-series-1-collect/">이전 포스트 - 트윗 수집하기</a>에서 수집했던 트윗을 예시로 텍스트 클리닝을 진행할 것이다.</p><p><img src="https://user-images.githubusercontent.com/25416425/80576775-bc4e2780-8a40-11ea-9f29-1d28ef486981.png" width="400"></p><p>위 그림은 트위터에서 직접 눈으로 볼 수 있는 트윗의 페이지를 캡쳐한 것이다. 그러나 우리가 수집한 데이터는 아래와 같이 생겼다.</p><p><img src="https://user-images.githubusercontent.com/25416425/80576974-0c2cee80-8a41-11ea-90b9-05aa40b5c625.png" width="700"></p><p>상당히 텍스트 데이터의 noise가 심한 것을 확인할 수 있다. 특수문자 및 URL이 텍스트 중간 중간에 섞여 있어 제대로 제거하지 않으면 이후 분석에 방해가 된다.</p><p>이제 텍스트 클리닝을 수행하는 코드를 실제로 작성해 보자. 주로 <code>regex</code> 문법을 활용할 것이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># Basic Cleaning Text Function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">CleanText</span><span class="params">(readData, Num=False, Eng=False)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove Retweets </span></span><br><span class="line">    text = re.sub(<span class="string">'RT @[\w_]+: '</span>, <span class="string">''</span>, readData)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove Mentions</span></span><br><span class="line">    text = re.sub(<span class="string">'@[\w_]+'</span>, <span class="string">''</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove or Replace URL </span></span><br><span class="line">    text = re.sub(<span class="string">r"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+"</span>, <span class="string">' '</span>, text) <span class="comment"># http로 시작되는 url</span></span><br><span class="line">    text = re.sub(<span class="string">r"[-a-zA-Z0-9@:%._\+~#=]&#123;1,256&#125;\.[a-zA-Z0-9()]&#123;2,6&#125;\b([-a-zA-Z0-9()@:%_\+.~#?&amp;//=]*)"</span>, <span class="string">' '</span>, text) <span class="comment"># http로 시작되지 않는 url</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Remove Hashtag</span></span><br><span class="line">    text = re.sub(<span class="string">'[#]+[0-9a-zA-Z_]+'</span>, <span class="string">' '</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove Garbage Words (ex. &amp;lt, &amp;gt, etc)</span></span><br><span class="line">    text = re.sub(<span class="string">'[&amp;]+[a-z]+'</span>, <span class="string">' '</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove Special Characters</span></span><br><span class="line">    text = re.sub(<span class="string">'[^0-9a-zA-Zㄱ-ㅎ가-힣]'</span>, <span class="string">' '</span>, text)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Remove newline</span></span><br><span class="line">    text = text.replace(<span class="string">'\n'</span>,<span class="string">' '</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> Num <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># Remove Numbers</span></span><br><span class="line">        text = re.sub(<span class="string">r'\d+'</span>,<span class="string">' '</span>,text)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> Eng <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># Remove English </span></span><br><span class="line">        text = re.sub(<span class="string">'[a-zA-Z]'</span> , <span class="string">' '</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove multi spacing &amp; Reform sentence</span></span><br><span class="line">    text = <span class="string">' '</span>.join(text.split())</span><br><span class="line">       </span><br><span class="line">    <span class="keyword">return</span> text</span><br></pre></td></tr></table></figure><p>코드가 좀 복잡하다. 그래도 위 코드는 내가 트윗을 연구 대상으로 삼으면서 여러모로 트위터에 맞게 세팅한 것이니 따라오길 바란다.</p><p>위 코드가 하는 역할은 최대한 원문을 살리면서 분석에 불필요한 (토픽을 이해하는 데에 필요하지 않은) 부분을 제거하는 것이다.<br>예를 들어서 트위터에서 리트윗 시 텍스트 앞에 RT @user_screenname 과 같은 형태의 텍스트가 붙게 되는데, 이런 부분만을 제거 한다던지 하는 것이다.</p><p>트위터에서 URL은 대단히 자주 보이는데, 우리가 분석할 때에는 필요치 않은 정보이다. 위 코드는 여러가지 경우의 URL을 찾아서 제거하게 해 놓았다. (Regex URL 매칭 후 제거)<br>또한 Boolean 을 사용해서 숫자와 영어에 대해서 옵션을 만들어 놓았는데, 이는 경우에 따라 숫자와 영어를 찾아서 모두 제거하고 한국어만 분석하는 것이 편하기 때문이다. 그러나 기본값은 <code>False</code>로 해 두었는데, 이를 활성화할 경우 KBS, CNN, 40개국, G20 과 같은 의미가 존재하는 단어들도 제거되기 때문이다.</p><p>트위터를 분석하지 않을 경우, 위 코드 중에서 일부만 사용하고 나머지는 주석 처리하면 편하게 적용할 수 있을 것이다. (요렇게 한국어 클리닝 코드를 통으로 올려놓은 블로그는 본적이 없어서.. 지금까지 나도 갑갑했다)</p><p>설명이 길었다. 위 코드를 앞의 예시 트윗에 적용해 보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SAMPLE_TEXT = <span class="string">"&lt;🚨코로나19 가짜뉴스 팩트체크&gt;\n\n신천지가 기성교회에 가서 코로나를 전파하라고 했다??!\n\n- 사실 무근입니다. \n신천지는 2월 18일 부터 전국 교회를 폐쇄하고 온라인\n예배로 전환하였습니다.\n\n#온라인예배\n#가짜뉴스_이제그만\n#신천지_팩트체크 pic.twitter.com/Dppie6iean"</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">f"Before cleaning text:\n<span class="subst">&#123;SAMPLE_TEXT&#125;</span>"</span>)</span><br><span class="line">print(<span class="string">"\n"</span>)</span><br><span class="line">print(<span class="string">f"After cleaning text:\n<span class="subst">&#123;CleanText(SAMPLE_TEXT)&#125;</span>"</span>)</span><br><span class="line">print(<span class="string">"\n"</span>)</span><br><span class="line">print(<span class="string">f"After cleaning text when Num is True:\n<span class="subst">&#123;CleanText(SAMPLE_TEXT, Num=<span class="literal">True</span>)&#125;</span>"</span>)</span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/25416425/80684237-53c67f80-8b00-11ea-865a-16651c612b8e.png" width="800"></p><p>깔끔하게 텍스트 클리닝이 완료된 것을 확인할 수 있다.</p><h2 id="텍스트-토크나이징"><a href="#텍스트-토크나이징" class="headerlink" title="텍스트 토크나이징"></a>텍스트 토크나이징</h2><p>이번에는 위 텍스트 클리닝 코드를 포함한 한국어 토크나이징을 진행해 보겠다.<br>의미를 내포하고 있는 단위로 잘라서 토픽모델링을 시도하기 전 단계로 이해하면 된다.</p><p><code>Mecab</code> 토크나이저는 POS 태깅을 지원하기 때문에, 태깅 상태를 보고 조사나 어미 등 의미를 파악하는 데에 불필요한 부분들을 제거한다. </p><p>추가적으로 위 프로세스에서 걸러지지 않은 Stopwords 를 추가로 거를 수도 있지만 이는 데이터에 따라서 커스터마이즈가 많이 이루어져야 하기에, 본 포스트에서는 생략했다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> konlpy.tag <span class="keyword">import</span> Mecab </span><br><span class="line"></span><br><span class="line"><span class="comment"># Preprocessing code with Mecab</span></span><br><span class="line">mecab = Mecab(dicpath=<span class="string">"/usr/local/lib/mecab/dic/mecab-ko-dic"</span>) <span class="comment"># Mecab User Dic Path</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocessing_mecab</span><span class="params">(readData)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#### Clean text</span></span><br><span class="line">    sentence = CleanText(readData)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#### Tokenize</span></span><br><span class="line">    morphs = mecab.pos(sentence)</span><br><span class="line">    </span><br><span class="line">    JOSA = [<span class="string">"JKS"</span>, <span class="string">"JKC"</span>, <span class="string">"JKG"</span>, <span class="string">"JKO"</span>, <span class="string">"JKB"</span>, <span class="string">"JKV"</span>, <span class="string">"JKQ"</span>, <span class="string">"JX"</span>, <span class="string">"JC"</span>] <span class="comment"># 조사</span></span><br><span class="line">    SIGN = [<span class="string">"SF"</span>, <span class="string">"SE"</span>, <span class="string">"SSO"</span>, <span class="string">"SSC"</span>, <span class="string">"SC"</span>, <span class="string">"SY"</span>] <span class="comment"># 문장 부호</span></span><br><span class="line">    TERMINATION = [<span class="string">"EP"</span>, <span class="string">"EF"</span>, <span class="string">"EC"</span>, <span class="string">"ETN"</span>, <span class="string">"ETM"</span>] <span class="comment"># 어미</span></span><br><span class="line">    SUPPORT_VERB = [<span class="string">"VX"</span>] <span class="comment"># 보조 용언</span></span><br><span class="line">    NUMBER = [<span class="string">"SN"</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Remove JOSA, EOMI, etc</span></span><br><span class="line">    morphs[:] = (morph <span class="keyword">for</span> morph <span class="keyword">in</span> morphs <span class="keyword">if</span> morph[<span class="number">1</span>] <span class="keyword">not</span> <span class="keyword">in</span> JOSA+SIGN+TERMINATION+SUPPORT_VERB)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Remove length-1 words  </span></span><br><span class="line">    morphs[:] = (morph <span class="keyword">for</span> morph <span class="keyword">in</span> morphs <span class="keyword">if</span> <span class="keyword">not</span> (len(morph[<span class="number">0</span>]) == <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Remove Numbers</span></span><br><span class="line">    morphs[:] = (morph <span class="keyword">for</span> morph <span class="keyword">in</span> morphs <span class="keyword">if</span> morph[<span class="number">1</span>] <span class="keyword">not</span> <span class="keyword">in</span> NUMBER)</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># Result pop-up</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> morph <span class="keyword">in</span> morphs:</span><br><span class="line">        result.append(morph[<span class="number">0</span>])</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>위 코드에서 <code>Mecab</code>을 불러올 때 사용한 <code>dicpath</code> 옵션은 등록된 사용자 사전을 사용하고 싶을때 적는 것이다. 사용하지 않을 경우 지워버리면 된다.</p><p>코드의 흐름은 먼저 앞의 섹션에서 작성했던 <code>CleanText()</code> 함수를 사용해 텍스트 클리닝을 진행하고, 이후 <code>Mecab</code> 토크나이저를 사용해서 토큰화한다. 그리고 POS 태깅된 정보를 활용해서 의미가 없는 단어들을 삭제한다. 추가적으로, 잘랐을 때 길이가 1인 (글자 1개) 단어는 의미를 알기 어려워 제거하였다.</p><p><code>Mecab</code> 토크나이저의 POS 태깅 정보를 보다 자세히 알고 싶다면 <a href="http://kkma.snu.ac.kr/documents/?doc=postag" rel="external nofollow noopener noreferrer" target="_blank">한글 형태소 품사 태그표</a>를 참고하자.</p><p>이제 위 코드를 실행시켜 보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">SAMPLE_TEXT = <span class="string">"&lt;🚨코로나19 가짜뉴스 팩트체크&gt;\n\n신천지가 기성교회에 가서 코로나를 전파하라고 했다??!\n\n- 사실 무근입니다. \n신천지는 2월 18일 부터 전국 교회를 폐쇄하고 온라인\n예배로 전환하였습니다.\n\n#온라인예배\n#가짜뉴스_이제그만\n#신천지_팩트체크 pic.twitter.com/Dppie6iean"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># RUN!</span></span><br><span class="line">preprocessing_mecab(SAMPLE_TEXT)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print out</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="string">'코로나'</span>,</span><br><span class="line"> <span class="string">'가짜'</span>,</span><br><span class="line"> <span class="string">'뉴스'</span>,</span><br><span class="line"> <span class="string">'팩트체크'</span>,</span><br><span class="line"> <span class="string">'신천지'</span>,</span><br><span class="line"> <span class="string">'기성'</span>,</span><br><span class="line"> <span class="string">'교회'</span>,</span><br><span class="line"> <span class="string">'코로나'</span>,</span><br><span class="line"> <span class="string">'전파'</span>,</span><br><span class="line"> <span class="string">'무근'</span>,</span><br><span class="line"> <span class="string">'입니다'</span>,</span><br><span class="line"> <span class="string">'신천지'</span>,</span><br><span class="line"> <span class="string">'전국'</span>,</span><br><span class="line"> <span class="string">'교회'</span>,</span><br><span class="line"> <span class="string">'폐쇄'</span>,</span><br><span class="line"> <span class="string">'온라인'</span>,</span><br><span class="line"> <span class="string">'예배'</span>,</span><br><span class="line"> <span class="string">'전환'</span>,</span><br><span class="line"> <span class="string">'온라인'</span>,</span><br><span class="line"> <span class="string">'예배'</span>,</span><br><span class="line"> <span class="string">'가짜'</span>,</span><br><span class="line"> <span class="string">'뉴스'</span>,</span><br><span class="line"> <span class="string">'이제'</span>,</span><br><span class="line"> <span class="string">'그만'</span>,</span><br><span class="line"> <span class="string">'신천지'</span>,</span><br><span class="line"> <span class="string">'팩트체크'</span>]</span><br></pre></td></tr></table></figure><p>깔끔하게 토크나이징이 완료된 것을 확인할 수 있다. 읽어보면 의미도 잘 파악이 된다.<br>이제 위 코드들을 바탕으로, 다음 포스트에서는 LDA 토픽 모델링 및 간단한 워드 클라우드 만들기를 해볼 것이다.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;트위터 파헤치기 두번째 시리즈의 주제는 &lt;strong&gt;한국어 전처리&lt;/strong&gt; 이다.&lt;br&gt;단순히 LDA 토픽 모델링을 하는 것에서부터 딥러닝 모델을 훈련시키는 것 까지 NLP와 관련된 전 과정에서 전처리는 필수적이다.&lt;br&gt;텍스트 데이터의 특성상 기본적으로 노이즈 (noise)가 많은 데이터에 속하기 때문이다. 다음과 같은 과정을 보통 진행한다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tokenization : 문장을 하나의 기준을 가지고 자르는 것 (안녕하세요 -&amp;gt; 안녕 / 하세요)&lt;/li&gt;
&lt;li&gt;Stemming : 동사 및 형용사 등의 활용 형태를 원문으로 바꾸는 것 (잼따 -&amp;gt; 재미 이다)&lt;/li&gt;
&lt;li&gt;Noramlization : 표기가 다른 단어들을 통합하는 것 (입니닼ㅋㅋ -&amp;gt; 입니다 ㅋㅋ)&lt;/li&gt;
&lt;li&gt;Noise removal : 문장의 의미를 이해하는 데에 불필요한 부분을 제거하는 것 (특수문자, url 등)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;영어의 경우 &lt;code&gt;nltk&lt;/code&gt; 라는 강력한 파이썬 패키지가 존재하여, 대부분의 우리가 원하는 전처리 함수들이 구현되어 있다.&lt;br&gt;그러나 한국어의 경우 Tokenization의 단위가 단어인지, 형태소인지, 자모인지, 아니면 그 외인지조차 아직까지 불명확한 부분이 있다. (현재도 연구중)&lt;br&gt;또한, Normalization이나 Stemming의 경우에도 &lt;code&gt;Konlpy&lt;/code&gt;에 최근 포함된 &lt;code&gt;Okt&lt;/code&gt; 클래스가 지원하지만 써본 결과 영어만큼 완벽하지는 않다.&lt;/p&gt;
&lt;p&gt;그래서 본 포스트에서는 제일 general 한 토크나이저인 &lt;code&gt;Mecab&lt;/code&gt;을 사용해서 그나마 reasonable한 방향으로 한국어 전처리를 진행해 보고자 한다. 현재도 계속 연구중이므로 완벽한 방법은 아니라는 것에 유의하자.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/25416425/80573175-742c0680-8a3a-11ea-9a8d-940a8215b879.png&quot; width=&quot;500&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅰ. Data Science" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/"/>
    
      <category term="트위터 데이터 분석하기" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/%ED%8A%B8%EC%9C%84%ED%84%B0-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0/"/>
    
    
      <category term="Python" scheme="https://jeongwookie.github.io/tags/Python/"/>
    
      <category term="Datamining" scheme="https://jeongwookie.github.io/tags/Datamining/"/>
    
      <category term="Twitter" scheme="https://jeongwookie.github.io/tags/Twitter/"/>
    
  </entry>
  
  <entry>
    <title>트위터 파헤치기 시리즈 첫번째 - 수집하기</title>
    <link href="https://jeongwookie.github.io/2020/04/23/datascience/twitter/2-analyze-tweet-series-1-collect/"/>
    <id>https://jeongwookie.github.io/2020/04/23/datascience/twitter/2-analyze-tweet-series-1-collect/</id>
    <published>2020-04-23T08:38:46.000Z</published>
    <updated>2021-11-21T11:21:38.807Z</updated>
    
    <content type="html"><![CDATA[<p>트위터 데이터를 주로 수집해서 사용하다 보니, 너무 관련된 포스트를 여러개 쓰는것 같지만..<br>많은 분들이 댓글 혹은 메일로도 연락이 오셔서 문의하시는 부분이 있어 이 기회에 정리해 보고자 한다.</p><p>이름하여 <strong>트위터 파헤치기 시리즈!</strong> 수집부터 시작해서 한국어 전처리, 워드 클라우드 시각화 및 클러스터링 시 적절한 하이퍼 파라미터 설정 등 분석 단계까지 조금씩 정리해 보고자 한다.</p><p>예시 주제로 요즘 우리들을 괴롭히는 <strong>코로나 바이러스</strong> 에 대해서 트위터를 살펴보는 것으로 정했다.</p><p>지금까지 트위터 수집 방법에 대해서 꽤 여러 포스트를 썼었는데, 지금까지 다루지 않은 방법으로 시도하고자 한다. 수집 방법을 많이 알면 알수록 좋으니까! </p><p><img src="https://user-images.githubusercontent.com/25416425/80474558-8ea2a900-8982-11ea-99b0-e1cef6218e03.png" width="500"></p><a id="more"></a><h2 id="수집-도구-정하기"><a href="#수집-도구-정하기" class="headerlink" title="수집 도구 정하기"></a>수집 도구 정하기</h2><p>이번에 트위터 수집에 사용할 패키지는 <code>twint</code> 라는 친구이다.<br>(github page : <a href="https://github.com/twintproject/twint" rel="external nofollow noopener noreferrer" target="_blank">https://github.com/twintproject/twint</a>)</p><p>무료로 사용할 수 있고, 트위터 개발자 등록 과정이 필요가 없어서 간단하게 트랜드나 토픽을 알고 싶을때 사용하곤 했다.</p><p>돈 내고 쓰는 것이 아니기 때문에 조금씩 불편한 점들이 있다. 그러나 현존하는 무료 파이썬 패키지 중에 가장 잘 작동하는 트위터 크롤링 패키지가 아닐까 싶다.</p><p>full-archive 트위터 데이터가 필요한 연구자라면 본 패키지는 불필요하다. Premium API를 결제해서 사용하도록 하자. 본인이 시도해본 결과 프리미엄에 비해 10~20%의 데이터밖에 크롤링하지 못한다.</p><p>그러나, 하루에 어떤 토픽이 이슈가 되었고 전반적인 트랜드를 알고 싶은 사용자라면 이것으로 충분하다.</p><p>아래부터 코드는 주피터 노트북으로 열어서 실행하는 것을 기본으로 전제하고 작성한다. <code>twint</code>를 설치부터 해주자.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># python 3.6 </span><br><span class="line"># install twint package</span><br><span class="line">!pip install --user --upgrade -e git+https://github.com/twintproject/twint.git@origin/master#egg=twint</span><br></pre></td></tr></table></figure><p>깃허브 홈페이지를 들어가보면 pip 설치 이외에도 설치 방법이 다양하게 나와있다. (Python 3.6 기준)</p><h2 id="파라미터-설정하기"><a href="#파라미터-설정하기" class="headerlink" title="파라미터 설정하기"></a>파라미터 설정하기</h2><p><code>twint</code> 패키지는 거의 대부분의 Twitter API 가 지원하는 옵션을 동일하게 지원한다. 자세한 사용법은 본 포스트에서는 다루지 않을 생각이다. wiki를 읽어보면 혼자서 할 수 있도록 설명이 잘 되어 있기 때문이다.</p><p>본 포스트의 목적은 <strong>코로나 바이러스</strong> 에 관한 트윗을 수집하는 것이므로, 여기에 초점을 맞춰서 파라미터를 설정해 보겠다. 설정하면서 등장하는 <code>twint</code> 옵션에 대해서는 간단하게 설명을 달아놓는 것으로.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> twint</span><br><span class="line">c = twint.Config() <span class="comment"># twint config 선언</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Parameter setting</span></span><br><span class="line">c.Limit = <span class="number">50</span></span><br><span class="line">c.Search = <span class="string">'코로나 OR 우한 폐렴'</span></span><br><span class="line">c.Since = <span class="string">'2020-04-23'</span></span><br><span class="line">c.Until = <span class="string">'2020-04-24'</span></span><br><span class="line">c.Output = <span class="string">'covid19_sample_tweet.json'</span></span><br><span class="line">c.Popular_tweets = <span class="literal">True</span></span><br><span class="line">c.Store_json = <span class="literal">True</span></span><br><span class="line">c.Hide_output = <span class="literal">True</span></span><br></pre></td></tr></table></figure><p>옵션이 생각보다 많다.. 위의 코드에 사용된 옵션에 대해서 하나하나 알아보자.</p><ul><li>Limit: 총 수집할 트윗의 수를 의미 (모든 트윗을 수집하고 싶다면 옵션을 제거)</li><li>Search: 수집할 트윗의 키워드를 입력, <strong>Exact Match</strong>를 원하면 쌍따옴표를 사용<br>(ex. ‘코로나 OR “우한 폐렴”‘ 으로 입력할 경우, 정확히 우한 폐렴 이라는 단어를 모두 포함하는 트윗만 수집됨)</li><li>Since, Until: 수집을 원하는 기간 범위 (끝은 포함하지 않음)</li><li>Output: 트윗을 수집 후 저장할 때 파일 이름</li><li>Popular_tweets: <code>True</code>일 때 트위터 탭 중 Polular을 의미, <code>False</code>의 경우 Recent을 의미</li><li>Store_json: 저장 시 JSON 포맷으로</li><li>Hide_output: <code>True</code>일 때 주피터 노트북 콘솔에 output이 출력되는 옵션을 끔</li></ul><p>더 원하는 옵션이 있거나, 설명을 보고도 잘 이해하기 어렵다면 <a href="https://github.com/twintproject/twint/wiki/Configuration" rel="external nofollow noopener noreferrer" target="_blank">공식 홈페이지</a>의 설명을 참고하자.</p><h2 id="트위터-수집하기"><a href="#트위터-수집하기" class="headerlink" title="트위터 수집하기"></a>트위터 수집하기</h2><p>자, 설정은 끝났다. 이제 위에서 설정한 <code>twint</code>을 실행시켜 볼 것이다. 아래의 코드를 입력한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">twint.run.Search(c)</span><br></pre></td></tr></table></figure><p>위의 옵션에서 나는 “트위터에서 코로나 또는 우한 폐렴을 포함하는 트윗을 2020년 4월 23일 (UTC), Popular 탭 기준으로 50개만 수집해줘” 를 주문했다.</p><p>제대로 실행되었다면, working directory에 <code>covid19_sample_tweet.json</code> 파일이 생성되었을 것이다. 뜯어서 살펴보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.read_json(<span class="string">'covid19_sample_tweet.json'</span>, lines=<span class="literal">True</span>)</span><br><span class="line">df[[<span class="string">"created_at"</span>, <span class="string">"id"</span>, <span class="string">"tweet"</span>, <span class="string">"retweets_count"</span>]].head() <span class="comment"># 편의상 4개의 칼럼만 출력</span></span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/25416425/80477180-79c81480-8986-11ea-96f3-5edd1718aaaa.png" width="750"></p><p>위와 같이 4월 23일의 트윗이 잘 수집되었음을 확인할 수 있다.</p><h2 id="크롤러-만들기"><a href="#크롤러-만들기" class="headerlink" title="크롤러 만들기"></a>크롤러 만들기</h2><p>위까지 잘 따라왔다면 <code>twint</code>를 사용해서 하루 단위의 트윗을 어떻게 모으는지 알았을 것이다.<br>이제 loop를 구성해서, 주어진 기간 내 특정 트윗을 모두 수집하도록 코드를 구성해 보자.<br>이쯤 되면 트위터 크롤러라고 이름을 붙여도 될 것이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import packages</span></span><br><span class="line"><span class="keyword">import</span> twint</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> mkdir, path</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># Valid Directory Naming Function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_name</span><span class="params">(term)</span>:</span></span><br><span class="line">    cleaned = re.sub(<span class="string">'[^0-9a-zA-Zㄱ-ㅎ가-힣]'</span>, <span class="string">''</span>, term) <span class="comment"># 특수문자 제거</span></span><br><span class="line">    <span class="keyword">return</span> cleaned</span><br><span class="line"></span><br><span class="line"><span class="comment"># Twint Search Function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">twint_search</span><span class="params">(dirname, searchterm, since, until, json_name, limit)</span>:</span></span><br><span class="line"></span><br><span class="line">    c = twint.Config()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Parameter setting</span></span><br><span class="line">    c.Limit = limit</span><br><span class="line">    c.Search = searchterm</span><br><span class="line">    c.Since = since</span><br><span class="line">    c.Until = until</span><br><span class="line">    c.Hide_output = <span class="literal">True</span></span><br><span class="line">    c.Store_json = <span class="literal">True</span></span><br><span class="line">    c.Output = json_name</span><br><span class="line">    c.Debug = <span class="literal">True</span></span><br><span class="line">    c.Resume = <span class="string">f'<span class="subst">&#123;dirname&#125;</span>/save_endpoint/save_endpoint_<span class="subst">&#123;since&#125;</span>.txt'</span></span><br><span class="line">    c.Popular_tweets = <span class="literal">True</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        twint.run.Search(c)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> (KeyboardInterrupt, SystemExit):</span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">f"Problem with <span class="subst">&#123;since&#125;</span>."</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loop Function, Default number of tweet is 50</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">twint_loop</span><span class="params">(searchterm, since, until, limit=<span class="number">50</span>)</span>:</span></span><br><span class="line">    </span><br><span class="line">    dirname = clean_name(searchterm)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create target directory</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        mkdir(dirname)</span><br><span class="line">        mkdir(<span class="string">f'<span class="subst">&#123;dirname&#125;</span>/save_endpoint'</span>)</span><br><span class="line">        print(<span class="string">"Directory"</span> , dirname ,  <span class="string">"Created "</span>)</span><br><span class="line">    <span class="keyword">except</span> FileExistsError:</span><br><span class="line">        print(<span class="string">"Directory"</span> , dirname ,  <span class="string">"already exists"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loop </span></span><br><span class="line">    daterange = pd.date_range(since, until)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> start_date <span class="keyword">in</span> daterange:</span><br><span class="line"></span><br><span class="line">        since = start_date.strftime(<span class="string">"%Y-%m-%d"</span>)</span><br><span class="line">        until = (start_date + timedelta(days=<span class="number">1</span>)).strftime(<span class="string">"%Y-%m-%d"</span>)</span><br><span class="line"></span><br><span class="line">        json_name = <span class="string">""</span>.join(since.split(<span class="string">"-"</span>)) + <span class="string">".json"</span></span><br><span class="line">        json_name = path.join(dirname, json_name)</span><br><span class="line"></span><br><span class="line">        print(<span class="string">f'Getting <span class="subst">&#123;since&#125;</span> '</span>)</span><br><span class="line">        twint_search(dirname, searchterm, since, until, json_name, limit)</span><br></pre></td></tr></table></figure><p>조금 함수의 형태들이 마음에 들지 않지만, 작동은 잘 한다.<br>따로 값을 지정하지 않으면 기본적으로 각 날짜에 대해 50개의 트윗만 가져오도록 설정했다.<br>50개의 트윗을 시간 순서대로 가져오고 싶다면 옵션 중 <code>Popular_tweets</code>을 <code>False</code>로 지정하면 된다.</p><p>위의 섹션에서 다루지 않은 옵션이 있는데, <code>Debug</code> 와 <code>Resume</code>이다. 이는 대량의 트윗을 수집할 때 <code>twint</code>가 트위터 서버 측의 공격적인 크롤링 방지로 인해 TimeoutError를 발생시키기 때문에, 중간 저장 포인트를 만들기 위해 설정한 것이다.</p><p>일단 실행 고고!</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Keyword = <span class="string">'코로나 OR 우한 폐렴'</span></span><br><span class="line">twint_loop(Keyword, <span class="string">'2020-04-23'</span>, <span class="string">'2020-04-25'</span>, limit=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 실행 화면</span></span><br><span class="line">&gt;&gt; Directory 코로나OR우한폐렴 Created</span><br><span class="line">&gt;&gt; Getting <span class="number">2020</span><span class="number">-04</span><span class="number">-23</span> </span><br><span class="line">&gt;&gt; Getting <span class="number">2020</span><span class="number">-04</span><span class="number">-24</span> </span><br><span class="line">&gt;&gt; Getting <span class="number">2020</span><span class="number">-04</span><span class="number">-25</span></span><br></pre></td></tr></table></figure><p>위와 같이 2020년 4월 23일부터 25일까지 트윗이 잘 수집됨을 확인할 수 있다.</p><p>Limit을 -1로 설정하면 조건을 만족하는 모든 트윗을 가져오게 되는데, 경우에 따라 몇 시간에서 몇십 시간이 소요될 수도 있다. (covid19와 같은 search 조건을 입력하면 그렇게 된다..)</p><p>그리고 너무 오랫동안 크롤러가 작동하게 되면 알수 없는 이유로 오류를 일으키는 경우가 간간히 존재한다. 경험적으로 크롤러가 끊어지는 부분들을 많이 보완한 코드가 위의 코드인데.. 문제들을 완전히 해결하고 싶다면 유료 버전을 검토해 보자.</p><p>수집된 내용을 확인해 볼까?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># Saved files path</span></span><br><span class="line">DATA_DIR = Path(<span class="string">f"./<span class="subst">&#123;clean_name(Keyword)&#125;</span>"</span>) <span class="comment"># 저장된 파일 디렉토리 정보</span></span><br><span class="line">json_files = [pos_json <span class="keyword">for</span> pos_json <span class="keyword">in</span> os.listdir(DATA_DIR) <span class="keyword">if</span> pos_json.endswith(<span class="string">'.json'</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data load</span></span><br><span class="line">df_list= []</span><br><span class="line"><span class="keyword">for</span> file_name <span class="keyword">in</span> tqdm(json_files):</span><br><span class="line">    temp_df = pd.read_json(DATA_DIR / file_name, lines=<span class="literal">True</span>)</span><br><span class="line">    df_list.append(temp_df)</span><br><span class="line">    </span><br><span class="line">df = pd.concat(df_list, sort=<span class="literal">False</span>)</span><br><span class="line">df[[<span class="string">"created_at"</span>, <span class="string">"id"</span>, <span class="string">"tweet"</span>, <span class="string">"retweets_count"</span>]].tail() <span class="comment"># 편의상 4개의 칼럼만 출력</span></span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/25416425/80562211-05db4a00-8a22-11ea-973a-8416eff25eab.png" width="750"></p><p>수집이 잘 이루어졌음을 확인할 수 있다.</p><p>또한 위의 코드에는 여러개의 JSON 파일을 한번에 읽는 방법도 포함되어 있다.<br>하나의 JSON 파일에 너무 많은 트윗이 포함되어 있다면 읽는 데에도 시간이 오래 걸리니 유의하자.<br>통째로 묶어서 <code>df</code>에 저장하도록 되어 있는데, 트윗의 수가 몇 백만개가 넘어가면 Memory Error가 발생할 수 있다.<br>얼마나 읽어졌는지 눈으로 확인하기 위해 <code>tqdm</code>을 추가하였다. 오류가 난다면 제거해도 상관없다.</p><p>다음 포스트에서는 위와 같은 방법으로 수집한 트윗에 대해 한국어 NLP에서 가장 고충을 겪고 있는 점 중 하나인 전처리 (preprocessing)에 대해 다루어 볼 계획이다.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;트위터 데이터를 주로 수집해서 사용하다 보니, 너무 관련된 포스트를 여러개 쓰는것 같지만..&lt;br&gt;많은 분들이 댓글 혹은 메일로도 연락이 오셔서 문의하시는 부분이 있어 이 기회에 정리해 보고자 한다.&lt;/p&gt;
&lt;p&gt;이름하여 &lt;strong&gt;트위터 파헤치기 시리즈!&lt;/strong&gt; 수집부터 시작해서 한국어 전처리, 워드 클라우드 시각화 및 클러스터링 시 적절한 하이퍼 파라미터 설정 등 분석 단계까지 조금씩 정리해 보고자 한다.&lt;/p&gt;
&lt;p&gt;예시 주제로 요즘 우리들을 괴롭히는 &lt;strong&gt;코로나 바이러스&lt;/strong&gt; 에 대해서 트위터를 살펴보는 것으로 정했다.&lt;/p&gt;
&lt;p&gt;지금까지 트위터 수집 방법에 대해서 꽤 여러 포스트를 썼었는데, 지금까지 다루지 않은 방법으로 시도하고자 한다. 수집 방법을 많이 알면 알수록 좋으니까! &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/25416425/80474558-8ea2a900-8982-11ea-99b0-e1cef6218e03.png&quot; width=&quot;500&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅰ. Data Science" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/"/>
    
      <category term="트위터 데이터 분석하기" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/%ED%8A%B8%EC%9C%84%ED%84%B0-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0/"/>
    
    
      <category term="Python" scheme="https://jeongwookie.github.io/tags/Python/"/>
    
      <category term="Datamining" scheme="https://jeongwookie.github.io/tags/Datamining/"/>
    
      <category term="Twitter" scheme="https://jeongwookie.github.io/tags/Twitter/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch 특정 GPU 사용하기</title>
    <link href="https://jeongwookie.github.io/2020/03/24/deeplearning/1-pytorch-cuda-gpu-allocate/"/>
    <id>https://jeongwookie.github.io/2020/03/24/deeplearning/1-pytorch-cuda-gpu-allocate/</id>
    <published>2020-03-24T07:48:48.000Z</published>
    <updated>2021-11-21T11:30:16.916Z</updated>
    
    <content type="html"><![CDATA[<p>나는 많은 딥러닝 프레임워크 중 Pytorch와 MxNet을 자주 사용하는 편이다.<br>그런데, 연구실 사람들과 GPU 서버를 함께 쓰다 보니 어떤 GPU가 현재 available한지 알아야 할 필요가 있었다.</p><p>원래는 시간대를 적당히 맞춰서 사용하곤 했는데, 멀티 GPU 세팅에 대해서는 잘 모르기도 하고 colab으로는 도저히 불편해서 쓸수가 없었으므로..ㅠㅠ 관련 정보를 찾아보고 그 결과를 간단히 공유하고자 한다.</p><p><img src="https://user-images.githubusercontent.com/25416425/77401561-7d4d0680-6df0-11ea-9cfa-b3bb0591f232.jpg" width="500"></p><a id="more"></a><h2 id="GPU-서버-상태-확인하기"><a href="#GPU-서버-상태-확인하기" class="headerlink" title="GPU 서버 상태 확인하기"></a>GPU 서버 상태 확인하기</h2><p>사용하고자 하는 서버의 GPU availability 를 먼저 알아보자. 간단하게 알아볼 수 있다.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi # bash OR terminal에서 명령어를 입력할 경우</span><br><span class="line">!nvidia-smi # Jupyter Notebook에서 명령어를 입력할 경우</span><br></pre></td></tr></table></figure><p>위와 같이 입력한 경우, 아래와 같은 화면이 출력된다.<br>(만약 출력이 안되는 경우, Nvidia driver에 문제가 있는 것이기 때문에 요 부분을 다시 검토해 보자)</p><p><img src="https://user-images.githubusercontent.com/25416425/77401942-27c52980-6df1-11ea-945b-a7067cb7e388.png" width="500"></p><p>내가 사용하는 서버는 TITAN Xp 가 4개 가동중인 GPU 서버이며, 현재 1,2,3번 GPU에서는 용량이 꽉 차있는 것으로 보아 누군가가 작업을 진행하고 있는 것으로 예상된다.</p><h2 id="Default-GPU-Setup-확인하기"><a href="#Default-GPU-Setup-확인하기" class="headerlink" title="Default GPU Setup 확인하기"></a>Default GPU Setup 확인하기</h2><p>어떤 GPU를 사용할지는 위의 과정을 거쳤더니 알게 되었다. 나는 GPU:0 을 사용해야 하는구만.</p><p>그러면 이제 내 작업환경으로 돌아가, 현재는 어떤 GPU를 사용하도록 셋팅 되어있는지 확인하는 과정이 필요하다.<br>마치 <code>os.getcwd()</code> 으로 현재 디렉토리를 아는 것처럼..</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 현재 Setup 되어있는 device 확인</span></span><br><span class="line">device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'Available devices '</span>, torch.cuda.device_count())</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'Current cuda device '</span>, torch.cuda.current_device())</span><br><span class="line">print(torch.cuda.get_device_name(device))</span><br></pre></td></tr></table></figure><p>위 코드를 실행시키면 차례대로 사용가능한 GPU 디바이스의 갯수, 현재 셋업 되어있는 GPU 넘버, 그리고 GPU 디바이스의 이름을 출력한다.</p><p><img src="https://user-images.githubusercontent.com/25416425/77402508-1c263280-6df2-11ea-9e40-77288ac2287c.png" width="500"></p><p>결과를 보니, 나는 TITAN Xp 디바이스 중 2번 GPU를 사용중임을 확인할 수 있었다. (인덱스는 0번부터 시작)</p><h2 id="GPU-Allocation-변경하기"><a href="#GPU-Allocation-변경하기" class="headerlink" title="GPU Allocation 변경하기"></a>GPU Allocation 변경하기</h2><p>나는 현재 2번 GPU를 사용중인데, 이를 0번 GPU로 바꾸어야 한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GPU 할당 변경하기</span></span><br><span class="line">GPU_NUM = <span class="number">0</span> <span class="comment"># 원하는 GPU 번호 입력</span></span><br><span class="line">device = torch.device(<span class="string">f'cuda:<span class="subst">&#123;GPU_NUM&#125;</span>'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">torch.cuda.set_device(device) <span class="comment"># change allocation of current GPU</span></span><br><span class="line"><span class="keyword">print</span> (<span class="string">'Current cuda device '</span>, torch.cuda.current_device()) <span class="comment"># check</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Additional Infos</span></span><br><span class="line"><span class="keyword">if</span> device.type == <span class="string">'cuda'</span>:</span><br><span class="line">    print(torch.cuda.get_device_name(GPU_NUM))</span><br><span class="line">    print(<span class="string">'Memory Usage:'</span>)</span><br><span class="line">    print(<span class="string">'Allocated:'</span>, round(torch.cuda.memory_allocated(GPU_NUM)/<span class="number">1024</span>**<span class="number">3</span>,<span class="number">1</span>), <span class="string">'GB'</span>)</span><br><span class="line">    print(<span class="string">'Cached:   '</span>, round(torch.cuda.memory_cached(GPU_NUM)/<span class="number">1024</span>**<span class="number">3</span>,<span class="number">1</span>), <span class="string">'GB'</span>)</span><br></pre></td></tr></table></figure><p>위 코드를 실행시키면 0번 GPU를 사용하도록 변경하고, 해당 GPU의 cuda memory 상태를 간략하게 출력한다.</p><p><img src="https://user-images.githubusercontent.com/25416425/77403002-e2a1f700-6df2-11ea-9b8a-d3a6fd23dd10.png" width="600"></p><p>제일 위의 출력 결과물을 확인해 보니, 성공적으로 Current cuda device가 2에서 0으로 바뀌었음을 알 수 있다.</p><p>모쪼록 GPU 서버가지고 싸우지 말고(?) 딥러닝을 즐기도록 하자 :)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;나는 많은 딥러닝 프레임워크 중 Pytorch와 MxNet을 자주 사용하는 편이다.&lt;br&gt;그런데, 연구실 사람들과 GPU 서버를 함께 쓰다 보니 어떤 GPU가 현재 available한지 알아야 할 필요가 있었다.&lt;/p&gt;
&lt;p&gt;원래는 시간대를 적당히 맞춰서 사용하곤 했는데, 멀티 GPU 세팅에 대해서는 잘 모르기도 하고 colab으로는 도저히 불편해서 쓸수가 없었으므로..ㅠㅠ 관련 정보를 찾아보고 그 결과를 간단히 공유하고자 한다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/25416425/77401561-7d4d0680-6df0-11ea-9cfa-b3bb0591f232.jpg&quot; width=&quot;500&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅳ. Deep Learning" scheme="https://jeongwookie.github.io/categories/%E2%85%A3-Deep-Learning/"/>
    
      <category term="Pytorch" scheme="https://jeongwookie.github.io/categories/%E2%85%A3-Deep-Learning/Pytorch/"/>
    
    
  </entry>
  
  <entry>
    <title>패키지 없이 트위터 데이터 수집하기 with Python</title>
    <link href="https://jeongwookie.github.io/2020/02/25/datascience/twitter/1-twitter-data-crawling-without-package/"/>
    <id>https://jeongwookie.github.io/2020/02/25/datascience/twitter/1-twitter-data-crawling-without-package/</id>
    <published>2020-02-25T09:27:19.000Z</published>
    <updated>2021-11-21T11:21:31.959Z</updated>
    
    <content type="html"><![CDATA[<p>이전에 트위터 데이터를 키워드를 기준으로 크롤링하는 글을 쓴적이 있다. 최근 내가 진행하는 연구에서도 트위터 크롤링이 계속 요구되었고, 정말 다양한 패키지와 방법을 사용해 왔다.</p><p>Tweepy나 TwitterScraper 등 좋은 패키지들이 github에 많이 공유되어 있는데, 뭔가 내 맘에 드는 게 없어서 순정으로 돌아가보기로 했다. </p><p>이번 포스트에서는 <u>일절 패키지 없이 트위터 API로만 크롤링</u>을 시도해 볼 것이다. 요즘 대단히 이슈가 되는 코로나 바이러스에 대해서 키워드를 설정하고, 관련 트윗을 수집해 보자!</p><p><img src="https://user-images.githubusercontent.com/25416425/75331914-d8a9d880-58c6-11ea-8781-1ae4dce07e5d.jpg" width="500"></p><a id="more"></a><h2 id="트위터-개발자-등록하기"><a href="#트위터-개발자-등록하기" class="headerlink" title="트위터 개발자 등록하기"></a>트위터 개발자 등록하기</h2><p>먼저, 트위터 공식 API를 사용하려면 인증키를 받아야 한다.<br>본 포스트에서는 관련 프로세스들을 다루지 않겠다. 너무 기본적인 세팅이라.. 각자 알아서 등록하도록!</p><p>간단하게 노트하면,</p><ol><li><a href="https://developer.twitter.com/" rel="external nofollow noopener noreferrer" target="_blank">트위터 개발자 홈페이지</a>에 접속해서 개발자로 신청하기</li><li>App 만들고, OAuth Key 발급 받기</li></ol><p>2번 프로세스에 대해 다른 블로그들 중 설명이 잘 되어있는 곳을 찾았다. <a href="https://ericnjennifer.github.io/python_crawling/2018/01/05/PythonCrawling_Chapt3.html" rel="external nofollow noopener noreferrer" target="_blank">Mark Lee 님의 블로그</a>를 참고해서 키를 발급 받아 옵시다..!!</p><p><img src="https://user-images.githubusercontent.com/25416425/75333305-3b9c6f00-58c9-11ea-9b7f-b65d52b57b6b.png" width="400"></p><p>위와 같이 키를 확인할 수 있다면, 준비는 끝났다.</p><h2 id="트위터-API-연결하기"><a href="#트위터-API-연결하기" class="headerlink" title="트위터 API 연결하기"></a>트위터 API 연결하기</h2><p>이제 파이참 또는 주피터를 열 시간이다.<br>본격적으로 트위터를 수집하기 전, 위에서 발급받은 인증키를 연동시켜, 제대로 연결되었는지 status를 먼저 확인해 보자.</p><p>트위터 공식 API 문서에서는 다양한 형태의 OAuth를 지원하는데, 우리는 OAuth2 를 사용하여 인증할 것이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"></span><br><span class="line"><span class="comment"># 트위터 API 개발자 키를 아래에 입력</span></span><br><span class="line">client_key = <span class="string">'YOUR-CLIENT-KEY'</span></span><br><span class="line">client_secret = <span class="string">'YOUR-CLIENT-SECRET-KEY'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># b64 encoded 형태로 만드는 과정 </span></span><br><span class="line">key_secret = <span class="string">'&#123;&#125;:&#123;&#125;'</span>.format(client_key, client_secret).encode(<span class="string">'ascii'</span>)</span><br><span class="line">b64_encoded_key = base64.b64encode(key_secret)</span><br><span class="line">b64_encoded_key = b64_encoded_key.decode(<span class="string">'ascii'</span>)</span><br></pre></td></tr></table></figure><p>위에서는 b64 형태로 인코딩 된 키를 만들었다. 이제 이를 통해서 트위터 API와 연결하는 코드를 작성한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># request에 필요한 url 만들기</span></span><br><span class="line">base_url = <span class="string">'https://api.twitter.com/'</span></span><br><span class="line">auth_url = <span class="string">'&#123;&#125;oauth2/token'</span>.format(base_url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># HEADER 구성하기</span></span><br><span class="line">auth_headers = &#123;</span><br><span class="line">    <span class="string">'Authorization'</span>: <span class="string">'Basic &#123;&#125;'</span>.format(b64_encoded_key),</span><br><span class="line">    <span class="string">'Content-Type'</span>: <span class="string">'application/x-www-form-urlencoded;charset=UTF-8'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Authentication Data section 만들기</span></span><br><span class="line">auth_data = &#123;</span><br><span class="line">    <span class="string">'grant_type'</span>: <span class="string">'client_credentials'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># POST request를 보내서 status 확인!</span></span><br><span class="line">auth_resp = requests.post(auth_url, headers=auth_headers, data=auth_data)</span><br><span class="line">print(auth_resp.status_code)</span><br></pre></td></tr></table></figure><p>status_code 가 200이 출력되면, 정상적으로 연결된 것이다.</p><h2 id="데이터-수집하기"><a href="#데이터-수집하기" class="headerlink" title="데이터 수집하기"></a>데이터 수집하기</h2><p>위의 코드까지는 세팅이라고 할 수 있으며, 지금부터가 실제 트위터 검색에 사용될 파라미터를 정의하는 구간이다.<br>코로나 바이러스와 연관된 트윗을 수집하는 것이 목표이므로, 키워드를 <strong>“우한폐렴”</strong> 및 <strong>“코로나”</strong> 라고 정했다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Bearer token 정의하기</span></span><br><span class="line">access_token = auth_resp.json()[<span class="string">'access_token'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Search HEADER 구성하기</span></span><br><span class="line">search_headers = &#123;</span><br><span class="line">    <span class="string">'Authorization'</span>: <span class="string">'Bearer &#123;&#125;'</span>.format(access_token)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># SEARCH TWEET</span></span><br><span class="line"><span class="comment"># Maximum number of tweets returned from a single token is 18,000 </span></span><br><span class="line"></span><br><span class="line">search_params = &#123;</span><br><span class="line">    <span class="string">'q'</span>:<span class="string">'우한폐렴 OR 코로나'</span>,</span><br><span class="line">    <span class="string">'result_type'</span>: <span class="string">'recent'</span>, <span class="comment"># 'mixed' or 'popular' 로도 지정 가능</span></span><br><span class="line">    <span class="string">'count'</span>:<span class="number">10</span>, <span class="comment"># 디폴트 값은 15이며, 최대 100까지 지정 가능</span></span><br><span class="line">    <span class="string">'retryonratelimit'</span>:<span class="literal">True</span>, <span class="comment"># rate limit에 도달했을 때 자동으로 다시 trial</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">search_url = <span class="string">'&#123;&#125;1.1/search/tweets.json'</span>.format(base_url)</span><br><span class="line">search_resp = requests.get(</span><br><span class="line">    search_url, headers=search_headers, </span><br><span class="line">    params=search_params</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>위 코드를 살행하면, <code>search_resp</code>에 우리가 원하는 결과값이 저장된다. 위에서는 간단하게 <strong>“최근 10개의 우한폐렴 또는 코로나 라는 단어가 포함된 트윗을 가져와!”</strong> 라고 <code>search_params</code>을 지정했지만, 더 다양한 옵션들이 존재한다. 궁금하면 <a href="https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets" rel="external nofollow noopener noreferrer" target="_blank">트위터 공식 API 문서</a>를 참고하자.</p><h2 id="Rate-Limit-확인하기"><a href="#Rate-Limit-확인하기" class="headerlink" title="Rate Limit 확인하기"></a>Rate Limit 확인하기</h2><p>위에서는 간단하게 10개의 트윗만 수집했지만, 1000개 또는 그 이상의 트윗을 수집하려는 사용자도 분명 있을 것이다. (물론 나도 위 방법으로 100만개 이상을 수집해 왔으니..) 이런 경우에는 트위터에서 명시해 놓은 Rate Limit에 대해서 민감하게 코드를 작성할 필요가 있다.</p><p>방금 위 코드를 실행시켰다면, 트위터 서버에 1번 데이터를 요청한 셈이 된다. 트위터에서 얼마나 요청을 받아줄까?<br>아래의 코드는 rate limit을 확인할 수 있게 해준다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rate limit URL</span></span><br><span class="line">url = <span class="string">'https://api.twitter.com/1.1/application/rate_limit_status.json'</span></span><br><span class="line">search_resp = requests.get(url, headers=search_headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 확인하기</span></span><br><span class="line">json.loads(search_resp.content)[<span class="string">'resources'</span>][<span class="string">'search'</span>]</span><br></pre></td></tr></table></figure><p>위 코드를 그대로 실행시키면, 트위터에서 제공하는 limit가 얼마이고 이 중 현재 남은 사용량이 얼마나 되는지 직관적으로 확인할 수 있다.</p><p>다만, 현재는 출력되는 limit가 450 으로 나오는데 직접 코드를 돌려보니 허용량을 초과하지 않았는데도 크롤러가 멈추는 현상이 있었다. 정확하게 확인하려면 <a href="https://developer.twitter.com/en/docs/developer-utilities/rate-limit-status/api-reference/get-application-rate_limit_status" rel="external nofollow noopener noreferrer" target="_blank">트위터 공식 API Ref</a>을 참고하자. 여기서는 <strong>15분 당 180번 요청 허용</strong> 이라고 나와 있었다.</p><p>참고로, 나는 <code>search_resp.content</code> 내의 정보를 확인하고, error가 존재하는 경우 크롤러를 강제로 15분동안 쉬도록 코드를 작성해서 사용했다.</p><h2 id="데이터-확인하기"><a href="#데이터-확인하기" class="headerlink" title="데이터 확인하기"></a>데이터 확인하기</h2><p>데이터 수집은 완료했고.. 이제 수집된 데이터를 확인해보자.<br>10개의 트윗을 예시로 수집하였고, 이를 <code>pandas</code>로 읽으면 편하다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">Data = json.loads(search_resp.content)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dict -&gt; Dataframe</span></span><br><span class="line">df = pd.DataFrame(Data[<span class="string">'statuses'</span>])</span><br><span class="line">df[[<span class="string">"id"</span>,<span class="string">'created_at'</span>,<span class="string">'text'</span>,<span class="string">'retweet_count'</span>]] <span class="comment"># 몇 개의 칼럼만 확인해보기</span></span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/25416425/75337214-e879ea80-58cf-11ea-91d8-aeb1a00fe3b8.png" width="700"></p><p>잘 보인다! 총 28개의 칼럼이 있는데, 이 중 관심이 있는 4개의 칼럼만 예시로 출력한 것이다. GOOD!!</p><h2 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h2><p>이런 식으로 패키지 없이 트위터에서 제공하는 공식 API로만 트위터를 수집할 수 있다.<br>다만, 공짜로 이용하는 것이기 때문에 기본적으로 standard API와 동일한 제약이 따른다. 무엇인고 하니, rate limit와 같은 속성도 있지만 무엇보다도 full-archive를 보장받지 못한다. 즉, 2월 20일자 트윗 중 “우한폐렴” 및 “코로나” 가 포함된 트윗을 모두 수집하라고 코드를 실행시켜도 모든 트윗을 긁어왔다고 보장해 주지 않는다.</p><p>다시 한번 한계점을 정리해 본다면,</p><ol><li>트윗을 성공적으로 크롤링 하여도, 기간 내 모든 트윗을 수집하였다고 보장하지 못한다.</li><li>Standard API의 한계 때문에, 오늘을 기준으로 7일 이전의 데이터만 크롤링이 가능하다.</li></ol><p>한계점을 극복하려면, 어쩔수 없이 다른 파이썬 패키지 또는 Premium API를 결제해야 한다.<br>그러나 미리미리 트위터를 주기적으로 크롤링 해 놓는다면, 공짜로 양질의 데이터를 손쉽게 얻을 수 있을 것이다.</p><p>아래는 트윗 10개 말고 100개를 긁어왔을 때 간단하게 frequency를 1초 별로 그려본 것이다. 예쁘게 잘 나오는군 후후</p><p><img src="https://user-images.githubusercontent.com/25416425/75339811-92f40c80-58d4-11ea-9cb2-c38f48489bf6.png" width="400"></p><p>끝!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;이전에 트위터 데이터를 키워드를 기준으로 크롤링하는 글을 쓴적이 있다. 최근 내가 진행하는 연구에서도 트위터 크롤링이 계속 요구되었고, 정말 다양한 패키지와 방법을 사용해 왔다.&lt;/p&gt;
&lt;p&gt;Tweepy나 TwitterScraper 등 좋은 패키지들이 github에 많이 공유되어 있는데, 뭔가 내 맘에 드는 게 없어서 순정으로 돌아가보기로 했다. &lt;/p&gt;
&lt;p&gt;이번 포스트에서는 &lt;u&gt;일절 패키지 없이 트위터 API로만 크롤링&lt;/u&gt;을 시도해 볼 것이다. 요즘 대단히 이슈가 되는 코로나 바이러스에 대해서 키워드를 설정하고, 관련 트윗을 수집해 보자!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/25416425/75331914-d8a9d880-58c6-11ea-8781-1ae4dce07e5d.jpg&quot; width=&quot;500&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅰ. Data Science" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/"/>
    
      <category term="트위터 데이터 분석하기" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/%ED%8A%B8%EC%9C%84%ED%84%B0-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0/"/>
    
    
      <category term="Python" scheme="https://jeongwookie.github.io/tags/Python/"/>
    
      <category term="Datamining" scheme="https://jeongwookie.github.io/tags/Datamining/"/>
    
      <category term="Twitter" scheme="https://jeongwookie.github.io/tags/Twitter/"/>
    
  </entry>
  
  <entry>
    <title>Khaiii 형태소 분석기 사용하기</title>
    <link href="https://jeongwookie.github.io/2019/11/17/datascience/koreannlp/1-khaiii-korean-tokenizer/"/>
    <id>https://jeongwookie.github.io/2019/11/17/datascience/koreannlp/1-khaiii-korean-tokenizer/</id>
    <published>2019-11-17T09:36:23.000Z</published>
    <updated>2021-11-21T11:21:23.002Z</updated>
    
    <content type="html"><![CDATA[<p>한국어로 된 데이터를 분석할 때, 이를 적절한 형태로 토크나이즈 (tokenize)하는 과정은 반드시 필요하다.</p><p>특히나 한국어는 영어와 달리 최소 의미 전달이 단어로 이루어진 언어가 아니기 때문에 형태소 단위로 잘라주는 패키지를 자주 사용한다.</p><p>오늘은 내가 평소에 자주 사용하는 형태소 분석기 중 <strong>Khaiii 형태소 분석기</strong> 에 대해 포스팅하고자 한다.</p><p><strong>Khaiii</strong> 는 카카오에서 18년도 말에 공개한 딥러닝 기반의 형태소 분석기이다. 기존의 사전 의존 방법과는 달리 세종 코퍼스 약 1000만 어절을 학습하여 형태소 단위로 분리한다고 한다.</p><p><img src="https://user-images.githubusercontent.com/25416425/69005815-8b82a600-096a-11ea-85da-f30967fa6f26.png" width="450"></p><a id="more"></a><h2 id="설치하기"><a href="#설치하기" class="headerlink" title="설치하기"></a>설치하기</h2><p>설치가 생각보다 까다롭다. 오래전에 설치하여 정확한 프로세스는 잘 기억이 나지 않지만, 상당히 많은 에러 동반 끝에 설치한 기억이..</p><p>기본적으로 리눅스 환경에서만 지원한다. 윈도우에서도 할 수 있는 방법이 있는지는 잘 모르겠다.</p><p>나는 한번 설치의 어려움을 경험한 후, 다시는 리눅스 커멘드로 일일히 설치하지 않는다. 대신 도커파일을 받아서 그대로 활용한다. 도커 파일의 경우 <a href="https://github.com/kakao/khaiii/blob/master/docker/Dockerfile" rel="external nofollow noopener noreferrer" target="_blank">여기</a>를 참고하자.</p><p>위 도커파일로 Khaiii를 설치 후, 원하는 세팅을 해서 나만의 도커 이미지를 만들어 놓으면 세팅 하는데 시간을 획기적으로 줄일 수 있다. 도커 사용법의 경우 시간 날때 천천히 정리할 계획.</p><h2 id="사용하기"><a href="#사용하기" class="headerlink" title="사용하기"></a>사용하기</h2><p>설치를 완료했다면, 이제 사용해 보자. 주피터 노트북에서 아래와 같은 코드를 실행한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> khaiii <span class="keyword">import</span> KhaiiiApi</span><br><span class="line">api = KhaiiiApi(rsc_dir=<span class="string">'/deps/khaiii/build/share/khaiii'</span>) <span class="comment"># 내 설치 경로</span></span><br><span class="line"></span><br><span class="line">morphs = []</span><br><span class="line">sentence = <span class="string">"하스스톤 전장이 새로 나왔는데 재밌어요!"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> api.analyze(sentence):</span><br><span class="line">    <span class="keyword">for</span> morph <span class="keyword">in</span> word.morphs:</span><br><span class="line">        morphs.append((morph.lex, morph.tag))</span><br></pre></td></tr></table></figure><p>적당한 sentence로 출력을 해보면 아래와 같이 형태소 단위로 잘 토크나이즈 된 것을 확인할 수 있다.</p><p><img src="https://user-images.githubusercontent.com/25416425/69006362-81b07100-0971-11ea-87cf-aae710ba18c1.png" width="350"></p><p>위 코드에서 <code>rsc_dir</code> 부분은 현재는 중요하지 않지만, 기분석 사전이나 오분석 패치 기능을 활용할 때 엄청 중요하다. 먼저 짚고 넘어가보자.</p><p>대부분이 비슷한 경로에 설치가 될 것 같은데 혹시 모르니 커멘드 창에 아래와 같은 코드를 입력한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find / -name <span class="string">'khaiii*'</span> -type d</span><br></pre></td></tr></table></figure><p>khaiii 라는 이름을 가진 디렉토리를 모두 찾으라는 뜻이다. 코드를 실행하여 <code>/deps/khaiii/build/share/khaiii&#39;</code> 와 비슷하게 share 폴더 안의 khaiii의 경로를 찾으면 된다.</p><h2 id="기분석-사전-추가"><a href="#기분석-사전-추가" class="headerlink" title="기분석 사전 추가"></a>기분석 사전 추가</h2><p>기분석 사전이란 내가 원하는 단일 어절에 대해, 문맥에 상관없이 일괄적인 분석 결과를 얻고 싶을 때 추가한다.</p><p>기본적인 사용 방법은 <a href="https://github.com/kakao/khaiii/wiki/%EA%B8%B0%EB%B6%84%EC%84%9D-%EC%82%AC%EC%A0%84" rel="external nofollow noopener noreferrer" target="_blank">Khaiii 깃헙 페이지</a>에 잘 정리되어 있다.</p><p>페이지에 적힌 대로 사전 형식은 따라하면 되는데, 내가 문제를 겪은 부분은 다름 아닌 사전 빌드였다.</p><p><img src="https://user-images.githubusercontent.com/25416425/69006983-d99fa580-097a-11ea-8517-d54d5ee830af.png" width="550"></p><p>요약하자면, modulenotfounderror: no module named ‘khaiii.munjong’ 이런 에러가 뜬다.</p><p>대부분이 <code>PYTHONPATH</code> 경로 문제인데, 위와 유사한 방법으로 찾아보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find / -name <span class="string">'munjong*'</span> -type d</span><br></pre></td></tr></table></figure><p>위 코드로 <code>munjong</code> 이 있는 디렉토리 위치를 찾는다. 나는 약 4개의 디렉토리 위치가 떴는데, 이중에서 적당히 파이썬 위치가 어딜까 하고 보니 보인다.</p><p><img src="https://user-images.githubusercontent.com/25416425/69007060-2768dd80-097c-11ea-881d-3a4a3dbe53e4.png" width="550"></p><p>이제 위치를 찾았으니, <code>PYTHONPATH</code> 경로를 수정한 코드를 차례대로 커멘드 창에 입력하여 사전을 빌드하면 된다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd rsc <span class="comment"># 어디에 있던 rsc로 와서 실행하기</span></span><br><span class="line">mkdir -p ../build/share/khaiii</span><br><span class="line">PYTHONPATH=/deps/khaiii/src/main/python/ ./bin/compile_preanal.py --rsc-src=./src --rsc-dir=/deps/khaiii/build/share/khaiii</span><br></pre></td></tr></table></figure><p>빌드 완료! 혹시 빌드한 사전이 적용이 안된다면, <code>rsc_dir</code> 경로를 다시 확인하자.</p><h2 id="오분석-패치"><a href="#오분석-패치" class="headerlink" title="오분석 패치"></a>오분석 패치</h2><p>오분석 패치는 기계학습 모델의 결과로 출력된 결과가 오분석일 경우, 이를 원하는 정분석으로 바로잡을 수 있는 사용자 사전이다.</p><p>기분석 사전과 마찬가지로 기본적인 사용 방법은 <a href="https://github.com/kakao/khaiii/wiki/%EC%98%A4%EB%B6%84%EC%84%9D-%ED%8C%A8%EC%B9%98" rel="external nofollow noopener noreferrer" target="_blank">Khaiii 깃헙 페이지</a>에 잘 정리되어 있다.</p><p>정해진 포멧을 맞추어 등록하고, 이를 빌드하면 되는데 위의 오분석 패치와 마찬가지로 약간의 코드 수정이 필요하다. (PYTHONPATH 부분)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd rsc <span class="comment"># 어디에 있던 rsc로 와서 실행하기</span></span><br><span class="line">mkdir -p ../build/share/khaiii</span><br><span class="line">PYTHONPATH=/deps/khaiii/src/main/python/  ./bin/compile_errpatch.py --model-size=base --rsc-src ./src --rsc-dir=/deps/khaiii/build/share/khaiii</span><br></pre></td></tr></table></figure><p>빌드 완료!</p><h2 id="맺음말"><a href="#맺음말" class="headerlink" title="맺음말"></a>맺음말</h2><p>Khaiii 형태소 분석기를 사용해보면 딥러닝 기반인데 사전 기반처럼 정확하게 작동함을 확인할 수 있다.</p><p>그러나, 아쉬운 점은 띄어쓰기가 잘 안된 비문들을 넣으면 기존에 잘 사용하는 <code>Mecab</code> 형태소 분석기보다 성능이 조금 떨어진다.</p><p>그리고 내가 다루는 데이터 안에 ‘후쿠시마’ 라는 단어가 있는데, 이를 <code>Mecab</code>을 사용했을 땐 몰랐는데 자꾸 후 + 쿠시마 또는 후쿠시 + 마 로 오분석이 되더라.. 기분석 사전에 추가하는 번거로움이 있었다.</p><p>서로 장단점이 있으니 적절하게 사용하면 될 것 같다.</p><p>기분석 사전 및 오분석 패치 사전 작성 시에 기본 한글 형태소 품사표를 알고 싶다면 <a href="http://kkma.snu.ac.kr/documents/?doc=postag" rel="external nofollow noopener noreferrer" target="_blank">한글 형태소 품사 (POS) 태그표</a>를 참고하자.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;한국어로 된 데이터를 분석할 때, 이를 적절한 형태로 토크나이즈 (tokenize)하는 과정은 반드시 필요하다.&lt;/p&gt;
&lt;p&gt;특히나 한국어는 영어와 달리 최소 의미 전달이 단어로 이루어진 언어가 아니기 때문에 형태소 단위로 잘라주는 패키지를 자주 사용한다.&lt;/p&gt;
&lt;p&gt;오늘은 내가 평소에 자주 사용하는 형태소 분석기 중 &lt;strong&gt;Khaiii 형태소 분석기&lt;/strong&gt; 에 대해 포스팅하고자 한다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Khaiii&lt;/strong&gt; 는 카카오에서 18년도 말에 공개한 딥러닝 기반의 형태소 분석기이다. 기존의 사전 의존 방법과는 달리 세종 코퍼스 약 1000만 어절을 학습하여 형태소 단위로 분리한다고 한다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/25416425/69005815-8b82a600-096a-11ea-85da-f30967fa6f26.png&quot; width=&quot;450&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅰ. Data Science" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/"/>
    
      <category term="한국어 형태소 분석기" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/%ED%95%9C%EA%B5%AD%EC%96%B4-%ED%98%95%ED%83%9C%EC%86%8C-%EB%B6%84%EC%84%9D%EA%B8%B0/"/>
    
    
      <category term="Python" scheme="https://jeongwookie.github.io/tags/Python/"/>
    
      <category term="Datamining" scheme="https://jeongwookie.github.io/tags/Datamining/"/>
    
      <category term="Korean NLP" scheme="https://jeongwookie.github.io/tags/Korean-NLP/"/>
    
  </entry>
  
  <entry>
    <title>2019년 여름, 연구실에서 근황</title>
    <link href="https://jeongwookie.github.io/2019/07/23/others/school/5-my-summer-these-days/"/>
    <id>https://jeongwookie.github.io/2019/07/23/others/school/5-my-summer-these-days/</id>
    <published>2019-07-23T12:53:57.000Z</published>
    <updated>2021-11-21T11:26:34.684Z</updated>
    
    <content type="html"><![CDATA[<p>쓰고 싶은 주제들은 많은데.. 요즘 블로그를 거의 못하고 있다 ㅠㅠ</p><p>덥기도 하고, 연구실에서 해야할 일도 많고 행사도 있고 정신이 없는듯.</p><p>매일 운동도 빠짐없이 하고 싶은데 밥을 제때 못먹어서 힘이 없어서 못하기도 하고, 미팅이 길어져서 타이밍을 놓치기도 하고..</p><p>그래도 간간히 블로그 들러주셔서 메일 주시는 분들이 몇 계시다는 데에 만족중 ㅋㅋ</p><p>현재 두 가지의 프로젝트에 involve 하는 중인데, 열심히는 하고 있지만 아직 갈길이 멀었다.</p><ol><li><p>네이버 뉴스 및 댓글 데이터를 바탕으로 정치적 편향성을 가진 사용자의 반응 연구</p></li><li><p>원자력 발전소와 관련한 트윗을 크롤링하여 루머의 확산에 관한 연구</p></li></ol><p>방학 때 좀 빡세게 해서 결과가 좀 나오면.. 탑 티어 컨퍼런스인 CHI나 ICWSM에 도전해 보고 싶다!! </p><p>이외에도, 최근 한 일중에 미래에 도움될 만한 일이 있다면.. <strong>도커 (Docker)</strong> 세팅을 해본 것?</p><p>처음 만져보니까 버벅대긴 했는데.. 어찌어찌 해서 나의 전용 도커파일도 만들고 내가 원하는 자연어 처리 세팅을 완료했다.</p><p>또 막상 끝내고 나니까 가르쳐주는 건 쉽더라. 시간 될 때 리마인드 겸 도커 세팅과 관련된 포스트를 작성할 계획이다.</p><p>친구들한테 물어보니, 기업에서 도커 다루는 것은 거의 필수라고 하더라고 ㅋㅋㅋ 공부한 셈 치고 머리 박은 시간들은 넘어가는 걸로. 다음엔 안헤메겠지뭐!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;쓰고 싶은 주제들은 많은데.. 요즘 블로그를 거의 못하고 있다 ㅠㅠ&lt;/p&gt;
&lt;p&gt;덥기도 하고, 연구실에서 해야할 일도 많고 행사도 있고 정신이 없는듯.&lt;/p&gt;
&lt;p&gt;매일 운동도 빠짐없이 하고 싶은데 밥을 제때 못먹어서 힘이 없어서 못하기도 하고,
      
    
    </summary>
    
      <category term="Ⅹ. Others" scheme="https://jeongwookie.github.io/categories/%E2%85%A9-Others/"/>
    
      <category term="학교 이야기" scheme="https://jeongwookie.github.io/categories/%E2%85%A9-Others/%ED%95%99%EA%B5%90-%EC%9D%B4%EC%95%BC%EA%B8%B0/"/>
    
    
      <category term="Daily life" scheme="https://jeongwookie.github.io/tags/Daily-life/"/>
    
  </entry>
  
  <entry>
    <title>Data Crawling - 크롤러 속도를 높이는 멀티프로세싱 (multiprocessing)</title>
    <link href="https://jeongwookie.github.io/2019/06/29/datascience/datacrawling/5-multiprocessing-crawler/"/>
    <id>https://jeongwookie.github.io/2019/06/29/datascience/datacrawling/5-multiprocessing-crawler/</id>
    <published>2019-06-29T09:01:17.000Z</published>
    <updated>2021-11-21T11:21:14.928Z</updated>
    
    <content type="html"><![CDATA[<p>이번에는 크롤러의 속도를 높이는 방법 중 하나를 알아보자.</p><p>우리가 10000개의 유저 데이터를 수집한다고 가정하면, 지금까지는 처음부터 차례대로 하나씩 수집한 것이다.</p><p>그런데 만약 동일한 기능을 하는 프로그램 창을 여러개 띄우고, 2500개씩 나누어 4개의 창으로 동시에 데이터를 수집하면 어떨까?</p><p>이런 것을 가능하게 하는 것이 바로 파이썬의 기본 모듈 중 하나인 멀티프로세싱 (multiprocessing)이다.</p><p><img src="https://user-images.githubusercontent.com/25416425/60382111-6237ab00-9a99-11e9-8500-c76666317467.png" width="450"></p><a id="more"></a><p>지금부터, 트위터에서 유저 데이터 (username, joined date, total tweets, followings, followers)를 멀티프로세싱을 통해 속도를 개선한 크롤러로 수집해 보겠다.</p><p>수집할 트윗은 요즘 결승 라운드를 시작하여 매우 핫한 “슈퍼밴드” 를 포함한 트윗으로, 6월 21일부터 6월 28일까지의 기간으로 정했다.</p><p>편의를 위해 트윗을 수집할 때 직접 수집하지 않고 앞서 사용하였던 <strong>GetOldTweet3</strong> 을 임포트 하였다. 자세한 내용은 <a href="https://jeongwookie.github.io/2019/06/10/190610-twitter-data-crawling/">여기</a>를 참고하자.</p><h2 id="트윗-수집하기"><a href="#트윗-수집하기" class="headerlink" title="트윗 수집하기"></a>트윗 수집하기</h2><p>먼저, <strong>GetOldTweet3</strong> 을 사용하여 특정 검색어를 포함한 트윗을 먼저 수집하고, 이런 트윗을 작성한 유저들의 닉네임 (username)을 리스트로 반환해 보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import packages</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> GetOldTweets3 <span class="keyword">as</span> got</span><br><span class="line"></span><br><span class="line"><span class="comment"># 트윗 수집하는 함수 정의</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_tweets</span><span class="params">(start_date, end_date, keyword)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 범위 끝을 포함하게 만듬</span></span><br><span class="line">    end_date = (datetime.datetime.strptime(end_date, <span class="string">"%Y-%m-%d"</span>) </span><br><span class="line">                + datetime.timedelta(days=<span class="number">1</span>)).strftime(<span class="string">"%Y-%m-%d"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 트윗 수집 기준 설정</span></span><br><span class="line">    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(<span class="string">'&#123;&#125;'</span>.format(keyword))\</span><br><span class="line">                                            .setSince(start_date)\</span><br><span class="line">                                            .setUntil(end_date)\</span><br><span class="line">                                            .setMaxTweets(<span class="number">-1</span>) <span class="comment"># 모두 수집</span></span><br><span class="line">    </span><br><span class="line">    print(<span class="string">"==&gt; Collecting data start.."</span>)</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    tweets = got.manager.TweetManager.getTweets(tweetCriteria)</span><br><span class="line">    print(<span class="string">"==&gt; Collecting data end.. &#123;0:0.2f&#125; minutes"</span>.format((time.time() - start_time)/<span class="number">60</span>))</span><br><span class="line">    print(<span class="string">"=== Total number of tweets is &#123;&#125; ==="</span>.format(len(tweets)))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> tweets</span><br><span class="line"></span><br><span class="line"><span class="comment"># 유저 리스트 반환하는 함수 정의</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_users</span><span class="params">(tweets)</span>:</span></span><br><span class="line">    </span><br><span class="line">    user_list = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> tweets:</span><br><span class="line">        username = index.username</span><br><span class="line">        user_list.append(username)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> user_list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 유저 리스트 수집하기</span></span><br><span class="line">tweets = get_tweets(<span class="string">"2019-06-21"</span>, <span class="string">"2019-06-28"</span>, <span class="string">"슈퍼밴드"</span>)</span><br><span class="line">users = get_users(tweets)</span><br><span class="line"></span><br><span class="line">&gt; ==&gt; Collecting data start..</span><br><span class="line">&gt; ==&gt; Collecting data end.. 4.45 minutes</span><br><span class="line">&gt; === Total number of tweets <span class="keyword">is</span> <span class="number">3456</span> ===</span><br></pre></td></tr></table></figure><p><code>get_tweets()</code>으로 2019년 06월 21일부터 2019년 06년 28일까지 키워드 “슈퍼밴드” 를 포함한 트윗을 먼저 수집하고, <code>get_users()</code>으로 트윗을 작성한 유저의 닉네임을 리스트로 만들어 <code>users</code>에 저장하였다.</p><p>총 5분 가량 소요되었고, 조건을 만족하는 트윗은 3456개임을 확인하였다.</p><h2 id="logger-정의하기"><a href="#logger-정의하기" class="headerlink" title="logger 정의하기"></a>logger 정의하기</h2><p>본격적으로 멀티프로세싱에 들어가기 전, 효과적으로 결과를 볼 수 있도록 도와주는 로깅 (logging)을 먼저 소개하고자 한다.</p><p>로깅 (logging)이란 현재 우리의 프로그램이 어떤 상태를 가지고 있는지 외부 출력을 하게 만들어서, 개발자들이 프로그램의 상황을 직접 눈으로 확인할 수 있도록 하는 것이다.</p><p>얼핏 보면 우리가 지금까지 사용한 <code>print()</code>와 유사하지만, 다양한 옵션의 출력을 미리 세팅해 둘 수 있어서 훨씬 유연하게 상황에 따라 대처할 수 있다.</p><p>코드부터 살펴보자. 파이썬 기본 모듈이므로 따로 설치할 필요는 없다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> logging.handlers</span><br><span class="line"></span><br><span class="line"><span class="comment"># logging 설정</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_logger</span><span class="params">()</span>:</span></span><br><span class="line">    logger = logging.getLogger(<span class="string">"my"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> len(logger.handlers) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> logger</span><br><span class="line">    </span><br><span class="line">    logger.setLevel(logging.INFO)</span><br><span class="line">    stream_hander = logging.StreamHandler()</span><br><span class="line">    logger.addHandler(stream_hander)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> logger</span><br></pre></td></tr></table></figure><p><em>my</em> 라는 로거 (logger)를 정의하고, <code>INFO</code> 이상의 등급에 해상하는 로그만 출력하도록 <code>setLevel()</code>을 통해 설정하였다. 또한 프로그램 실행과 동시에 결과를 보여줄 수 있도록 핸들러를 정의하고, 이를 콘솔창에 출력하도록 하였다.</p><p>또한, 로그가 중복되어 두번씩 출력되는 현상을 방지하기 위해 <code>logging.handlers</code>를 이미 불러온 경우에는 또 불러오지 않도록 중간에 if문을 넣었다.</p><p>대단히 간단한 옵션들만 사용한 것인데, 자세한 내용은 <a href="https://hamait.tistory.com/880" rel="external nofollow noopener noreferrer" target="_blank">이승현님의 블로그</a>를 참고하자. 여러가지 옵션에 대해서 상세히 다루어 놓았다.</p><h2 id="유저-데이터-수집하기"><a href="#유저-데이터-수집하기" class="headerlink" title="유저 데이터 수집하기"></a>유저 데이터 수집하기</h2><p>아까 수집해 놓은 유저 닉네임 (username)을 바탕으로, 유저 데이터를 수집해 보자.</p><p>수집에 사용할 툴은 <code>bs4</code> 패키지의 <code>BeautlfulSoup</code>이며, <em>lxml</em> 형식으로 데이터를 받아올 것이다. </p><p>수집할 유저 데이터는 유저 닉네임, 가입일, 전체 작성 트윗수, 팔로워수, 팔로잉수 이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawl_userdata</span><span class="params">(username)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># setting</span></span><br><span class="line">    url = <span class="string">'https://twitter.com/&#123;&#125;'</span>.format(username)</span><br><span class="line">    mylogger.info(<span class="string">"&#123;&#125; 유저의 데이터 수집 시작"</span>.format(username))</span><br><span class="line">    HEADER = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'</span>&#125;</span><br><span class="line">    response = requests.get(url, headers=HEADER)</span><br><span class="line">    html = response.text</span><br><span class="line"></span><br><span class="line">    <span class="comment"># parsing</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">"lxml"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># parsing fail</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_profile_header = soup.find(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>:<span class="string">'ProfileHeaderCard'</span>&#125;)</span><br><span class="line">        user_profile_canopy = soup.find(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>:<span class="string">'ProfileCanopy-nav'</span>&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># data collect</span></span><br><span class="line">        user = user_profile_header.find(<span class="string">'a'</span>, &#123;<span class="string">'class'</span>:<span class="string">'ProfileHeaderCard-nameLink u-textInheritColor js-nav'</span>&#125;)[<span class="string">'href'</span>].strip(<span class="string">"/"</span>) </span><br><span class="line"></span><br><span class="line">        date_joined = user_profile_header.find(<span class="string">'div'</span>, &#123;<span class="string">'class'</span>:<span class="string">"ProfileHeaderCard-joinDate"</span>&#125;).find(<span class="string">'span'</span>, &#123;<span class="string">'class'</span>:<span class="string">'ProfileHeaderCard-joinDateText js-tooltip u-dir'</span>&#125;)[<span class="string">'title'</span>]</span><br><span class="line">        date_joined = date_joined.split(<span class="string">"-"</span>)[<span class="number">1</span>].strip()</span><br><span class="line">        <span class="keyword">if</span> date_joined <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            data_joined = <span class="string">"Unknown"</span></span><br><span class="line"></span><br><span class="line">        tweets = user_profile_canopy.find(<span class="string">'span'</span>, &#123;<span class="string">'class'</span>:<span class="string">"ProfileNav-value"</span>&#125;)[<span class="string">'data-count'</span>]</span><br><span class="line">        <span class="keyword">if</span> tweets <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            tweets = <span class="number">0</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">except</span> AttributeError:</span><br><span class="line">        mylogger.info(<span class="string">"&#123;&#125; 유저의 데이터 수집 중 알수없는 오류가 발생했습니다."</span>.format(username))</span><br><span class="line">        mylogger.info(<span class="string">"링크 : &#123;&#125;"</span>.format(url))</span><br><span class="line">        user, date_joined, tweets, following, followers = username, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 블락 계정 특징 : 팔로워, 팔로잉 수가 안보임</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line"></span><br><span class="line">        test_following = user_profile_canopy.find(<span class="string">'li'</span>, &#123;<span class="string">'class'</span>:<span class="string">"ProfileNav-item ProfileNav-item--following"</span>&#125;)</span><br><span class="line">        test_followers = user_profile_canopy.find(<span class="string">'li'</span>, &#123;<span class="string">'class'</span>:<span class="string">"ProfileNav-item ProfileNav-item--followers"</span>&#125;)</span><br><span class="line"></span><br><span class="line">        following = test_following.find(<span class="string">'span'</span>, &#123;<span class="string">'class'</span>:<span class="string">"ProfileNav-value"</span>&#125;)[<span class="string">'data-count'</span>]</span><br><span class="line">        followers = test_followers.find(<span class="string">'span'</span>, &#123;<span class="string">'class'</span>:<span class="string">"ProfileNav-value"</span>&#125;)[<span class="string">'data-count'</span>]</span><br><span class="line"></span><br><span class="line">        mylogger.info(<span class="string">"&#123;&#125; 유저의 데이터 수집 완료"</span>.format(username))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> AttributeError:</span><br><span class="line">        mylogger.info(<span class="string">"&#123;&#125; 유저는 블락된 계정입니다."</span>.format(username))</span><br><span class="line">        following = <span class="string">"Block"</span></span><br><span class="line">        followers = <span class="string">"Block"</span></span><br><span class="line"></span><br><span class="line">    result = [user, date_joined, tweets, following, followers]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>트위터 데이터를 어려번 수집하여 보니 안 사실인데, 트위터의 정책상 블락 (block)된 유저들은 가입일이나 전체 작성한 트윗 수 등은 조회가 가능하지만, 팔로잉 수나 팔로워 수는 보이지 않는다. 처음에는 이런 정보를 유저가 선택적으로 오픈할 수 있는 옵션이 있는지 의심했지만, 그런 옵션은 공식적으로 제공하지 않았다.</p><p>중간중간에 <code>try-except</code>문을 사용하여 위와 같은 경우를 방지하였다. <code>BeautifulSoup</code>을 통해 원하는 데이터를 수집하는 부분은 따로 설명하지 않았다. 좀 더 알고 싶다면 <a href="https://jeongwookie.github.io/2019/03/18/190318-naver-finance-data-crawling-using-python/">과거에 작성한 글</a>이 있으니 참고.</p><h2 id="멀티프로세싱-사용하기"><a href="#멀티프로세싱-사용하기" class="headerlink" title="멀티프로세싱 사용하기"></a>멀티프로세싱 사용하기</h2><p>모든 준비가 끝났다. 이제 실제 코드를 멀티프로세싱을 통해서 병렬화 하여 돌리면 된다. (병렬 크롤링)</p><p>유의할 점은, 멀티프로세싱을 사용할 때, <code>main()</code>이 무엇인지 정확히 언급해 주어야 오류를 방지할 수 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"></span><br><span class="line"><span class="comment"># 유저 정보 Multiprocessing</span></span><br><span class="line"><span class="keyword">global</span> user_info</span><br><span class="line">user_info = []</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    user_list = users</span><br><span class="line">    pool_size = len(user_list)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> pool_size &lt; <span class="number">8</span>:</span><br><span class="line">        pool = Pool(pool_size)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        pool = Pool(<span class="number">8</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> pool.map(crawl_userdata, user_list):</span><br><span class="line">        user_info.append(user)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    </span><br><span class="line">    start_time = time.time()</span><br><span class="line">    </span><br><span class="line">    mylogger = get_logger()</span><br><span class="line">    mylogger.info(<span class="string">"유저 정보 수집 시작"</span>)</span><br><span class="line">    </span><br><span class="line">    main()</span><br><span class="line">    </span><br><span class="line">    end_time = (time.time() - start_time)/<span class="number">60</span></span><br><span class="line">    mylogger.info(<span class="string">"유저 정보 수집 종료.. &#123;0:0.2f&#125; 분 소요"</span>.format(end_time))</span><br><span class="line">    mylogger.info(<span class="string">"총 수집된 유저 정보는 &#123;&#125; 개 입니다."</span>.format(len(user_info)))</span><br></pre></td></tr></table></figure><p><code>Pool</code>은, 몇개의 창을 열어서 동시에 프로그램을 돌릴지 정의하는 함수이다. 위 코드에서는 우리가 수집할 데이터의 갯수가 8 이하일 경우에는 그 숫지만큼, 아닐 경우 8개를 동시에 실행해서 수집하도록 셋팅하였다.</p><p>이어서 <code>pool.map()</code>으로 적용하고 싶은 함수 <code>crawl_userdata()</code>와 그 적용 대상이 되는 <code>user_list</code>을 차례로 적고 for문을 완성한다.</p><p>위 코드를 실행시켜보면, 총 3456개의 유저 정보가 <u>단 10분만에 크롤링 됨</u>을 확인할 수 있다.</p><p><img src="https://user-images.githubusercontent.com/25416425/60386591-e1e16c00-9ad1-11e9-8c41-fca71061bddb.png" width="700"></p><p>결과가 어떤 형태로 나오는지 보여주기 위해, 해당 트윗도 추가해서 위와 같이 출력해 보았다.</p><p>위의 정보 뿐만 아니라 트윗의 업로드 시각, 리트윗 수, 관심글 수, 지역 등의 데이터를 추가로 수집 가능하다.</p><p>이전 다루었던 트위터 데이터 크롤링의 코드로 실행하면 거의 3시간씩 걸린 작업을 멀티 프로세싱을 통해 대단히 빠른 속도로 시간을 단축시켜 보았다.</p><p>하지만, 이는 공격적인 크롤링으로 오인받아 일부 사이트의 경우 차단당할 우려가 있으므로.. 상황에 맞게 조심스레(?) 사용하자.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;이번에는 크롤러의 속도를 높이는 방법 중 하나를 알아보자.&lt;/p&gt;
&lt;p&gt;우리가 10000개의 유저 데이터를 수집한다고 가정하면, 지금까지는 처음부터 차례대로 하나씩 수집한 것이다.&lt;/p&gt;
&lt;p&gt;그런데 만약 동일한 기능을 하는 프로그램 창을 여러개 띄우고, 2500개씩 나누어 4개의 창으로 동시에 데이터를 수집하면 어떨까?&lt;/p&gt;
&lt;p&gt;이런 것을 가능하게 하는 것이 바로 파이썬의 기본 모듈 중 하나인 멀티프로세싱 (multiprocessing)이다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/25416425/60382111-6237ab00-9a99-11e9-8500-c76666317467.png&quot; width=&quot;450&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅰ. Data Science" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/"/>
    
      <category term="데이터 크롤링" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%81%AC%EB%A1%A4%EB%A7%81/"/>
    
    
      <category term="Python" scheme="https://jeongwookie.github.io/tags/Python/"/>
    
      <category term="Datamining" scheme="https://jeongwookie.github.io/tags/Datamining/"/>
    
      <category term="Twitter" scheme="https://jeongwookie.github.io/tags/Twitter/"/>
    
  </entry>
  
  <entry>
    <title>19년 카이스트 봄학기 후기</title>
    <link href="https://jeongwookie.github.io/2019/06/28/others/school/4-spring-semester-finish/"/>
    <id>https://jeongwookie.github.io/2019/06/28/others/school/4-spring-semester-finish/</id>
    <published>2019-06-28T07:03:25.000Z</published>
    <updated>2021-11-21T11:26:17.325Z</updated>
    
    <content type="html"><![CDATA[<p>카이스트에서의 도전적인(?) 한 학기가 드디어 끝났다.</p><p>정말 많은 일들을 한꺼번에 진행하느라 힘들었지만, 그만큼 의미있었던 한 학기였다.</p><p>나의 무기를 가지고 싶어 시작했던 일들이었던 만큼, 재미있고 가슴뛰는 무언가를 찾아서 움직였던 과거와는 달리 모든 일에 조금 진지하게 임하였던 것 같다.</p><a id="more"></a><p>나는 데이터 가반의 의사 결정 방법이 스타트업의 서비스 설계에 있어 대단히 중요하다고 생각한다.</p><p>단순히 데이터를 쌓아놓고, 그 후에 어떻게 이 데이터를 읽어낼 것인가를 이야기 하는 것이 아니라, 첫 단계부터 어떤 유저들에게 어떤 데이터를 수집할 것인지, 그것을 어떻게 처리하여 다시 우리의 유저에게 어떤 영향을 미칠 것인지 그 시스템 자체를 설계하기를 원했다.</p><p>지금까지 해왔던 것 처럼, 경영 분야의 지식을 익히고 또 다른 창업 팀에서 활동하는 선택지도 분명 있었다.</p><p>하지만, 스스로 해보고 싶어졌다. 창업을 경험하면서 조금만 진전이 없으면 따라오던 답없는 질문.. 내가 정말 잘하는 것이 무엇인가? 나는 정말 대체가능한 인원이 아닌건가? 우리 회사의 성장에 꼭 필요한 인재일까? 하는 의문들…</p><p>나 스스로에게 무기를 쥐어주고 싶었다. 창업이 원래 답없고 실패 확률이 매우 높은 일 아닌가. 뭐라도 믿는 구석이 있어야 뚝심있게 밀고 나갈 수 있는 것 같다. 스스로에게 자신감이 떨어지면 이도저도 어렵지 않을까. </p><p>그래서 다시 코딩을 시작했다. 학부때 기본 과정은 들었고, 수학에 자신이 있었기 때문에 어떻게든 할 수 있지 않을까 생각했다.</p><p>기회가 되어 기초과학연구원의 데이터 사이언스 연구실에서 일할 수 있게 되었고, 데이터를 직접 수집하기 시작했다. </p><p>동시에 카이스트 전산학부 및 산업공학과의 빅데이터, 알고리즘, 머신러닝 및 딥러닝 관련 전공 수업들을 전부 수강했다.</p><p>솔직히 엄청 힘들었다.. 사실 전공 수업만 따라가기도 벅찬데 연구실에서 맡은 프로젝트도 있었고, 창업석사의 메인 트랙인 창업 수업이 기본적으로 조별과제라서 그냥 개인 시간이 거의 없었던 것 같다.</p><p>그래도 끝내고 나니 확실히 기본적인 개념들은 전부 익힌 것 같고, 최신 논문을 읽어도 무슨 말인지 따라갈 수 있게 되었다!</p><p>그리고.. 힘든 것과는 별개로, 더 해보고 싶어졌다. 내가 수집한 데이터에 새로운 모델을 적용해 보고 싶고, 전처리를 더 잘하고 싶고, 수집도 더 우아하게 (?) 해보고 싶고 막 하고 싶은 것들이 쑥쑥 늘어났다. 욕심이 생긴다고 해야할까?</p><p>이번 방학은 연구실에 오롯히 매진할 생각이다. 현재 맡은 프로젝트는 네이버 뉴스 데이터를 기반으로 한 의견성 기사 분류 및 분석, 특정 키워드를 포함한 트위터 데이터 수집 및 분석 등이다. </p><p>프로젝트의 주제들을 보면 한국어 NLP인데, 이번에 구글브레인에서 발표한 XLNet을 적용해보고 싶고.. 이때까지는 형태소 분석기를 Mecab을 사용했는데 딥러닝 기반의 Khaiii를 사용해서 여러 모델들을 적용해 볼 생각이다.</p><p>이와 별개로 연구실에서 Twitch 채팅 로그를 기반으로 Hatespeech 분석, 비언어적 특성 (이모티콘 등) 분석 등을 진행하고 계신 분들이 있는데, 여력이 된다면 조인하고 싶다.</p><blockquote><p>2019년 한국정보과학회 참여 사진</p></blockquote><p><img src="https://user-images.githubusercontent.com/25416425/60381891-34049c00-9a96-11e9-8103-00d00ea2743e.jpeg" width="500"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;카이스트에서의 도전적인(?) 한 학기가 드디어 끝났다.&lt;/p&gt;
&lt;p&gt;정말 많은 일들을 한꺼번에 진행하느라 힘들었지만, 그만큼 의미있었던 한 학기였다.&lt;/p&gt;
&lt;p&gt;나의 무기를 가지고 싶어 시작했던 일들이었던 만큼, 재미있고 가슴뛰는 무언가를 찾아서 움직였던 과거와는 달리 모든 일에 조금 진지하게 임하였던 것 같다.&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅹ. Others" scheme="https://jeongwookie.github.io/categories/%E2%85%A9-Others/"/>
    
      <category term="학교 이야기" scheme="https://jeongwookie.github.io/categories/%E2%85%A9-Others/%ED%95%99%EA%B5%90-%EC%9D%B4%EC%95%BC%EA%B8%B0/"/>
    
    
      <category term="Daily life" scheme="https://jeongwookie.github.io/tags/Daily-life/"/>
    
  </entry>
  
  <entry>
    <title>Data Crawling - 파이썬을 이용한 트위터 수집하기</title>
    <link href="https://jeongwookie.github.io/2019/06/10/datascience/datacrawling/4-twitter-data-crawling/"/>
    <id>https://jeongwookie.github.io/2019/06/10/datascience/datacrawling/4-twitter-data-crawling/</id>
    <published>2019-06-10T09:24:31.000Z</published>
    <updated>2021-11-21T11:21:07.615Z</updated>
    
    <content type="html"><![CDATA[<p>어떤 사건에 대한 사람들의 즉각적인 관심과 반응, 그리고 영향력자들이 어떻게 일반 사용자에게 영향을 미치는지 분석하는 데는 트위터 만한 SNS가 없다.</p><p>본 포스트에서는 예제로 19년 4월 4주차에서 <u>어벤져스</u> 또는 <u>스포</u>가 포함된 트윗을 수집해 볼 것이다.</p><p>어벤져스 엔드게임은 19년 4월 24일에 개봉해서 엄청난 인기를 끌었는데, 한동안 SNS에서 일명 스포 (스포일러)를 한다고 절대 아무거나 클릭하지 말라고 소동이 있었던 것으로 기억한다.</p><p>개봉일 전후로 트윗 수가 차이가 나고, <u>스포</u>와 같이 작성된 트윗이 많을 것으로 기대된다. </p><p><img src="https://user-images.githubusercontent.com/25416425/59194117-ebf30780-8bc2-11e9-91f1-ab6b84883cd6.png" width="400"></p><a id="more"></a><h2 id="수집-도구-선택"><a href="#수집-도구-선택" class="headerlink" title="수집 도구 선택"></a>수집 도구 선택</h2><p>트위터에서는 공식적으로 데이터 수집을 지원하는 API를 제공하고 있는데, 이름은 <strong>Tweepy</strong>. 최근 자료들을 얻는 데 있어서는 간단하고 빠르다.</p><p>그러나, 이 방법에는 치명적인 단점이 존재하는데.. 바로 현재 시간부터 7일 이전까지의 데이터만 수집이 가능하다는 점이다.</p><p>그 이전의 데이터를 수집하고 싶다면, Premium-Api를 구매해야 한다.. <a href="https://developer.twitter.com/en/premium-apis" rel="external nofollow noopener noreferrer" target="_blank">트위터 개발자 홈페이지</a>에 접속하면 아래와 같은 가격 플랜을 안내하고 있다.</p><p><em>Pricing for the elevated tiers of the Search Tweets: 30-day endpoint start at <strong>$149/month</strong> for 500 requests, while pricing for the Search Tweets: Full-archive endpoint starts at <strong>$99/month</strong> for 100 requests.</em>   </p><p>상당한 비용이 발생함을 알 수 있다. 그럼 다른 방법은 없을까?</p><p>직접 크롤러를 만들수도 있지만 그건 최후의 (?) 수단이고, 누군가 만들어 놓은 도구가 있다면 쓰는 것이 인지상정! 다행히 오래된 트윗을 수집할 수 있는 <a href="https://github.com/Mottl/GetOldTweets3" rel="external nofollow noopener noreferrer" target="_blank"><strong>GetOldTweet3</strong></a> 이라는 패키지가 있다.</p><p><img src="https://user-images.githubusercontent.com/25416425/59187501-901f8300-8bb0-11e9-954d-ca8994b0c726.png" width="700"></p><p>이 패키지를 사용해서 수집할 수 있는 변수들을 확인해 보니, 내가 원하는 것은 대부분 수집이 가능했다.</p><ul><li>업로드 유저 아이디 (username)</li><li>트윗 링크 (permalink)</li><li>트윗 내용 (text)</li><li>업로드 시간 (date)</li><li>리트윗 수 (retweets)</li><li>관심글 수 (favorites)</li></ul><p>또한, 다양한 기준으로 데이터 수집 범위를 설정할 수 있었다.</p><ul><li>특정 유저 아이디로 트윗 검색 (setUsername)</li><li>기간 안의 트윗 검색 (setSince / setUntil)</li><li>특정 검색어가 포함된 트윗 검색 (setQuerySearch)</li><li>기준 위치를 설정하고 근처에서 생성된 트윗 검색 (setNear / setWithin)</li><li>출력할 최대 트윗 수 지정 (setMaxTweets)</li></ul><p>좀 더 자세한 옵션 및 사용 방법은 <a href="https://github.com/Mottl/GetOldTweets3" rel="external nofollow noopener noreferrer" target="_blank">GetOldTweet3 github</a> 을 참고하자.</p><h2 id="패키지-준비"><a href="#패키지-준비" class="headerlink" title="패키지 준비"></a>패키지 준비</h2><p>본격적으로 크롤링에 앞서, 먼저 <strong>GetOldTweet3</strong> 패키지를 설치한다. 본 포스트에서는 python 3.7, ubuntu 18.04 의 개발 환경을 기본으로 한다. Jupyter Notebook으로 코드를 작성하였다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GetOldTweet3 사용 준비</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> GetOldTweets3 <span class="keyword">as</span> got</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    !pip install GetOldTweets3</span><br><span class="line">    <span class="keyword">import</span> GetOldTweets3 <span class="keyword">as</span> got</span><br></pre></td></tr></table></figure><p>또한, 추가적인 데이터 수집을 위해서 이전 포스트에서도 사용하였던 <strong>Beautifulsoup4</strong> 가 설치되어 있는지 확인한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># BeautifulSoup4 사용 준비</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    !pip install bs4</span><br><span class="line">    <span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br></pre></td></tr></table></figure><h2 id="수집-기간-정의하기"><a href="#수집-기간-정의하기" class="headerlink" title="수집 기간 정의하기"></a>수집 기간 정의하기</h2><p>본격적으로 크롤러를 만들어 보자. 먼저 <code>datetime</code>을 사용하여 원하는 수집 기간을 정의한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 가져올 범위를 정의</span></span><br><span class="line"><span class="comment"># 예제 : 2019-04-21 ~ 2019-04-24</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">days_range = []</span><br><span class="line"></span><br><span class="line">start = datetime.datetime.strptime(<span class="string">"2019-04-21"</span>, <span class="string">"%Y-%m-%d"</span>)</span><br><span class="line">end = datetime.datetime.strptime(<span class="string">"2019-04-25"</span>, <span class="string">"%Y-%m-%d"</span>)</span><br><span class="line">date_generated = [start + datetime.timedelta(days=x) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, (end-start).days)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> date <span class="keyword">in</span> date_generated:</span><br><span class="line">    days_range.append(date.strftime(<span class="string">"%Y-%m-%d"</span>))</span><br><span class="line"></span><br><span class="line">print(<span class="string">"=== 설정된 트윗 수집 기간은 &#123;&#125; 에서 &#123;&#125; 까지 입니다 ==="</span>.format(days_range[<span class="number">0</span>], days_range[<span class="number">-1</span>]))</span><br><span class="line">print(<span class="string">"=== 총 &#123;&#125;일 간의 데이터 수집 ==="</span>.format(len(days_range)))</span><br><span class="line"></span><br><span class="line">&gt; === 설정된 트윗 수집 기간은 <span class="number">2019</span><span class="number">-04</span><span class="number">-21</span> 에서 <span class="number">2019</span><span class="number">-04</span><span class="number">-24</span> 까지 입니다 ===</span><br><span class="line">&gt; === 총 <span class="number">4</span>일 간의 데이터 수집 ===</span><br></pre></td></tr></table></figure><p><code>days_range</code> 라는 이름의 리스트에 날짜를 %Y-%m-%d 형태로 저장해 놓았다.</p><h2 id="트윗-수집하기"><a href="#트윗-수집하기" class="headerlink" title="트윗 수집하기"></a>트윗 수집하기</h2><p>이제 본격적으로 트위터에서 데이터를 크롤링할 차례이다.</p><p><strong>GetOldTweet3</strong>는 <code>tweetCriteria</code>로 수집 기준을 정의할 수 있다.</p><p>앞에서 설정한 수집 기간에서 <u>어벤져스</u> 또는 <u>스포</u> 가 포함된 트윗을 모두 수집해 보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 특정 검색어가 포함된 트윗 검색하기 (quary search)</span></span><br><span class="line"><span class="comment"># 검색어 : 어벤져스, 스포</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 수집 기간 맞추기</span></span><br><span class="line">start_date = days_range[<span class="number">0</span>]</span><br><span class="line">end_date = (datetime.datetime.strptime(days_range[<span class="number">-1</span>], <span class="string">"%Y-%m-%d"</span>) </span><br><span class="line">            + datetime.timedelta(days=<span class="number">1</span>)).strftime(<span class="string">"%Y-%m-%d"</span>) <span class="comment"># setUntil이 끝을 포함하지 않으므로, day + 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 트윗 수집 기준 정의</span></span><br><span class="line">tweetCriteria = got.manager.TweetCriteria().setQuerySearch(<span class="string">'어벤져스 OR 스포'</span>)\</span><br><span class="line">                                           .setSince(start_date)\</span><br><span class="line">                                           .setUntil(end_date)\</span><br><span class="line">                                           .setMaxTweets(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 수집 with GetOldTweet3</span></span><br><span class="line">print(<span class="string">"Collecting data start.. from &#123;&#125; to &#123;&#125;"</span>.format(days_range[<span class="number">0</span>], days_range[<span class="number">-1</span>]))</span><br><span class="line">start_time = time.time()</span><br><span class="line"></span><br><span class="line">tweet = got.manager.TweetManager.getTweets(tweetCriteria)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Collecting data end.. &#123;0:0.2f&#125; Minutes"</span>.format((time.time() - start_time)/<span class="number">60</span>))</span><br><span class="line">print(<span class="string">"=== Total num of tweets is &#123;&#125; ==="</span>.format(len(tweet)))</span><br><span class="line"></span><br><span class="line">&gt; Collecting data start.. <span class="keyword">from</span> <span class="number">2019</span><span class="number">-04</span><span class="number">-21</span> to <span class="number">2019</span><span class="number">-04</span><span class="number">-24</span></span><br><span class="line">&gt; Collecting data end.. <span class="number">41.39</span> Minutes</span><br><span class="line">&gt; === Total num of tweets <span class="keyword">is</span> <span class="number">22964</span> ===</span><br></pre></td></tr></table></figure><p>수집하는 데 시간이 조금 걸린다. 참고로 너무 많은 트윗을 한번에 수집하려다 보면, 트위터 측에서 나가라고 쫒아낸다.. (Error 104)</p><p><em>An error occured during an HTTP request: [Errno 104] Connection reset by peer</em></p><p>Connection 관련한 에러가 뜨면, 지정한 날짜 범위에 기준을 만족하는 트윗의 수가 너무 많은 것이니 범위를 좁혀서 다시 시도해 보자.</p><p>수집하는 데 얼마나 시간이 걸렸는지 알아보기 위해 <code>time</code> 을 임포트 해서 코드 몇줄을 추가했다. 참고로 나는 이 과정에서 1시간 넘게 소요된 적도 있었으니 참을성있게 기다려보자.</p><p>위 코드는 41분 가량 소요되었다. 몇개의 트윗이 수집되었는지 출력되면, 아래 단계로 넘어가자.</p><h2 id="변수-저장하기"><a href="#변수-저장하기" class="headerlink" title="변수 저장하기"></a>변수 저장하기</h2><p>이제 원하는 정보만을 저장해 보자. <strong>GetOldTweet3</strong> 에서 제공하는 기본 변수 중 유저 아이디, 트윗 링크, 트윗 내용, 날짜, 리트윗 수, 관심글 수를 수집한다.</p><p>또한, 이 패키지에서 제공하지 않는 변수 중 각 유저의 가입일, 전체 트윗 수, 팔로잉 수, 팔로워 수도 같이 수집한다. 이때, 앞서 준비한 <strong>BeautifulSoup4</strong> 를 사용한다. 자세한 사용 방법은 이전 포스트들을 참고하자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 원하는 변수 골라서 저장하기</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> uniform</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm_notebook</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize</span></span><br><span class="line">tweet_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> tqdm_notebook(tweet):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 메타데이터 목록 </span></span><br><span class="line">    username = index.username</span><br><span class="line">    link = index.permalink </span><br><span class="line">    content = index.text</span><br><span class="line">    tweet_date = index.date.strftime(<span class="string">"%Y-%m-%d"</span>)</span><br><span class="line">    tweet_time = index.date.strftime(<span class="string">"%H:%M:%S"</span>)</span><br><span class="line">    retweets = index.retweets</span><br><span class="line">    favorites = index.favorites</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># === 유저 정보 수집 시작 ===</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        personal_link = <span class="string">'https://twitter.com/'</span> + username</span><br><span class="line">        bs_obj = get_bs_obj(personal_link)</span><br><span class="line">        uls = bs_obj.find(<span class="string">"ul"</span>, &#123;<span class="string">"class"</span>: <span class="string">"ProfileNav-list"</span>&#125;).find_all(<span class="string">"li"</span>)</span><br><span class="line">        div = bs_obj.find(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>: <span class="string">"ProfileHeaderCard-joinDate"</span>&#125;).find_all(<span class="string">"span"</span>)[<span class="number">1</span>][<span class="string">"title"</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 가입일, 전체 트윗 수, 팔로잉 수, 팔로워 수</span></span><br><span class="line">        joined_date = div.split(<span class="string">'-'</span>)[<span class="number">1</span>].strip()</span><br><span class="line">        num_tweets = uls[<span class="number">0</span>].find(<span class="string">"span"</span>, &#123;<span class="string">"class"</span>: <span class="string">"ProfileNav-value"</span>&#125;).text.strip()</span><br><span class="line">        num_following = uls[<span class="number">1</span>].find(<span class="string">"span"</span>, &#123;<span class="string">"class"</span>: <span class="string">"ProfileNav-value"</span>&#125;).text.strip()</span><br><span class="line">        num_follower = uls[<span class="number">2</span>].find(<span class="string">"span"</span>, &#123;<span class="string">"class"</span>: <span class="string">"ProfileNav-value"</span>&#125;).text.strip()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> AttributeError:</span><br><span class="line">        print(<span class="string">"=== Attribute error occurs at &#123;&#125; ==="</span>.format(link))</span><br><span class="line">        print(<span class="string">"link : &#123;&#125;"</span>.format(personal_link))   </span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">     </span><br><span class="line">    <span class="comment"># 결과 합치기</span></span><br><span class="line">    info_list = [tweet_date, tweet_time, username, content, link, retweets, favorites, </span><br><span class="line">                 joined_date, num_tweets, num_following, num_follower]</span><br><span class="line">    tweet_list.append(info_list)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 휴식 </span></span><br><span class="line">    time.sleep(uniform(<span class="number">1</span>,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><p><strong>(주의: 실행 시 약 24시간이 소요됩니다. 결과를 빨리 확인하려면 유저 정보 수집 부분을 전부 주석처리 해주세요.)</strong></p><p>유저의 가입일, 전체 트윗 수, 팔로잉 수, 팔로워 수 와 같은 변수는 <strong>GetOldTweet3</strong>으로 얻은 <code>username</code>으로 <code>personal_link</code>을 만들어 수집하였다.</p><p>중간에 <code>try-except</code> 구문을 사용하였는데, 이는 수집을 시도해 보니 몇몇 사용자의 팔로잉 수 혹은 팔로워 수가 공개되어 있지 않아 <code>AttributeError</code>을 발생시키고 있었다. 이런 에러를 발생시키는 계정은 보통 광고용 찌라시 계정이었는데, 이를 확인하기 위해 에러 발생시 그 link를 출력하도록 코드를 구성하였다.</p><p>또한, 공격적인 크롤링 방지를 위해 <code>random.uniform()</code>을 활용하여 아래에 1~2초 사이로 랜덤하게 for문을 쉬게 하는 코드를 추가했다.  </p><p>트윗 수집 결과는 <code>tweet_list</code>에 저장된다.</p><h2 id="파일-저장-후-확인"><a href="#파일-저장-후-확인" class="headerlink" title="파일 저장 후 확인"></a>파일 저장 후 확인</h2><p>이제 결과를 csv 파일로 저장하고, 저장된 파일을 불러와서 확인해 보자. <code>Pandas</code> 패키지를 사용할 것이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 파일 저장하기</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">twitter_df = pd.DataFrame(tweet_list, </span><br><span class="line">                          columns = [<span class="string">"date"</span>, <span class="string">"time"</span>, <span class="string">"user_name"</span>, <span class="string">"text"</span>, <span class="string">"link"</span>, <span class="string">"retweet_counts"</span>, <span class="string">"favorite_counts"</span>,</span><br><span class="line">                                    <span class="string">"user_created"</span>, <span class="string">"user_tweets"</span>, <span class="string">"user_followings"</span>, <span class="string">"user_followers"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># csv 파일 만들기</span></span><br><span class="line">twitter_df.to_csv(<span class="string">"sample_twitter_data_&#123;&#125;_to_&#123;&#125;.csv"</span>.format(days_range[<span class="number">0</span>], days_range[<span class="number">-1</span>]), index=<span class="literal">False</span>)</span><br><span class="line">print(<span class="string">"=== &#123;&#125; tweets are successfully saved ==="</span>.format(len(tweet_list)))</span><br><span class="line"></span><br><span class="line">&gt; === <span class="number">22964</span> tweets are successfully saved ===</span><br></pre></td></tr></table></figure><p>위 코드를 실행시키면, working directory 내에 sample_twitter_data_2019-04-21_to_2019-04-24.csv 파일이 생성되었음을 확인할 수 있다.</p><p>생성한 파일을 로드해서 내용을 확인해 보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 파일 확인하기</span></span><br><span class="line"></span><br><span class="line">df_tweet = pd.read_csv(<span class="string">'sample_twitter_data_&#123;&#125;_to_&#123;&#125;.csv'</span>.format(days_range[<span class="number">0</span>], days_range[<span class="number">-1</span>]))</span><br><span class="line">df_tweet.head(<span class="number">10</span>) <span class="comment"># 위에서 10개만 출력</span></span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/25416425/59205137-2d90ac00-8bdd-11e9-9d3b-fdef803b7e6c.png" width="700"></p><h2 id="데이터-통계-확인"><a href="#데이터-통계-확인" class="headerlink" title="데이터 통계 확인"></a>데이터 통계 확인</h2><p>수집한 데이터라 어떤 특징을 보이고 있는지 간단하게 확인해 보자. </p><p><u>어벤져스</u> 또는 <u>스포</u>가 포함된 트윗을 수집하였는데, 각각의 빈도는 어느 정도일까?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 키워드 빈도 분석하기</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_keywords</span><span class="params">(dataframe)</span>:</span></span><br><span class="line">    keywords = []</span><br><span class="line">    text = dataframe[<span class="string">"text"</span>].lower()</span><br><span class="line">    <span class="keyword">if</span> <span class="string">"어벤져스"</span> <span class="keyword">in</span> text:</span><br><span class="line">        keywords.append(<span class="string">"어벤져스"</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">"스포"</span> <span class="keyword">in</span> text:</span><br><span class="line">        keywords.append(<span class="string">"스포"</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">","</span>.join(keywords)</span><br><span class="line"></span><br><span class="line">df_tweet[<span class="string">"keyword"</span>] = df_tweet.apply(get_keywords,axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># barplot 그리기</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">counts = df_tweet[<span class="string">"keyword"</span>].value_counts()</span><br><span class="line">plt.bar(range(len(counts)), counts)</span><br><span class="line">plt.title(<span class="string">"Tweets mentioning keywords"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"# of tweets"</span>)</span><br><span class="line">plt.show()</span><br><span class="line">print(counts)</span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/25416425/59205869-bcea8f00-8bde-11e9-910e-a7e1ba347476.png" width="450"></p><p>barplot을 그릴 때에는 파이썬의 visualization package 중 가장 유명한 <code>matplotlib</code>을 사용했다.</p><p><u>스포</u> 가 단일로 포함된 트윗이 14,782개로 가장 많았고, 그 뒤로 <u>어벤져스</u> 단일이 6,902개 , 그리고 <u>어벤져스</u> 와 <u>스포</u> 모두 포함된 트윗이 1,248개 로 파악된다.</p><p>이번에는 어벤져스 개봉일이 다가오면서 변화하는 트윗의 빈도를 출력해 보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 날짜별 빈도 분석하기</span></span><br><span class="line"></span><br><span class="line">counts = df_tweet[<span class="string">"date"</span>].value_counts().sort_index()</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">"Tweets mentioning keywords in time series"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"# of tweets"</span>)</span><br><span class="line">counts.plot(kind = <span class="string">'bar'</span>)</span><br><span class="line">print(counts)</span><br></pre></td></tr></table></figure><p><img src="https://user-images.githubusercontent.com/25416425/59206240-7c3f4580-8bdf-11e9-93b4-8803db1e7084.png" width="450"></p><p>역시나 예상했던 대로, 영화 개봉일인 4월 24일이 되자 트윗이 14,989개로 폭발적으로 증가했음을 확인할 수 있다.</p><p>여기까지 간단하게 데이터의 shape 정도를 확인해 보았다. 이외에도 다양한 방법으로 데이터를 분석할 수 있으니 그건 각자 해보는 걸로..</p><p><em>20.02.25 추가</em><br><a href="https://jeongwookie.github.io/2020/02/25/200225-twitter-data-crawling-without-package/">트위터 크롤링, 패키지 없이 해보자!</a> 라는 주제로 새로 블로그에 글을 업로드 하였으니 필요하신 분은 참고 바랍니다.</p><p><em>20.04.23 추가</em><br><a href="https://jeongwookie.github.io/2020/04/23/200423-analyze-tweet-series-1-collect/">트위터 파헤치기 시리즈 첫번째 - 수집하기</a> 라는 트위터 크롤링 관련 포스트를 새로 작성하였습니다. 많은 분들이 댓글로 질문 주셨던 내용들이 여기에 자연스럽게 담겨 있습니다. 일례로, 해당 날짜의 전수 트윗을 모으는 것이 아닌 popular한 100개의 트윗만을 모으는 것도 가능합니다. 자세한 내용은 포스트를 읽어 보시고, 궁금한 점 댓글 달아주세요!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;어떤 사건에 대한 사람들의 즉각적인 관심과 반응, 그리고 영향력자들이 어떻게 일반 사용자에게 영향을 미치는지 분석하는 데는 트위터 만한 SNS가 없다.&lt;/p&gt;
&lt;p&gt;본 포스트에서는 예제로 19년 4월 4주차에서 &lt;u&gt;어벤져스&lt;/u&gt; 또는 &lt;u&gt;스포&lt;/u&gt;가 포함된 트윗을 수집해 볼 것이다.&lt;/p&gt;
&lt;p&gt;어벤져스 엔드게임은 19년 4월 24일에 개봉해서 엄청난 인기를 끌었는데, 한동안 SNS에서 일명 스포 (스포일러)를 한다고 절대 아무거나 클릭하지 말라고 소동이 있었던 것으로 기억한다.&lt;/p&gt;
&lt;p&gt;개봉일 전후로 트윗 수가 차이가 나고, &lt;u&gt;스포&lt;/u&gt;와 같이 작성된 트윗이 많을 것으로 기대된다. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/25416425/59194117-ebf30780-8bc2-11e9-91f1-ab6b84883cd6.png&quot; width=&quot;400&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅰ. Data Science" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/"/>
    
      <category term="데이터 크롤링" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%81%AC%EB%A1%A4%EB%A7%81/"/>
    
    
      <category term="Python" scheme="https://jeongwookie.github.io/tags/Python/"/>
    
      <category term="Datamining" scheme="https://jeongwookie.github.io/tags/Datamining/"/>
    
      <category term="Twitter" scheme="https://jeongwookie.github.io/tags/Twitter/"/>
    
  </entry>
  
  <entry>
    <title>Data Crawling - 네이버 뉴스 데이터 수집하기</title>
    <link href="https://jeongwookie.github.io/2019/05/31/datascience/datacrawling/3-naver-main-news-crawling/"/>
    <id>https://jeongwookie.github.io/2019/05/31/datascience/datacrawling/3-naver-main-news-crawling/</id>
    <published>2019-05-31T07:26:09.000Z</published>
    <updated>2021-11-21T11:20:59.985Z</updated>
    
    <content type="html"><![CDATA[<p>네이버 뉴스와 관련된 데이터로 연구실에서 일하다 보니, 여러가지 관점에서 데이터를 수집하는 경우가 생긴다.</p><p>네이버 뉴스에서 오른쪽 위쪽을 잘 살펴보면 <a href="https://news.naver.com/main/history/mainnews/index.nhn" rel="external nofollow noopener noreferrer" target="_blank">기사배열 이력</a> 이라는 코너가 있다.</p><p>2019년 4월 4일 이후부터는 메인에 뜨는 뉴스가 개인마다 다르게 적용되도록 서비스 하고 있는 것 같은데, 그 전에는 네이버가 자신들의 기준으로 메인에 기사를 걸어놓은 것 같다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58689423-f4c52b80-83c1-11e9-9561-a1e8bd4f2fec.png" width="550"></p><a id="more"></a><p>원하는 기간에 <u>네이버 뉴스 메인에 게시되었던 기사들</u>만 골라서 제목 및 링크를 수집하여 보자.</p><p>차근차근 따라올 수 있도록 코드를 최대한 구성해 보도록 노력했다.</p><p>코드는 <code>python 3.7</code> 환경에서 작성했다.</p><h2 id="수집-기간-정의하기"><a href="#수집-기간-정의하기" class="headerlink" title="수집 기간 정의하기"></a>수집 기간 정의하기</h2><p>먼저, 원하는 수집 기간을 정의해 보자. 파이썬의 기본 패키지 중 하나인 <code>datetime</code>을 사용할 것이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 가져올 범위를 정의</span></span><br><span class="line"><span class="comment"># 2015-02-25 ~ 2015-02-28 // 2015-03-01 ~ 2015-03-30</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">days_range = []</span><br><span class="line"></span><br><span class="line">start = datetime.datetime.strptime(<span class="string">"2015-02-25"</span>, <span class="string">"%Y-%m-%d"</span>)</span><br><span class="line">end = datetime.datetime.strptime(<span class="string">"2015-03-31"</span>, <span class="string">"%Y-%m-%d"</span>) <span class="comment"># 범위 + 1</span></span><br><span class="line">date_generated = [start + datetime.timedelta(days=x) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, (end-start).days)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> date <span class="keyword">in</span> date_generated:</span><br><span class="line">    days_range.append(date.strftime(<span class="string">"%Y-%m-%d"</span>))</span><br><span class="line"></span><br><span class="line">print(days_range)</span><br><span class="line"></span><br><span class="line">&gt;&gt; [<span class="string">'2015-02-25'</span>, <span class="string">'2015-02-26'</span>, <span class="string">'2015-02-27'</span>, <span class="string">'2015-02-28'</span>, <span class="string">'2015-03-01'</span>, ... , <span class="string">'2015-03-30'</span>]</span><br></pre></td></tr></table></figure><p>코드를 읽어보면 별로 어렵지 않다. <code>start</code> 와 <code>end</code>로 날짜 범위를 지정한 다음, <code>striptime</code> 함수를 활용하여 원하는 형식인 <u>%Y-%m-%d</u> 으로 뽑아내어 <code>days_range</code> 라는 리스트에 저장하였다.</p><h2 id="html-parser-정의하기"><a href="#html-parser-정의하기" class="headerlink" title="html parser 정의하기"></a>html parser 정의하기</h2><p>이제 원하는 페이지의 html에 접근하기 위해, parser을 정의할 것이다.</p><p>다행히도 간편하게 html parsing을 지원하는 패키지인 <code>BeautifulSoup4</code>가 존재한다.</p><p>혹시나 이 패키지를 다운받지 않으신 분들은 주피터 노트북 상에서 아래와 같은 코드를 입력하면 된다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install bs4</span><br></pre></td></tr></table></figure><p>다운로드가 완료되었다면, 이제 원래의 목적으로 돌아가보자. 아래의 코드를 작성한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_bs_obj</span><span class="params">(url)</span>:</span></span><br><span class="line">    result = requests.get(url)</span><br><span class="line">    bs_obj = BeautifulSoup(result.content, <span class="string">"html.parser"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> bs_obj</span><br></pre></td></tr></table></figure><p><code>get_bs_obj()</code> 라는, url을 입력하면 bs_obj을 반환하는 함수를 작성하였다.</p><h2 id="뉴스-페이지-수-구하기"><a href="#뉴스-페이지-수-구하기" class="headerlink" title="뉴스 페이지 수 구하기"></a>뉴스 페이지 수 구하기</h2><p>이제 우리가 수집할 페이지에 접속하여, 페이지가 동작하는 방식에 대해서 파악해 보자.</p><p><a href="https://news.naver.com/main/history/mainnews/list.nhn" rel="external nofollow noopener noreferrer" target="_blank">네이버 주요뉴스 배열 이력 (리스트형)</a></p><p><img src="https://user-images.githubusercontent.com/25416425/58690689-1f64b380-83c5-11e9-8630-04cd97bc2be7.png" width="550"></p><p>우리가 원하는 정보는 위의 페이지에서 우리 눈으로 보이는 정보들 (기사 제목, 링크, 날짜 등) 이다. </p><p>빨간색 네모 부분을 누르면 다음 페이지로 넘어가며, 사진과 같이 메인 뉴스로 게시되었던 기사 및 텍스트만 메인 뉴스로 게시된 기사 모두를 수집해야 한다.</p><p>날짜가 바뀔때 마다 메인 뉴스에 걸렸던 기사의 갯수가 달라질 것인데, 그러면 당연하게도 페이지 수를 알아야 한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm_notebook</span><br><span class="line"></span><br><span class="line">test = [<span class="string">"2015-03-01"</span>] <span class="comment"># 테스트를 위한 데이터 수집 구간</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> date <span class="keyword">in</span> tqdm_notebook(test):</span><br><span class="line">    </span><br><span class="line">    news_arrange_url = <span class="string">"https://news.naver.com/main/history/mainnews/list.nhn"</span></span><br><span class="line">    news_list_date_page_url = news_arrange_url + <span class="string">"?date="</span> + date</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get bs_obj</span></span><br><span class="line">    bs_obj = get_bs_obj(news_list_date_page_url)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 포토 뉴스 페이지 수 구하기</span></span><br><span class="line">    photo_news_count = bs_obj.find(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>: <span class="string">"eh_page"</span>&#125;).text.split(<span class="string">'/'</span>)[<span class="number">1</span>]</span><br><span class="line">    photo_news_count = int(photo_news_count)</span><br><span class="line">    </span><br><span class="line">    print(photo_news_count)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 리스트 뉴스 페이지 수 구하기</span></span><br><span class="line">    text_news_count = bs_obj.find(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>: <span class="string">"mtype_list_wide"</span>&#125;).find(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>: <span class="string">"eh_page"</span>&#125;).text.split(<span class="string">'/'</span>)[<span class="number">1</span>]</span><br><span class="line">    text_news_count = int(text_news_count)</span><br><span class="line">    </span><br><span class="line">    print(text_news_count)</span><br><span class="line"></span><br><span class="line">&gt;&gt; <span class="number">15</span></span><br><span class="line">&gt;&gt; <span class="number">7</span></span><br></pre></td></tr></table></figure><p>위 코드에 사용된 <code>tqdm</code>은 for문의 진행 정도를 시각적으로 보여주는 좋은 패키지이다. 사용법은 위와 같이 import한 후, for문의 범위에 감싸주면 된다.</p><p>웹페이지의 html에서 값을 가져오는 데에는 <code>bs4</code>의 <code>find()</code> 함수를 사용하였다.</p><p>사용법이 궁금하다면, 예전 포스트들을 참고하자.</p><p>전체적인 흐름은, 페이지 수 주변의 html 코드를 가져온 후,  Python의 기본 함수인 <code>split()</code> 으로 쪼개어, 원하는 부분만 출력한 것이다.</p><h2 id="뉴스-정보-수집하기"><a href="#뉴스-정보-수집하기" class="headerlink" title="뉴스 정보 수집하기"></a>뉴스 정보 수집하기</h2><p>이제 진짜 우리가 원하는 정보를 수집할 준비가 완료되었다.</p><p>예시로 각 페이지에서 기사 제목, 발행 언론사, 카테고리, 기사 링크, 기사 고유번호 (10자리) 를 수집할 것이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm_notebook</span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">test = [<span class="string">"2015-03-01"</span>]</span><br><span class="line">main_news_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> date <span class="keyword">in</span> tqdm_notebook(test):</span><br><span class="line">    </span><br><span class="line">    news_arrange_url = <span class="string">"https://news.naver.com/main/history/mainnews/list.nhn"</span></span><br><span class="line">    news_list_date_page_url = news_arrange_url + <span class="string">"?date="</span> + date</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get bs_obj</span></span><br><span class="line">    bs_obj = get_bs_obj(news_list_date_page_url)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 포토 뉴스 페이지 수 구하기</span></span><br><span class="line">    photo_news_count = bs_obj.find(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>: <span class="string">"eh_page"</span>&#125;).text.split(<span class="string">'/'</span>)[<span class="number">1</span>]</span><br><span class="line">    photo_news_count = int(photo_news_count)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 리스트 뉴스 페이지 수 구하기</span></span><br><span class="line">    text_news_count = bs_obj.find(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>: <span class="string">"mtype_list_wide"</span>&#125;).find(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>: <span class="string">"eh_page"</span>&#125;).text.split(<span class="string">'/'</span>)[<span class="number">1</span>]</span><br><span class="line">    text_news_count = int(text_news_count)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 포토 뉴스 부분 링크 크롤링</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> tqdm_notebook(range(<span class="number">1</span>,photo_news_count+<span class="number">1</span>)):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 포토 뉴스 링크</span></span><br><span class="line">        news_list_photo_url = <span class="string">'http://news.naver.com/main/history/mainnews/photoTv.nhn'</span></span><br><span class="line">        date_str = <span class="string">"?date="</span></span><br><span class="line">        page_str = <span class="string">"&amp;page="</span></span><br><span class="line">        news_list_photo_full_url = news_list_photo_url + <span class="string">"?date="</span> + date + <span class="string">"&amp;page="</span> + str(page)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># get bs obj</span></span><br><span class="line">        photo_bs_obj = get_bs_obj(news_list_photo_full_url)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 링크 내 정보 수집</span></span><br><span class="line">        ul = photo_bs_obj.find(<span class="string">"ul"</span>, &#123;<span class="string">"class"</span>: <span class="string">"edit_history_lst"</span>&#125;)</span><br><span class="line">        lis = ul.find_all(<span class="string">"li"</span>)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> lis:</span><br><span class="line">            title = item.find(<span class="string">"a"</span>)[<span class="string">"title"</span>]</span><br><span class="line">            press = item.find(<span class="string">"span"</span>, &#123;<span class="string">"class"</span> : <span class="string">"eh_by"</span>&#125;).text</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># link</span></span><br><span class="line">            link = item.find(<span class="string">"a"</span>)[<span class="string">"href"</span>]</span><br><span class="line">            </span><br><span class="line">            sid1 = link.split(<span class="string">'&amp;'</span>)[<span class="number">-3</span>].split(<span class="string">'='</span>)[<span class="number">1</span>]</span><br><span class="line">            oid = link.split(<span class="string">'&amp;'</span>)[<span class="number">-2</span>].split(<span class="string">'='</span>)[<span class="number">1</span>]</span><br><span class="line">            aid = link.split(<span class="string">'&amp;'</span>)[<span class="number">-1</span>].split(<span class="string">'='</span>)[<span class="number">1</span>]            </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 연예 TV 기사 제외</span></span><br><span class="line">            <span class="keyword">if</span> sid1 == <span class="string">"shm"</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">            article_type = <span class="string">"pic"</span></span><br><span class="line">            </span><br><span class="line">            pic_list = [date, article_type, title, press, sid1, link, aid]</span><br><span class="line">            </span><br><span class="line">            main_news_list.append(pic_list)</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># 텍스트 뉴스 부분 링크 크롤링</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> tqdm_notebook(range(<span class="number">1</span>, text_news_count+<span class="number">1</span>)):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 텍스트 뉴스 링크</span></span><br><span class="line">        news_list_text_url = <span class="string">'http://news.naver.com/main/history/mainnews/text.nhn'</span></span><br><span class="line">        date_str = <span class="string">"?date="</span></span><br><span class="line">        page_str = <span class="string">"&amp;page="</span></span><br><span class="line">        news_list_text_full_url = news_list_text_url + <span class="string">"?date="</span> + date + <span class="string">"&amp;page="</span> + str(page)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># get bs obj</span></span><br><span class="line">        text_bs_obj = get_bs_obj(news_list_text_full_url)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 링크 내 정보 수집</span></span><br><span class="line">        uls = text_bs_obj.find_all(<span class="string">"ul"</span>)</span><br><span class="line">        <span class="keyword">for</span> ul <span class="keyword">in</span> uls:</span><br><span class="line">            lis = ul.find_all(<span class="string">"li"</span>)</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> lis:</span><br><span class="line">                title = item.find(<span class="string">"a"</span>).text</span><br><span class="line">                press = item.find(<span class="string">"span"</span>, &#123;<span class="string">"class"</span> : <span class="string">"writing"</span>&#125;).text</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># link</span></span><br><span class="line">                link = item.find(<span class="string">"a"</span>)[<span class="string">"href"</span>]</span><br><span class="line"></span><br><span class="line">                sid1 = link.split(<span class="string">'&amp;'</span>)[<span class="number">-3</span>].split(<span class="string">'='</span>)[<span class="number">1</span>]</span><br><span class="line">                oid = link.split(<span class="string">'&amp;'</span>)[<span class="number">-2</span>].split(<span class="string">'='</span>)[<span class="number">1</span>]</span><br><span class="line">                aid = link.split(<span class="string">'&amp;'</span>)[<span class="number">-1</span>].split(<span class="string">'='</span>)[<span class="number">1</span>]</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 연예 TV 기사 제외</span></span><br><span class="line">                <span class="keyword">if</span> sid1 == <span class="string">"shm"</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                article_type = <span class="string">"text"</span></span><br><span class="line">                </span><br><span class="line">                text_list = [date, article_type, title, press, sid1, link, aid]</span><br><span class="line">                </span><br><span class="line">                main_news_list.append(text_list)</span><br><span class="line"></span><br><span class="line">pprint(main_news_list, width = <span class="number">20</span>)</span><br></pre></td></tr></table></figure><p>코드가 크게 두 부분으로 나뉘어져 있다.</p><p>하나는 포토 기사에 대한 데이터 수집. 앞선 step에서 <code>photo_news_count</code> 에 페이지 수를 저장했던 것을 기억할 것이다.</p><p>for문으로 페이지 수만큼 반복하여 여러가지 정보를 수집하도록 코드를 짰다.</p><p>그리고, 수집하다보면 네이버 기사 메인에 게시되긴 하였지만 <a href="https://entertain.naver.com/read?oid=416&amp;aid=0000140695" rel="external nofollow noopener noreferrer" target="_blank">뉴스가 아닌(?) 링크들</a>이 있어서 제외하였다.</p><p>두 번째는 <code>text_news_count</code> 으로 페이지 수를 저장하였던 텍스트 기사에 대한 데이터 수집이다.</p><p>또한, 수집된 기사가 포토 기사인지 텍스트 기사인지 알고 싶어서 중간에 <code>article_type</code>을 추가해 놓았다.</p><p>모든 수집된 데이터는 <code>main_news_list</code> 라는 이름의 리스트에 차례대로 append 되도록 설정했다.</p><p>마지막 줄의 <code>pprint()</code>는 단지 리스트를 깔끔하게 출력하고 싶어서 추가한 코드이니, 크롤러랑은 무관하다.</p><blockquote><p>test 기간에 대해 네이버 메인 뉴스 기사배열이력 수집 결과</p></blockquote><p><img src="https://user-images.githubusercontent.com/25416425/58693771-7326cb00-83cc-11e9-943a-996c599aa672.png" width="550"></p><h2 id="CSV-파일로-저장하기"><a href="#CSV-파일로-저장하기" class="headerlink" title="CSV 파일로 저장하기"></a>CSV 파일로 저장하기</h2><p>수집을 했으면 관리하기 쉽도록 적절한 형태로 저장하는 것이 필수!</p><p>가장 보편적인 형태인 .csv 파일로 저장해 보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># make .csv file</span></span><br><span class="line">naver_news_df = pd.DataFrame(main_news_list, </span><br><span class="line">                                  columns = [<span class="string">"date"</span>, <span class="string">"type"</span>, <span class="string">"title"</span>, <span class="string">"press"</span>, <span class="string">"category"</span>, <span class="string">"link"</span>, <span class="string">"aid"</span>])</span><br><span class="line">naver_news_df.to_csv(<span class="string">"naver_main_news.csv"</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>실행하면, working directory 내에 <code>naver_main_news.csv</code> 파일이 생성되어 있음을 확인할 수 있다.</p><p>csv file을 만들기 위해, 데이터를 다루는 데에 매우 편리한 패키지인 <code>pandas</code>를 사용하였다.</p><p>참고로, 주피터 노트북에서 작업하는 사용자의 경우 위에 <code>bs4</code> 패키지를 설치할 때와 유사하게 코드를 입력하면 쉽게 패키지를 다운로드 받을 수 있다.</p><p>제대로 수집되었는지 csv file을 열어서 확인해 보자. 아래와 같은 코드를 입력한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># open .csv file</span></span><br><span class="line"></span><br><span class="line">df_naver_news = pd.read_csv(<span class="string">'naver_main_news.csv'</span>, dtype = &#123;<span class="string">"aid"</span> : <span class="string">"str"</span>&#125;)</span><br><span class="line">df_naver_news.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>위 코드에서 <code>read_csv()</code>으로 파일을 읽을 때 <code>dtype</code> 을 추가한 이유는, 저장했었던 <code>aid</code>가 뉴스 고유 번호 10자리인데 경우에 따라 0000003455와 같이 앞에 0이 있어서, 이를 그대로 출력하고 싶어서 이다.</p><p>만약 저 옵션을 추가하지 않으면 방금 전 예로 든 뉴스 고유 번호는 10자리가 아니라 0을 다 빼버린 3455 라고 출력된다.. (ㅠㅠ)</p><p><img src="https://user-images.githubusercontent.com/25416425/58694773-c9950900-83ce-11e9-814e-4acb2aeaefb4.png" width="550"></p><h2 id="전체-코드"><a href="#전체-코드" class="headerlink" title="전체 코드"></a>전체 코드</h2><p>수집을 원하는 기간을 가장 위의 <code>start</code>, <code>end</code>에 입력하면 그 결과가 csv file 로 저장되는 코드이다.</p><p>본 코드는 정적 데이터를 수집하기 위해 작성되었으며, 동적 데이터가 존재하는 경우 다른 패키지를 사용해야 한다. (참고!) </p><p>그리 깔끔한 코드는 아니니까 공부용으로 사용하시길..</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 가져올 범위를 정의</span></span><br><span class="line"><span class="comment"># 2015-02-25 ~ 2015-02-28 // 2015-03-01 ~ 2015-03-31</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">days_range = []</span><br><span class="line"></span><br><span class="line">start = datetime.datetime.strptime(<span class="string">"2015-02-25"</span>, <span class="string">"%Y-%m-%d"</span>) <span class="comment"># 수집 시작 날짜</span></span><br><span class="line">end = datetime.datetime.strptime(<span class="string">"2015-03-31"</span>, <span class="string">"%Y-%m-%d"</span>) <span class="comment"># 수집 종료 날짜 + 1</span></span><br><span class="line">date_generated = [start + datetime.timedelta(days=x) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, (end-start).days)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> date <span class="keyword">in</span> date_generated:</span><br><span class="line">    days_range.append(date.strftime(<span class="string">"%Y-%m-%d"</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 크롤러 작성</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm_notebook</span><br><span class="line"></span><br><span class="line">main_news_list = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># html parser 정의</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_bs_obj</span><span class="params">(url)</span>:</span></span><br><span class="line">    result = requests.get(url)</span><br><span class="line">    bs_obj = BeautifulSoup(result.content, <span class="string">"html.parser"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> bs_obj</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> date <span class="keyword">in</span> tqdm_notebook(days_range):</span><br><span class="line">    </span><br><span class="line">    news_arrange_url = <span class="string">"https://news.naver.com/main/history/mainnews/list.nhn"</span></span><br><span class="line">    news_list_date_page_url = news_arrange_url + <span class="string">"?date="</span> + date</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get bs_obj</span></span><br><span class="line">    bs_obj = get_bs_obj(news_list_date_page_url)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 포토 뉴스 페이지 수 구하기</span></span><br><span class="line">    photo_news_count = bs_obj.find(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>: <span class="string">"eh_page"</span>&#125;).text.split(<span class="string">'/'</span>)[<span class="number">1</span>]</span><br><span class="line">    photo_news_count = int(photo_news_count)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 리스트 뉴스 페이지 수 구하기</span></span><br><span class="line">    text_news_count = bs_obj.find(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>: <span class="string">"mtype_list_wide"</span>&#125;).find(<span class="string">"div"</span>, &#123;<span class="string">"class"</span>: <span class="string">"eh_page"</span>&#125;).text.split(<span class="string">'/'</span>)[<span class="number">1</span>]</span><br><span class="line">    text_news_count = int(text_news_count)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 포토 뉴스 부분 링크 크롤링</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> tqdm_notebook(range(<span class="number">1</span>,photo_news_count+<span class="number">1</span>)):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 포토 뉴스 링크</span></span><br><span class="line">        news_list_photo_url = <span class="string">'http://news.naver.com/main/history/mainnews/photoTv.nhn'</span></span><br><span class="line">        date_str = <span class="string">"?date="</span></span><br><span class="line">        page_str = <span class="string">"&amp;page="</span></span><br><span class="line">        news_list_photo_full_url = news_list_photo_url + <span class="string">"?date="</span> + date + <span class="string">"&amp;page="</span> + str(page)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># get bs obj</span></span><br><span class="line">        photo_bs_obj = get_bs_obj(news_list_photo_full_url)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 링크 내 정보 수집</span></span><br><span class="line">        ul = photo_bs_obj.find(<span class="string">"ul"</span>, &#123;<span class="string">"class"</span>: <span class="string">"edit_history_lst"</span>&#125;)</span><br><span class="line">        lis = ul.find_all(<span class="string">"li"</span>)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> lis:</span><br><span class="line">            title = item.find(<span class="string">"a"</span>)[<span class="string">"title"</span>]</span><br><span class="line">            press = item.find(<span class="string">"span"</span>, &#123;<span class="string">"class"</span> : <span class="string">"eh_by"</span>&#125;).text</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># link</span></span><br><span class="line">            link = item.find(<span class="string">"a"</span>)[<span class="string">"href"</span>]</span><br><span class="line">            </span><br><span class="line">            sid1 = link.split(<span class="string">'&amp;'</span>)[<span class="number">-3</span>].split(<span class="string">'='</span>)[<span class="number">1</span>]</span><br><span class="line">            oid = link.split(<span class="string">'&amp;'</span>)[<span class="number">-2</span>].split(<span class="string">'='</span>)[<span class="number">1</span>]</span><br><span class="line">            aid = link.split(<span class="string">'&amp;'</span>)[<span class="number">-1</span>].split(<span class="string">'='</span>)[<span class="number">1</span>]            </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 연예 TV 기사 제외</span></span><br><span class="line">            <span class="keyword">if</span> sid1 == <span class="string">"shm"</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">            article_type = <span class="string">"pic"</span></span><br><span class="line">            </span><br><span class="line">            pic_list = [date, article_type, title, press, sid1, link, aid]</span><br><span class="line">            </span><br><span class="line">            main_news_list.append(pic_list)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 텍스트 뉴스 부분 링크 크롤링</span></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> tqdm_notebook(range(<span class="number">1</span>, text_news_count+<span class="number">1</span>)):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 텍스트 뉴스 링크</span></span><br><span class="line">        news_list_text_url = <span class="string">'http://news.naver.com/main/history/mainnews/text.nhn'</span></span><br><span class="line">        date_str = <span class="string">"?date="</span></span><br><span class="line">        page_str = <span class="string">"&amp;page="</span></span><br><span class="line">        news_list_text_full_url = news_list_text_url + <span class="string">"?date="</span> + date + <span class="string">"&amp;page="</span> + str(page)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># get bs obj</span></span><br><span class="line">        text_bs_obj = get_bs_obj(news_list_text_full_url)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 링크 내 정보 수집</span></span><br><span class="line">        uls = text_bs_obj.find_all(<span class="string">"ul"</span>)</span><br><span class="line">        <span class="keyword">for</span> ul <span class="keyword">in</span> uls:</span><br><span class="line">            lis = ul.find_all(<span class="string">"li"</span>)</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> lis:</span><br><span class="line">                title = item.find(<span class="string">"a"</span>).text</span><br><span class="line">                press = item.find(<span class="string">"span"</span>, &#123;<span class="string">"class"</span> : <span class="string">"writing"</span>&#125;).text</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># link</span></span><br><span class="line">                link = item.find(<span class="string">"a"</span>)[<span class="string">"href"</span>]</span><br><span class="line"></span><br><span class="line">                sid1 = link.split(<span class="string">'&amp;'</span>)[<span class="number">-3</span>].split(<span class="string">'='</span>)[<span class="number">1</span>]</span><br><span class="line">                oid = link.split(<span class="string">'&amp;'</span>)[<span class="number">-2</span>].split(<span class="string">'='</span>)[<span class="number">1</span>]</span><br><span class="line">                aid = link.split(<span class="string">'&amp;'</span>)[<span class="number">-1</span>].split(<span class="string">'='</span>)[<span class="number">1</span>]</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 연예 TV 기사 제외</span></span><br><span class="line">                <span class="keyword">if</span> sid1 == <span class="string">"shm"</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                article_type = <span class="string">"text"</span></span><br><span class="line">                </span><br><span class="line">                text_list = [date, article_type, title, press, sid1, link, aid]</span><br><span class="line">                </span><br><span class="line">                main_news_list.append(text_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># make .csv file</span></span><br><span class="line">naver_news_main_df = pd.DataFrame(main_news_list, </span><br><span class="line">                                  columns = [<span class="string">"date"</span>, <span class="string">"type"</span>, <span class="string">"title"</span>, <span class="string">"press"</span>, <span class="string">"category"</span>, <span class="string">"link"</span>, <span class="string">"aid"</span>])</span><br><span class="line">naver_news_main_df.to_csv(<span class="string">"naver_main_news_&#123;&#125;_to_&#123;&#125;.csv"</span>.format(days_range[<span class="number">0</span>], days_range[<span class="number">-1</span>]), index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"=== total # of articles is &#123;&#125; ==="</span>.format(len(main_news_list)))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;네이버 뉴스와 관련된 데이터로 연구실에서 일하다 보니, 여러가지 관점에서 데이터를 수집하는 경우가 생긴다.&lt;/p&gt;
&lt;p&gt;네이버 뉴스에서 오른쪽 위쪽을 잘 살펴보면 &lt;a href=&quot;https://news.naver.com/main/history/mainnews/index.nhn&quot; rel=&quot;external nofollow noopener noreferrer&quot; target=&quot;_blank&quot;&gt;기사배열 이력&lt;/a&gt; 이라는 코너가 있다.&lt;/p&gt;
&lt;p&gt;2019년 4월 4일 이후부터는 메인에 뜨는 뉴스가 개인마다 다르게 적용되도록 서비스 하고 있는 것 같은데, 그 전에는 네이버가 자신들의 기준으로 메인에 기사를 걸어놓은 것 같다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/25416425/58689423-f4c52b80-83c1-11e9-9561-a1e8bd4f2fec.png&quot; width=&quot;550&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅰ. Data Science" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/"/>
    
      <category term="데이터 크롤링" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%81%AC%EB%A1%A4%EB%A7%81/"/>
    
    
      <category term="Python" scheme="https://jeongwookie.github.io/tags/Python/"/>
    
      <category term="Datamining" scheme="https://jeongwookie.github.io/tags/Datamining/"/>
    
      <category term="WEB Crawling" scheme="https://jeongwookie.github.io/tags/WEB-Crawling/"/>
    
  </entry>
  
  <entry>
    <title>Server Setting - 고정 ip 없이 주피터(jupyter) 원격 접속 설정하기</title>
    <link href="https://jeongwookie.github.io/2019/05/23/server/2-ubuntu-jupyter-notebook-remote/"/>
    <id>https://jeongwookie.github.io/2019/05/23/server/2-ubuntu-jupyter-notebook-remote/</id>
    <published>2019-05-23T03:36:42.000Z</published>
    <updated>2021-11-21T11:46:23.346Z</updated>
    
    <content type="html"><![CDATA[<p>오늘은 머신러닝과 데이터 사이언스 분야에서 거의 필수적으로 사용하고 있는 주피터 (Jupyter notebook)를 원격으로 접속할 수 있도록 세팅해 보겠다.</p><p>이 과정은 동일한 ip를 사용중인 wifi 환경에서 벗어난 (예를 들어 카페나 학교 등) 곳에서도 집에 있는 서버를 접속하여 편안한 코딩을 할 수 있도록 하기 위함이다.</p><p>셋팅은 Ubuntu 18.04 기준으로 진행하였다.</p><a id="more"></a><h2 id="공유기-설정하기"><a href="#공유기-설정하기" class="headerlink" title="공유기 설정하기"></a>공유기 설정하기</h2><p>먼저, 주피터 노트북을 원격으로 접속하려면 서버가 있는 환경의 고정 ip가 필요하다.</p><p>마치 택배를 배송받을 집 주소가 있어야 하는 것인데, 일반적으로 학교나 연구실, 회사가 아닌 이상 고정 ip가 아닌 유동 ip를 사용한다.</p><p>쉽게 말하면, 우리집 주소가 계속 바뀐다는 것. 이러면 제대로 찾아갈 수가 없다..</p><p>그래서 먼저 <strong>DDNS</strong> 라는 기능을 제공하는 공유기를 준비하여 우리의 유동 ip와 특정 문자열을 연결시킬 것이다.</p><p>택배 회사와 계약해서 ‘정욱이네’ 로 물건을 배송해 주세요~ 하면 우리집으로 배송되는 것과 비슷하다.</p><p>하지만 그 전에 집에 있는 공유기가 DDNS 기능을 제공하는지 검색해서 확인해보자.</p><p>아니라면 새로 하나 장만하기를 추천한다. 세팅이 가장 쉬운 것은 iptime 공유기이다.</p><p>다나와에서 아래와 같이 검색하면 쉽게 제품을 확인할 수 있다. 나는 마침 굴러다니는 12,900원짜리 iptime N702R 공유기가 있어 이것을 사용했다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58224546-2baf9780-7d59-11e9-86d0-cdd5f5e9d578.png" width="600"></p><h3 id="DDNS-설정-진입"><a href="#DDNS-설정-진입" class="headerlink" title="DDNS 설정 진입"></a>DDNS 설정 진입</h3><p>iptime 공유기 설정을 위해 192.168.0.1로 접속한다. 기본 아이디 비밀번호는 admin으로 동일하다. 혹시 비밀번호를 설정했는데 잊어버렸다면 공유기 reset 버튼을 꾹 눌러서 초기화하자.</p><p>접속해서 관리 설정을 누르면 아래와 같은 화면이 보일 것이다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58224807-17b86580-7d5a-11e9-9d38-2fdd1d88e13d.png" width="600"></p><p>여기서 고급 설정 -&gt; 특수 기능 -&gt; <strong>DDNS 설정</strong> 으로 들어간다.</p><p>호스트 이름은 원하는 것으로 자유롭게 입력한다. 이 주소로 서버에 접속할 것이다.</p><p>사용자 아이디는 자주 사용하는 메일을 입력하고 (예시 : <a href="mailto:OOO@gmail.com" rel="external nofollow noopener noreferrer" target="_blank">OOO@gmail.com</a>)</p><p>오른쪽에 보이는 보안문자를 입력 후 DDNS 등록을 누르면 끝!</p><p><img src="https://user-images.githubusercontent.com/25416425/58224946-b8a72080-7d5a-11e9-8bd3-97751756093d.png" width="600"></p><p>아래에 등록 IP 주소가 나오는데, 이것으로 외부에서 접속이 가능하게 한다. 방금 전 입력하였던 호스트 이름으로도 접속이 가능하다.</p><h3 id="포트포워딩-설정"><a href="#포트포워딩-설정" class="headerlink" title="포트포워딩 설정"></a>포트포워딩 설정</h3><p>이번에는 포트포워딩 설정을 해보자. 특정 포트를 열고, 아까 전 설정한 DDNS 으로 등록된 ip 주소와 함께 입력하면 그것이 완전한 우리 서버의 주소이다. 등록된 ip는 전체 주소, 특정 포트 번호는 상세 주소라고 생각하면 된다.</p><p>고급 설정 -&gt; NAT/라우터 관리 -&gt; <strong>포트포워드 설정</strong> 으로 들어간다.</p><p>적당한 규칙 이름을 지정하고, 내부 ip 주소는 현재 세팅하고 있는 서버의 주소를 입력하면 된다. 현재 접속된 IP 주소를 체크하여도 괜찮다.</p><p>프로토콜은 TCP로 하고, 외부 포트 및 내부 포트 번호를 모두 3389로 입력한다. (기본)</p><p><img src="https://user-images.githubusercontent.com/25416425/58225218-fce6f080-7d5b-11e9-913e-93ddf12bc6ed.png" width="600"></p><p>여기까지 진행한 내용을 간단히 정리해 보면,</p><p>외부에서 서버에 접속할 때 DDNS 설정 시 입력하였던 적당한 호스트 이름 주소 (OOO.iptime.org) 및 포트번호 (3389)를 입력하면, 포트포워딩을 설정한 내부 ip + 해당 포트(3389) 로 접속되는 것이다.</p><h3 id="공유기-설정-접속-관리"><a href="#공유기-설정-접속-관리" class="headerlink" title="공유기 설정 접속 관리"></a>공유기 설정 접속 관리</h3><p>마지막으로, 외부에서도 서버에 연결된 공유기의 설정을 변경하고 싶을때를 대비하여 세팅을 해보자.</p><p>고급 설정 -&gt; 보안 기능 -&gt; <strong>공유기 접속/보안관리</strong> 로 들어간다.</p><p>외부 접속 보안에서 <strong>[원격 관리 포트 사용]</strong> 을 체크하고, 적당한 포트 번호를 입력한다. (예시: 1234)</p><p>적용 버튼을 누르면 끝! 이제 외부에서 공유기를 설정하고 싶을 때는 <strong>OOO.iptime.org:1234</strong> 로 접속하면 된다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58225493-39671c00-7d5d-11e9-8b2c-35e3264e9df8.png" width="600"></p><p>그리고 공유기를 혹시 초기화 하였다면 공유기 자체의 무선 비밀번호 또한 초기화 되어 있을 것이므로, 기본 설정에서 각자 세팅해 주자.</p><h2 id="우분투에서-포트-열기"><a href="#우분투에서-포트-열기" class="headerlink" title="우분투에서 포트 열기"></a>우분투에서 포트 열기</h2><p>전반적인 공유기 설정은 완료되었다. 이제 주피터를 설정해야 하는데, 그 전에 아까 전 입력했던 포트를 우분투에서 열어놓자.</p><p>터미널을 열고, 아래와 같은 코드를 순차적으로 입력한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3389 포트 오픈</span></span><br><span class="line">sudo iptables -I INPUT <span class="number">1</span> -p tcp --dport <span class="number">3389</span> -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 포트가 열렸는지 확인</span></span><br><span class="line">sudo iptables -L -v</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3389 포트의 방화벽 해제</span></span><br><span class="line">sudo ufw allow <span class="number">3389</span></span><br></pre></td></tr></table></figure><h2 id="주피터-노트북-설정하기"><a href="#주피터-노트북-설정하기" class="headerlink" title="주피터 노트북 설정하기"></a>주피터 노트북 설정하기</h2><h3 id="비밀번호-설정"><a href="#비밀번호-설정" class="headerlink" title="비밀번호 설정"></a>비밀번호 설정</h3><p>먼저 주피터 노트북의 설정 파일을 만들고, 이를 우리의 세팅으로 수정할 것이다.</p><p>우분투 터미널을 켜고, 아래와 같은 코드를 순차적으로 입력한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda activate ds_fox <span class="comment"># 나의 가상 환경 activate</span></span><br><span class="line">jupyter notebook –generate-config <span class="comment"># 주피터 설정 파일 만들기</span></span><br><span class="line">ipython</span><br><span class="line"><span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</span><br><span class="line">passwd()</span><br></pre></td></tr></table></figure><p><code>passwd()</code> 을 입력하면 아래에 패스워드를 입력하라고 뜨는데, 이것이 차후 주피터 서버에 접속할 때 요구하는 자신만의 비밀번호이다.</p><p>입력을 완료하면 Output으로 <code>sha1:----</code> 이런 형태의 긴 암호화된 문자열이 출력되는데, <strong>반드시 어딘가에 복사/붙여넣기 를 해놓도록 하자.</strong></p><p><img src="https://user-images.githubusercontent.com/25416425/58225860-09207d00-7d5f-11e9-8b05-e3de12559791.png" width="600"></p><h3 id="주피터-환경-설정"><a href="#주피터-환경-설정" class="headerlink" title="주피터 환경 설정"></a>주피터 환경 설정</h3><p>이제, 아까 만든 주피터 설정 파일을 vi 편집기로 열어서 수정할 것이다. 아래와 같은 코드를 입력한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># config file 열기</span></span><br><span class="line"><span class="comment"># jeongwook 자리에는 username 을 입력할 것</span></span><br><span class="line">vi /home/jeongwook/.jupyter/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure><p>입력하면 vi 편집기가 열릴 것이다. 처음 다루는 사람이라면 조금 어려울 수 있지만 간단한 규칙 몇가지만 알면 삽질을 피할 수 있을 것이다.</p><ol><li>방향키를 함부로 누르지 말것. 항상 <strong>ctrl 키</strong>를 누른 채로 움직인다.</li><li>명령어를 입력하고 싶으면 <strong>esc 키</strong>를 한번 누른 후 : 을 입력할 것</li><li>코드를 추가하고 싶을 때는 <strong>i (커서 오른쪽 시작)</strong> or <strong>a (커서 왼쪽 시작)</strong> 을 한번 누르고 입력할 것</li><li>코드를 수정하고 싶을 때는 backspace 키가 아닌 <strong>delete 키</strong>를 사용할 것</li></ol><p>이정도면 따로 찾아보지 않아도 대충은 코드 입력/수정이 가능하지 않을까 싶다.</p><p>이제 차례대로 수정해보자. 순서대로 입력하면 된다.</p><p><strong>a. 비밀번호 등록</strong></p><p><code>:/pp.pass/</code> 명령어를 입력하여 <strong>password</strong> 가 있는 위치를 찾는다. 찾으면 주석 아래에 코드를 입력한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c = get_config()</span><br><span class="line">c.NotebookApp.password = u‘내비밀번호붙여넣기’ <span class="comment"># sha1:--- 붙여넣기</span></span><br></pre></td></tr></table></figure><p><strong>b. 외부 접속 허용</strong></p><p><code>:/pp.allow/</code> 를 입력 후 대충 위쪽을 보면 <code>#c.NotebookApp.alloworigin = &#39;&#39;</code> 이런 주석이 있다. 바로 아래에다가 코드를 추가한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.allow_origin = ‘*’</span><br></pre></td></tr></table></figure><p><strong>c. 아이피 설정</strong></p><p><code>:/pp.ip/</code> 로 <strong>ip</strong> 가 있는 위치를 찾고, 주석 아래에 추가한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.ip = <span class="string">'192.168.0.2'</span> <span class="comment"># DDNS 설정 시 입력했던 내부 ip주소</span></span><br></pre></td></tr></table></figure><p><strong>d. 포트 설정</strong></p><p><code>:/pp.port/</code> 로 <strong>port</strong> 가 있는 위치를 찾고, 주석 아래에 열어놓은 포트 번호를 추가한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.port = <span class="number">3389</span></span><br></pre></td></tr></table></figure><p><strong>e. 시작 시 브라우저 실행 여부</strong></p><p><code>:/pp.op/</code> 로 <strong>open</strong> 이 있는 위치를 찾고, 주석 아래에 추가한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c.NotebookApp.open_browser = <span class="literal">False</span></span><br></pre></td></tr></table></figure><p>차례대로 주피터 설정 파일을 수정하고, 명령어 <code>:wq</code> 를 입력하여 저장하고 밖으로 나온다.</p><p>이것으로 주피터 외부 접속 환경설정이 끝났다.</p><p>잘 설정되었는지 확인해 보려면, 서버 컴퓨터에서 <code>jupyter notebook</code>을 입력해서 서버를 켠 후, 다른 외부망을 사용중인 PC에서 <strong>OOO.iptime.org:3389</strong> 를 입력해 보면 된다.</p><p>아래와 같은 창이 뜨면 성공!!</p><p><img src="https://user-images.githubusercontent.com/25416425/58226511-e6439800-7d61-11e9-97aa-e1e3dc6207e2.png" width="600"></p><p><em>세팅하는데 참고한 블로그들</em><br><em><a href="https://light-tree.tistory.com/111" rel="external nofollow noopener noreferrer" target="_blank">https://light-tree.tistory.com/111</a></em><br><em><a href="https://breath91.tistory.com/" rel="external nofollow noopener noreferrer" target="_blank">https://breath91.tistory.com/</a></em><br><em><a href="https://ironmask.net/354" rel="external nofollow noopener noreferrer" target="_blank">https://ironmask.net/354</a></em><br><em><a href="https://linguist79.tistory.com/45" rel="external nofollow noopener noreferrer" target="_blank">https://linguist79.tistory.com/45</a></em></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;오늘은 머신러닝과 데이터 사이언스 분야에서 거의 필수적으로 사용하고 있는 주피터 (Jupyter notebook)를 원격으로 접속할 수 있도록 세팅해 보겠다.&lt;/p&gt;
&lt;p&gt;이 과정은 동일한 ip를 사용중인 wifi 환경에서 벗어난 (예를 들어 카페나 학교 등) 곳에서도 집에 있는 서버를 접속하여 편안한 코딩을 할 수 있도록 하기 위함이다.&lt;/p&gt;
&lt;p&gt;셋팅은 Ubuntu 18.04 기준으로 진행하였다.&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅴ. DevEnv" scheme="https://jeongwookie.github.io/categories/%E2%85%A4-DevEnv/"/>
    
      <category term="Jupyter" scheme="https://jeongwookie.github.io/categories/%E2%85%A4-DevEnv/Jupyter/"/>
    
    
      <category term="Server setting" scheme="https://jeongwookie.github.io/tags/Server-setting/"/>
    
      <category term="Ubuntu" scheme="https://jeongwookie.github.io/tags/Ubuntu/"/>
    
      <category term="Linux" scheme="https://jeongwookie.github.io/tags/Linux/"/>
    
      <category term="Jupyter notebook" scheme="https://jeongwookie.github.io/tags/Jupyter-notebook/"/>
    
  </entry>
  
  <entry>
    <title>Server Setting - 우분투(Ubuntu) 18.04 설치하기</title>
    <link href="https://jeongwookie.github.io/2019/05/21/server/1-ubuntu-install-usb/"/>
    <id>https://jeongwookie.github.io/2019/05/21/server/1-ubuntu-install-usb/</id>
    <published>2019-05-21T11:55:21.000Z</published>
    <updated>2021-11-21T11:46:17.747Z</updated>
    
    <content type="html"><![CDATA[<p>지금까지 가상머신으로 우분투를 사용하다가 Pre-trained model을 불러오는데 Memory Error가 떠서..ㅠㅠ 이참에 집에 남아있는 컴퓨터로 서버를 세팅하고자 마음먹었다.</p><p>딥러닝에 사용할 서버로, 설치 OS는 <strong>Ubuntu 18.04.2 LTS</strong> 이다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58094898-afa83900-7c0c-11e9-8220-e91b063b03ed.png" width="300"></p><a id="more"></a><h2 id="준비하기"><a href="#준비하기" class="headerlink" title="준비하기"></a>준비하기</h2><p>먼저, 공식 웹사이트에서 설치 파일을 다운받자.</p><p><a href="https://www.ubuntu.com/download/desktop" rel="external nofollow noopener noreferrer" target="_blank">Download Ubuntu 18.04.2 LTS Version</a></p><p>ISO 파일을 다운받았다면, 이제 부팅 USB를 만들어야 한다.</p><p>적어도 2GB 이상의 USB를 준비하자.</p><p>USB 메모리 내부에 있는 모든 데이터가 삭제되므로, 빈 USB가 아니라면 백업을 권장한다.</p><h2 id="부팅-USB-만들기"><a href="#부팅-USB-만들기" class="headerlink" title="부팅 USB 만들기"></a>부팅 USB 만들기</h2><p>이제, 윈도우 환경 기준으로 우분투 부팅 USB를 만들어 볼 것이다.</p><p>아래의 사이트에 방문하여, <strong>Rufus</strong>라는 프로그램을 다운로드 하자. Ubuntu에서 공식으로 지원하는 프로그램이니 안심해도 된다.</p><p><a href="https://rufus.ie/" rel="external nofollow noopener noreferrer" target="_blank">https://rufus.ie/</a></p><p>프로그램을 다운받은 후 USB를 연결한 후 실행한다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58095561-3dd0ef00-7c0e-11e9-8a2b-6f05a7912583.png" width="350"></p><p>장치는 부팅용으로 만들 USB를 클릭하고 (대부분의 경우 기본으로 잡힘) 부트 선택에서 빨간색 네모가 있는 부분을 클릭. 그리고 방금 전 다운로드 받은 ISO 파일을 선택한다.</p><p>그리고 제일 아래 시작을 누르면 되는데, 중간에 두 번의 팝업이 뜬다.</p><p>첫 번째는 추가 파일 다운로드 여부를 묻는 것으로 <strong>[예 (Y)]</strong> 를 클릭하면 되고, 두 번째는 <strong>[ISO 이미지 모드로 쓰기 (권장)]</strong> 을 선택하면 된다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58095997-12023900-7c0f-11e9-9cbf-ffa5eeea69c7.png" width="350"></p><p>ISO 파일 복사가 완료되면, 이제 이것으로 부팅을 하면 된다.</p><h2 id="Ubuntu-설치하기"><a href="#Ubuntu-설치하기" class="headerlink" title="Ubuntu 설치하기"></a>Ubuntu 설치하기</h2><p>부팅 시 바이오스창을 F2, F11 등으로 열어서 Boot option을 해당 USB으로 바꾸어 주는 것은 기본.</p><p>부팅 후 첫 화면은 아래와 같다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58120188-a8e6e980-7c3f-11e9-8c7c-7d9201770593.jpg" width="500"></p><p>여기서 <strong>[install Ubuntu]</strong> 버튼을 클릭해서 설치를 시작한다.</p><p>키보드 레이아웃 및 업데이트 등의 선택 사항들이 차례대로 나오는데 default로 쭉쭉 넘어간다.</p><p>설치 유형을 선택하는 창이 아래와 같이 나오면, 이때부터 조심해야 한다.</p><p>여러 옵션 중에서 <strong>[Something else]</strong> 을 클릭하여 <u>세부적인 파티션 설정</u>을 시작할 것이다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58120367-109d3480-7c40-11e9-97b2-4395a838edb3.jpg" width="500"></p><h2 id="파티션-설정하기"><a href="#파티션-설정하기" class="headerlink" title="파티션 설정하기"></a>파티션 설정하기</h2><p>이 부분이 Ubuntu 설치에서 가장 복잡한 단계이다.</p><p>먼저, 아래의 <strong>[New Partition Table]</strong> 버튼을 클릭한다. 이때, 아래의 그림과 달리 사용자의 HDD나 다른 SSD가 존재할 경우 잘못된 위치에 셋업하지 않도록 주의한다. 새 파티션을 구성할 장치는 포맷되기 때문에..</p><p><img src="https://user-images.githubusercontent.com/25416425/58120679-ad5fd200-7c40-11e9-8b21-9e73776bded4.jpg" width="500"></p><p>이제 생성한 새 파티션 테이블 아래에 2개의 파티션을 생성할 것이다. 왼쪽 아래의 (+) 버튼을 눌러서 새 파티션을 추가한다.</p><ul><li>스왑 (Swap) 파티션 : 시스템에서 물리메모리가 부족할 경우 사용되는 파티션이며, 일반적으로 메모리 용량의 2배 정도로 설정하여 생성한다.</li><li>Ext4 파티션 : 실제 파일들이 저장되게 될 파티션.</li></ul><p>스왑 파티션의 용량 설정에 관하여는 <a href="https://access.redhat.com/ko/solutions/744483" rel="external nofollow noopener noreferrer" target="_blank">RedHat Linux 권장 Swap 크기</a>를 참고하자.</p><p>먼저 <strong>스왑 파티션</strong>을 추가한다. 필자는 8기가 메모리에 16기가만큼 할당하였으며 아래 그림은 1024 MB (1 GB) 공간을 할당한 스크린샷을 가져왔다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58121375-46431d00-7c42-11e9-8184-3702ea40aa67.png" width="500"></p><p>그리고 다시 (+) 버튼을 눌러서 이번에는 <strong>Ext4 파티션</strong>을 추가한다. 나머지 모든 공간을 할당하였으며 마운트 위치는 / 으로 설정한다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58121375-46431d00-7c42-11e9-8184-3702ea40aa67.png" width="500"></p><p>파티션 설정은 완료되었다. 이제 아래의 <strong>[Install Now]</strong> 버튼을 눌러 진행하면 설치 끝!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;지금까지 가상머신으로 우분투를 사용하다가 Pre-trained model을 불러오는데 Memory Error가 떠서..ㅠㅠ 이참에 집에 남아있는 컴퓨터로 서버를 세팅하고자 마음먹었다.&lt;/p&gt;
&lt;p&gt;딥러닝에 사용할 서버로, 설치 OS는 &lt;strong&gt;Ubuntu 18.04.2 LTS&lt;/strong&gt; 이다.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/25416425/58094898-afa83900-7c0c-11e9-8220-e91b063b03ed.png&quot; width=&quot;300&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅴ. DevEnv" scheme="https://jeongwookie.github.io/categories/%E2%85%A4-DevEnv/"/>
    
      <category term="Ubuntu" scheme="https://jeongwookie.github.io/categories/%E2%85%A4-DevEnv/Ubuntu/"/>
    
    
      <category term="Server setting" scheme="https://jeongwookie.github.io/tags/Server-setting/"/>
    
      <category term="Ubuntu" scheme="https://jeongwookie.github.io/tags/Ubuntu/"/>
    
      <category term="Linux" scheme="https://jeongwookie.github.io/tags/Linux/"/>
    
      <category term="Boot USB" scheme="https://jeongwookie.github.io/tags/Boot-USB/"/>
    
  </entry>
  
  <entry>
    <title>R을 사용한 데이터 시각화 - 3. histogram과 barplot 그리기</title>
    <link href="https://jeongwookie.github.io/2019/03/25/datascience/visualization/3-data-visualization-using-R-3/"/>
    <id>https://jeongwookie.github.io/2019/03/25/datascience/visualization/3-data-visualization-using-R-3/</id>
    <published>2019-03-25T13:23:09.000Z</published>
    <updated>2021-11-21T11:24:14.003Z</updated>
    
    <content type="html"><![CDATA[<p>이번 포스트에서는 Histogram 과 Boxplot 다루어 볼 것이다.</p><p>내장 데이터셋인 <code>cane</code>을 활용하여 먼저 Histogram을 그려보자.</p><p><img src="https://user-images.githubusercontent.com/25416425/58715926-d9c6db80-8402-11e9-986b-85a5cd951f12.png" width="450"></p><a id="more"></a><h2 id="Simple-histogram"><a href="#Simple-histogram" class="headerlink" title="Simple histogram"></a>Simple histogram</h2><p><code>hist()</code> 함수가 기본적으로 내장되어 있다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(boot)</span><br><span class="line">head(cane)</span><br><span class="line">ratio &lt;- cane$r/cane$n <span class="comment"># dataset_name$column_name</span></span><br><span class="line">hist(ratio, breaks = <span class="number">20</span>, xlab = <span class="string">"Diseased Shoot Ratio"</span>, </span><br><span class="line">    col = <span class="string">'aquamarine'</span>, main = <span class="string">"Histogram of Diseased Shoot Ratio"</span>)</span><br></pre></td></tr></table></figure><p>코드에서 <code>breaks</code> 옵션은 블록의 크기를 얼마나 잘게 쪼갤지 조절한다.</p><blockquote><p>왼쪽은 breaks = 20, 오른쪽은 breaks = 40 일때</p></blockquote><div style="width:50%; height:450px; float:left;"><br><img src="https://user-images.githubusercontent.com/25416425/58709127-7635b180-83f4-11e9-82b1-f0aa805f3e23.png" width="450"><br></div><div style="width:50%; height:450px; float:right;"><br><img src="https://user-images.githubusercontent.com/25416425/58709161-8fd6f900-83f4-11e9-9694-471d2de5b72f.png" width="450"><br></div><h2 id="ggplot으로-histogram-그리기"><a href="#ggplot으로-histogram-그리기" class="headerlink" title="ggplot으로 histogram 그리기"></a>ggplot으로 histogram 그리기</h2><p>ggplot으로 histogram을 그릴 때는, <code>geom_histogram()</code> 함수를 사용한다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line">ggplot(cane, aes(x=r/n, fill=block)) + </span><br><span class="line">  geom_histogram(col=<span class="string">"black"</span>, bins=<span class="number">20</span>) + theme_bw() + </span><br><span class="line">  facet_grid(block ~ .) + xlab(<span class="string">'Diseased Shoot Ratio'</span>) + </span><br><span class="line">  theme(legend.position = <span class="string">"none"</span>) <span class="comment"># legend를 제거</span></span><br></pre></td></tr></table></figure><p><code>fill</code> 옵션으로 block 별로 다르게 색상을 표시하라고 지정했다.</p><p>히스토그램 내 <code>bins</code> 옵션은 위의 <code>breaks</code>와 동일한 효과이며, <code>facet_grid()</code> 를 활용하여 cane 내의 block 값 별로 분리하여 출력했다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58710078-7df65580-83f6-11e9-8436-e8374169e332.png" width="450"></p><h2 id="Simple-boxplot"><a href="#Simple-boxplot" class="headerlink" title="Simple boxplot"></a>Simple boxplot</h2><p>이번에는 <strong>Boxplot</strong> 을 그려 보자. 주로 그룹 간의 차이를 나타낼 때 사용하며, 꽤나 자주 등장하는 타입이므로 중요하다.</p><p>데이터는 내장 데이터셋인 <code>ToothGrowth</code>를 사용한다. 데이터를 먼저 살펴보자.</p><p><img src="https://user-images.githubusercontent.com/25416425/58710691-de39c700-83f7-11e9-9855-7e041a70ed07.png" width="450"></p><p>기본적으로 <code>boxplot()</code> 함수로 그릴 수 있다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># simple boxplot</span></span><br><span class="line">boxplot(len~supp, data=ToothGrowth, xlab=<span class="string">'Supplement Type'</span>, ylab=<span class="string">'Tooth Length'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Boxplot of len against dose and supp factors</span></span><br><span class="line">boxplot(len~supp*dose, data=ToothGrowth, notch=<span class="literal">T</span>, </span><br><span class="line">        xlab=<span class="string">'Suppliment and Dose'</span>, ylab=<span class="string">'Tooth length'</span>, col=c(<span class="string">'cyan'</span>, <span class="string">'magenta'</span>))</span><br></pre></td></tr></table></figure><blockquote><p>왼쪽은 <strong>supp</strong>을 기준으로, 오른쪽은 <strong>supp</strong>와 <strong>dose</strong>를 조합하여 그린 boxplot</p></blockquote><div style="width:50%; height:450px; float:left;"><br><img src="https://user-images.githubusercontent.com/25416425/58710962-759f1a00-83f8-11e9-91ef-d743bce361e4.png" width="450"><br></div><div style="width:50%; height:450px; float:right;"><br><img src="https://user-images.githubusercontent.com/25416425/58710999-894a8080-83f8-11e9-9eec-28b45072b2a1.png" width="450"><br></div><h2 id="ggplot으로-boxplot-그리기"><a href="#ggplot으로-boxplot-그리기" class="headerlink" title="ggplot으로 boxplot 그리기"></a>ggplot으로 boxplot 그리기</h2><p>ggplot으로 boxplot을 그릴 때는, <code>geom_boxplot()</code> 함수를 사용한다.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line">ggplot(ToothGrowth, aes(x=factor(dose), y=len)) +</span><br><span class="line">  geom_boxplot(aes(fill=supp)) +</span><br><span class="line">  xlab(<span class="string">'Dose'</span>) + ylab(<span class="string">'Tooth length'</span>) + ggtitle(<span class="string">'Analyzing ToothGrowth Data'</span>)</span><br></pre></td></tr></table></figure><p>x 값에 우리가 원하는 <code>dose</code>를 넣을 때, 자료형을 num 에서 factor로 바꿔주기 위해서 (category화) <code>factor()</code> 함수를 사용했다.</p><p>boxplot의 색상은 <code>supp</code>에 따라 바뀌도록 <code>fill</code> 옵션을 지정하였다.</p><p><img src="https://user-images.githubusercontent.com/25416425/58711160-d9294780-83f8-11e9-8689-429a08b549be.png" width="450"></p><p>확실히 ggplot으로 그린 그래프들이 전반적으로 깔끔하다. 기본적인 graph 그리기 포스트는 끝!</p><blockquote><p><em>본 포스트는 KAIST 전산학부 대학원 과정에서 수강하고 있는 Big Data Analytics using R (CS564)을 실습하며 작성하였음을 밝힙니다.</em></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;이번 포스트에서는 Histogram 과 Boxplot 다루어 볼 것이다.&lt;/p&gt;
&lt;p&gt;내장 데이터셋인 &lt;code&gt;cane&lt;/code&gt;을 활용하여 먼저 Histogram을 그려보자.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/25416425/58715926-d9c6db80-8402-11e9-986b-85a5cd951f12.png&quot; width=&quot;450&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Ⅰ. Data Science" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/"/>
    
      <category term="데이터 시각화" scheme="https://jeongwookie.github.io/categories/%E2%85%A0-Data-Science/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94/"/>
    
    
      <category term="R programming" scheme="https://jeongwookie.github.io/tags/R-programming/"/>
    
      <category term="Class" scheme="https://jeongwookie.github.io/tags/Class/"/>
    
      <category term="KAIST" scheme="https://jeongwookie.github.io/tags/KAIST/"/>
    
  </entry>
  
</feed>
